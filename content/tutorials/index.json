[{"uri":"https://fslab.org/005_testing_t-test.html","title":"Testing with FSharp.Stats I: t-test\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Testing with FSharp.Stats I: t-test\ncategory: datascience\nauthors: Oliver Maus\nindex: 5\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: Deedle, 2.5.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: Newtonsoft.Json, 13.0.1\u0022\n#r \u0022nuget: DynamicObj, 0.2.0\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: Deedle, 2.5.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: Newtonsoft.Json, 13.0.1\u0022\n#r \u0022nuget: DynamicObj, 0.2.0\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n#endif // IPYNB\n\n\n\n(**\n\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath=content/tutorials/{{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n# Testing with FSharp.Stats I: t-test\n\n## Getting started: The t-test\n\n_I love statistical testing_ - A sentence math teachers don\u0027t hear often during their time at school. In this tutorial we aim to give you a short introduction of the theory and how to \nperform the most used statistical test: the t-test\n\nSuppose you have measured the length of some leaves of two trees and you want to find out if the average length of the leaves is the same or if they differ from each other. \nIf you knew the population distributions of all leaves hanging on both trees the task would be easy, but since we only have samples from both populations, we have to apply a statistical test.\nStudent\u0027s t-test can be applied to test whether two samples have the same mean (H0), or if the means are different (H1). There are two requirements to the samples that have to be fulfilled:\n\n1. The variances of both samples have to be equal.\n\n2. The samples have to follow a normal distribution.\n\n_Note: Slight deviations from these requirements can be accepted but strong violations result in an inflated false positive rate. If the variances are not equal a Welch test can be performed._\n_There are some tests out there to check if the variances are equal or if the sample follows a normal distribution, but their effectiveness is discussed._\n_You always should consider the shape of the theoretical background distribution, instead of relying on preliminary tests rashly._\n\n\nThe t-test is one of the most used statistical tests in datascience. It is used to compare two samples in terms of statistical significance. \nOften a significance threshold (or \u0026alpha; level) of 0.05 is chosen to define if a p value is defined as statistically significant. A p value describes how likely it is to observe an effect\nat least as extreme as you observed (in the comparison) by chance. Low p values indicate a high confidence to state that there is a real difference and the observed difference is not caused by chance.\n\n*)\n\n#r \u0022nuget: FSharp.Data\u0022\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.2\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n\nopen FSharp.Data\nopen Deedle\nopen Plotly.NET\n\n(**\n\nFor our purposes, we will use the housefly wing length dataset (from _Sokal et al., 1955, A morphometric analysis of DDT-resistant and non-resistant housefly strains_).\nHead over to the [Getting started](001_getting-started.html#Data-access) tutorial where it is shown how to import datasets in a simple way.\n\n\n*)\n\n// We retrieve the dataset via FSharp.Data:\nlet rawDataHousefly = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/HouseflyWingLength.txt\u0022\n\nlet dataHousefly : seq\u003Cfloat\u003E = \n    Frame.ReadCsvString(rawDataHousefly, false, schema = \u0022wing length (mm * 10^1)\u0022)\n    |\u003E Frame.getCol \u0022wing length (mm * 10^1)\u0022\n    |\u003E Series.values\n    // We convert the values to mm\n    |\u003E Seq.map (fun x -\u003E x / 10.)\n\n(**\n\nLet us first have a look at the sample data with help of a boxplot. As shown below, the average wingspan is around 4.5 with variability ranges between 3.5 and 5.5.\n\n\n*)\n\nlet boxPlot = \n    Chart.BoxPlot(y = dataHousefly, Name = \u0022housefly\u0022, BoxPoints = StyleParam.BoxPoints.All, Jitter = 0.2)\n    |\u003E Chart.withYAxisStyle \u0022wing length [mm]\u0022\n\n(*** condition: ipynb ***)\n#if IPYNB\nboxPlot\n#endif // IPYNB\n\n(***hide***)\nboxPlot |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n(**\n\n## One-sample t-test\n\nWe want to analyze if an estimated expected value differs from the sample above. Therefore, we perform a one-sample t-test which covers exactly this situation.\n\n\n\n\u003Cimg style=\u0022max-width:75%\u0022 src=\u0022../../images/OneSampleTTest.png\u0022\u003E\u003C/img\u003E\n\nFig. 1: **The one-sample t-test** The dashed orange line depicts the distribution of our sample, the green bar the expected value to test against.\n\n*)\n\nopen FSharp.Stats\nopen FSharp.Stats.Testing\n\n// The testing module in FSharp.Stats require vectors as input types, thus we transform our array into a vector:\nlet vectorDataHousefly = vector dataHousefly\n\n// The expected value of our population.\nlet expectedValue = 4.5\n\n// Perform the one-sample t-test with our vectorized data and our exptected value as parameters.\nlet oneSampleResult = TTest.oneSample vectorDataHousefly expectedValue\n\n(*** hide ***)\n\n(*** include-value:oneSampleResult ***)\n\n(**\n\nThe function returns a \u0060TTestStatistics\u0060 type. If contains the fields \n\n  - \u0060Statistic\u0060: defines the exact teststatistic\n\n  - \u0060DegreesOfFreedom\u0060: defines the degrees of freedom\n\n  - \u0060PValueLeft\u0060: the left-tailed p-value \n\n  - \u0060PValueRight\u0060: the right-tailed p-value\n\n  - \u0060PValue\u0060: the two-tailed p-value\n\nAs we can see, when looking at the two-tailed p-value, our sample does _not_ differ significantly from our expected value. This matches our visual impression of the boxplot, where the sample distribution \nis centered around 4.5.\n\n\n## Two-sample t-test (unpaired data)\n\nThe t-test is most often used in its two-sample variant. Here, two samples, independent from each other, are compared. It is required that both samples are normally distributed.\nIn this next example, we are going to see if the gender of college athletes determines the number of concussions suffered over 3 years (from: _Covassin et al., 2003, Sex Differences and the Incidence of Concussions Among Collegiate Athletes, Journal of Athletic Training_).\n\n\n\u003Cimg style=\u0022max-width:75%\u0022 src=\u0022../../images/TwoSampleTTest.png\u0022\u003E\u003C/img\u003E\n\nFig. 2: **The two-sample t-test** The dashed orange and green lines depict the distribution of both samples that are compared with each other.\n\n*)\n\nopen System.Text\n\nlet rawDataAthletes = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/ConcussionsInMaleAndFemaleCollegeAthletes_adapted.tsv\u0022\n\nlet dataAthletesAsStream = new System.IO.MemoryStream(rawDataAthletes |\u003E Encoding.UTF8.GetBytes)\n\n// The schema helps us setting column keys.\nlet dataAthletesAsFrame = Frame.ReadCsv(dataAthletesAsStream, hasHeaders = false, separators = \u0022\\t\u0022, schema = \u0022Gender, Sports, Year, Concussion, Count\u0022)\n\ndataAthletesAsFrame.Print()\n\n// We need to filter out the columns and rows we don\u0027t need. Thus, we filter out the rows where the athletes suffered no concussions  \n// as well as filter out the columns without the number of concussions.\nlet dataAthletesFemale, dataAthletesMale =\n    let getAthleteGenderData gender =\n        let dataAthletesOnlyConcussion =\n            dataAthletesAsFrame\n            |\u003E Frame.filterRows (fun r objS -\u003E objS.GetAs \u0022Concussion\u0022)\n        let dataAthletesGenderFrame =\n            dataAthletesOnlyConcussion\n            |\u003E Frame.filterRows (fun r objS -\u003E objS.GetAs \u0022Gender\u0022 = gender)\n        dataAthletesGenderFrame\n        |\u003E Frame.getCol \u0022Count\u0022 \n        |\u003E Series.values\n        |\u003E vector\n    getAthleteGenderData \u0022Female\u0022, getAthleteGenderData \u0022Male\u0022\n    \n(**\n\nAgain, let\u0027s check our data via boxplots before we proceed on comparing them.\n\n*)\n\nlet boxPlot2 = \n    [\n        Chart.BoxPlot(y = dataAthletesFemale, Name = \u0022female college athletes\u0022, BoxPoints = StyleParam.BoxPoints.All, Jitter = 0.2)\n        Chart.BoxPlot(y = dataAthletesMale, Name = \u0022male college athletes\u0022, BoxPoints = StyleParam.BoxPoints.All, Jitter = 0.2)\n    ]\n    |\u003E Chart.combine\n    |\u003E Chart.withYAxisStyle \u0022number of concussions over 3 years\u0022\n\n\n(*** condition: ipynb ***)\n#if IPYNB\nboxPlot2\n#endif // IPYNB\n\n(***hide***)\nboxPlot2 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\nBoth samples are tested against using \u0060FSharp.Stats.Testing.TTest.twoSample\u0060 and assuming equal variances.\n\n*)\n\n// We test both samples against each other, assuming equal variances.\nlet twoSampleResult = TTest.twoSample true dataAthletesFemale dataAthletesMale\n\n(*** include-value:twoSampleResult ***)\n\n(**\n\nWith a p value of 0.58 the t-test indicate that there\u0027s no significant difference between the number of concussions over 3 years between male and female college athletes.\n\n\n## Two-sample t-test (paired data)\n\nPaired data describes data where each value from the one sample is connected with its respective value from the other sample.  \nIn the next case, the endurance performance of several persons in a normal situation (control situation) is compared to their performance after ingesting a specific amount of caffeine*. \nIt is the same person that performs the exercise but under different conditions. Thus, the resulting values of the persons under each condition are compared.  \nAnother example are time-dependent experiments: One measures, e.g., the condition of cells stressed with a high surrounding temperature in the beginning and after 30 minutes. \nThe measured cells are always the same, yet their conditions might differ.\nDue to the connectivity of the sample pairs the samples must be of equal length.\n\n*Source: W.J. Pasman, M.A. van Baak, A.E. Jeukendrup, A. de Haan (1995). _The Effect of Different Dosages of Caffeine on Endurance Performance Time_, International Journal of Sports Medicine, Vol. 16, pp225-230.\n\n*)\n\nlet rawDataCaffeine = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/CaffeineAndEndurance(wide)_adapted.tsv\u0022\n\nlet dataCaffeineAsStream = new System.IO.MemoryStream(rawDataCaffeine |\u003E Encoding.UTF8.GetBytes)\nlet dataCaffeineAsFrame = Frame.ReadCsv(dataCaffeineAsStream, hasHeaders = false, separators = \u0022\\t\u0022, schema = \u0022Subject ID, no Dose, 5 mg, 9 mg, 13 mg\u0022)\n\n// We want to compare the subjects\u0027 performances under the influence of 13 mg caffeine and in the control situation.\nlet dataCaffeineNoDose, dataCaffeine13mg =\n    let getVectorFromCol col = \n        dataCaffeineAsFrame\n        |\u003E Frame.getCol col\n        |\u003E Series.values\n        |\u003E vector\n    getVectorFromCol \u0022no Dose\u0022, getVectorFromCol \u002213 mg\u0022\n\n// Transforming our data into a chart.\nlet visualizePairedData = \n    Seq.zip dataCaffeineNoDose dataCaffeine13mg\n    |\u003E Seq.mapi (fun i (control,treatment) -\u003E \n        let participant = \u0022Person \u0022 \u002B string i \n        Chart.Line([\u0022no dose\u0022, control; \u002213 mg\u0022, treatment], Name = participant)\n        )\n    |\u003E Chart.combine\n    |\u003E Chart.withXAxisStyle \u0022\u0022\n    |\u003E Chart.withYAxisStyle(\u0022endurance performance\u0022, MinMax = (0.,100.))\n\n(**\n\n\n*)\n\n(*** condition: ipynb ***)\n#if IPYNB\nvisualizePairedData\n#endif // IPYNB\n\n(***hide***)\nvisualizePairedData |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n\n\nThe function for pairwise t-tests can be found at \u0060FSharp.Stats.Testing.TTest.twoSamplePaired\u0060. Note, that the order of the elements in each vector must be the same, so that a pairwise comparison can be performed.\n\n*)\n\nlet twoSamplePairedResult = TTest.twoSamplePaired dataCaffeineNoDose dataCaffeine13mg\n\n(*** include-value:twoSamplePairedResult ***)\n\n(**\n\nThe two-sample paired t-test suggests a significant difference beween caffeine and non-caffeine treatment groups with a p-value of 0.012. \n\n*)"},{"uri":"https://fslab.org/index.html","title":"This is not the page you are looking for.\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: -\ncategory: hidden\nauthors: -\nindex: 0\n---\n*)\n\n(**\n# This is not the page you are looking for.\n\nWhoops! please tell us how you got here. You are most likely looking for this page: https://fslab.org/tutorials.html\n*)"},{"uri":"https://fslab.org/introductionI.html","title":"F# Introduction I: Setting up an environment\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: F# Introduction I: Setting up an environment\ncategory: fsharp\nauthors: Jonathan Ott\nindex: 1\n---\n*)\n(**\n# F# Introduction I: Setting up an environment\n\n## Installing Visual Studio Code\n\n* Download the recommended [.NET SDK](https://dotnet.microsoft.com/download) for your operating system and install it.\n    * By Selecting [All .NET downloads](https://dotnet.microsoft.com/download/dotnet) you can between installers for different operating systems.  \n\n    ![]({{root}}images/DotnetSDK.png)\n\n* Download the latest stable build of [Visual Studio Code](https://code.visualstudio.com/) for your operating system and install it.  \n\n    ![]({{root}}images/VSCode.png)\n\n* Open Visual Studio Code, navigate to the \u0022Extensions\u0022 tab and install \u0022Ionide-fsharp\u0022  \n\n    ![]({{root}}images/IonideVSCode.png)\n\n## Installing Visual Studio\n\n### Windows\n\n* Download the desired version of [Visual Studio](https://visualstudio.microsoft.com/downloads/?utm_medium=microsoft\u0026utm_source=docs.microsoft.com\u0026utm_campaign=inline\u002Blink\u0026utm_content=download\u002Bvs2019)  \n\n    ![]({{root}}images/VSWindows.png)\n\n* When executing the installer select \u0022.NET desktop development\u0022 under workloads and make sure \u0022F# desktop language support\u0022 is ticked as well on the right side.  \n\n    ![]({{root}}images/VSInstaller.png)\n\n* Select any other workloads or individual components you are interested in and start the installation.\n\n### macOS\n\n* Download Visual Studio for Mac [Visual Studio](https://visualstudio.microsoft.com/downloads/?utm_medium=microsoft\u0026utm_source=docs.microsoft.com\u0026utm_campaign=inline\u002Blink\u0026utm_content=download\u002Bvs2019)  \n\n    ![]({{root}}images/VSMac.png)\n\n* Run the Installer. F# is installed by default.\n*)"},{"uri":"https://fslab.org/002_clustering_kMeans.html","title":"Clustering with FSharp.Stats I: k-means\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Clustering with FSharp.Stats I: k-means\ncategory: datascience\nauthors: Benedikt Venn\nindex: 1\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: Deedle, 2.5.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: Newtonsoft.Json, 13.0.1\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: Deedle, 2.5.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: Newtonsoft.Json, 13.0.1\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n#endif // IPYNB\n\n(**\n\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath=content/tutorials/{{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n\n# Clustering with FSharp.Stats I: k-means\n\n_Summary:_ This tutorial demonstrates k means clustering with FSharp.Stats and how to visualize the results with Plotly.NET.\n\n## Introduction\n\nClustering methods can be used to group elements of a huge data set based on their similarity. Elements sharing similar properties cluster together and can be reported as coherent group.\nk-means clustering is a frequently used technique, that segregates the given data into k clusters with similar elements grouped in each cluster, but high variation between the clusters.\nThe algorithm to cluster a n-dimensional dataset can be fully described in the following 4 steps:\n\n  1. Initialize k n-dimensional centroids, that are randomly distributed over the data range.\n  2. Calculate the distance of each point to all centroids and assign it to the nearest one.\n  3. Reposition all centroids by calculating the average point of each cluster.\n  4. Repeat step 2-3 until convergence.\n\n### Centroid initiation\n\nSince the random initiation of centroids may influences the result, a second initiation algorithm is proposed (_cvmax_), that extract a set of medians from the dimension with maximum variance to initialize the centroids. \n\n### Distance measure\n\nWhile several distance metrics can be used (e.g. Manhattan distance or correlation measures) it is preferred to use Euclidean distance.\nIt is recommended to use a squared Euclidean distance. To not calculate the square root does not change the result but saves computation time.\n\n\u003Cimg style=\u0022max-width:75%\u0022 src=\u0022../../images/kMeans.png\u0022\u003E\u003C/img\u003E\n\n\u003Cbr\u003E\n\n\nFor demonstration of k-means clustering, the classic iris data set is used, which consists of 150 records, each of which contains four measurements and a species identifier.\n\n## Referencing packages\n\n\u0060\u0060\u0060fsharp\n// Packages hosted by the Fslab community\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n// third party .net packages \n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\u0060\u0060\u0060\n\n*)\n\n(**\n## Loading data\n*)\nopen FSharp.Data\nopen Deedle\n\n// Retrieve data using the FSharp.Data package and read it as dataframe using the Deedle package\nlet rawData = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/iris.csv\u0022\nlet df = Frame.ReadCsvString(rawData)\n\ndf.Print()\n\n(*** include-output ***)\n\n(**\n\nLet\u0027s take a first look at the data with heatmaps using Plotly.NET. Each of the 150 records consists of four measurements and a species identifier. \nSince the species identifier occur several times (_Iris-virginica_, _Iris-versicolor_, and _Iris-setosa_), we create unique labels by adding the rows index to the species identifier.\n\n*)\nopen Plotly.NET\n\nlet colNames = [\u0022sepal_length\u0022;\u0022sepal_width\u0022;\u0022petal_length\u0022;\u0022petal_width\u0022]\n\n// isolate data as float [] []\nlet data = \n    Frame.dropCol \u0022species\u0022 df\n    |\u003E Frame.toJaggedArray\n\n//isolate labels as seq\u003Cstring\u003E\nlet labels = \n    Frame.getCol \u0022species\u0022 df\n    |\u003E Series.values\n    |\u003E Seq.mapi (fun i s -\u003E sprintf \u0022%s_%i\u0022 s i)\n\nlet dataChart = \n    Chart.Heatmap(data,colNames=colNames,rowNames=labels)\n    // required to fit the species identifier on the left side of the heatmap\n    |\u003E Chart.withMarginSize(Left=100.)\n    |\u003E Chart.withTitle \u0022raw iris data\u0022\n\n// required to fit the species identifier on the left side of the heatmap\n\n(*** condition: ipynb ***)\n#if IPYNB\ndataChart\n#endif // IPYNB\n\n(***hide***)\ndataChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n## Clustering\n\nThe function that performs k-means clustering can be found at \u0060FSharp.Stats.ML.Unsupervised.IterativeClustering.kmeans\u0060. It requires four input parameters:\n\n  1. Centroid initiation method\n  2. Distance measure (from \u0060FSharp.Stats.ML.DistanceMetrics\u0060)\n  3. Data to cluster as \u0060float [] []\u0060, where each entry of the outer array is a sequence of coordinates\n  4. _k_, the number of clusters that are desired\n\n\n*)\n\nopen FSharp.Stats\nopen FSharp.Stats.ML\nopen FSharp.Stats.ML.Unsupervised\n\n// For random cluster initiation use randomInitFactory:\nlet rnd = System.Random()\nlet randomInitFactory : IterativeClustering.CentroidsFactory\u003Cfloat []\u003E = \n    IterativeClustering.randomCentroids\u003Cfloat []\u003E rnd\n\n// For assisted cluster initiation use cvmaxFactory:\n//let cvmaxFactory : IterativeClustering.CentroidsFactory\u003Cfloat []\u003E = \n//    IterativeClustering.intitCVMAX\n\nlet distanceFunction = DistanceMetrics.euclideanNaNSquared\n  \nlet kmeansResult = \n    IterativeClustering.kmeans distanceFunction randomInitFactory data 4\n\n\n(**\nAfter all centroids are set, the affiliation of a datapoint to a cluster can be determined by minimizing the distance of the respective point to each of the centroids.\nA function realizing the mapping is integrated in the \u0060kmeansResult\u0060.\n\n*)\n\nlet clusteredIrisData =\n    Seq.zip labels data\n    |\u003E Seq.map (fun (species,dataPoint) -\u003E \n        let clusterIndex,centroid = kmeansResult.Classifier dataPoint\n        clusterIndex,species,dataPoint)\n\n// Each datapoint is given associated with its cluster index, species identifier, and coordinates.\n\n(*** condition: ipynb ***)\n#if IPYNB\nclusteredIrisData\n|\u003E Seq.take 10\n|\u003E Seq.map (fun (a,b,c) -\u003E sprintf \u0022%i, %A, %A\u0022 a b c)\n|\u003E String.concat \u0022\\n\u0022\n|\u003E fun x -\u003E x \u002B \u0022\\n... \u0022\n#endif // IPYNB\n\n(***hide***)\nlet printClusters=\n    clusteredIrisData\n    |\u003E Seq.take 7\n    |\u003E Seq.map (fun (a,b,c) -\u003E sprintf \u0022%i, %A, %A\u0022 a b c)\n    |\u003E String.concat \u0022\\n\u0022\n    |\u003E fun x -\u003E x \u002B \u0022\\n ... \u0022\n\n(*** include-value:printClusters ***)\n(**\n\n## Visualization of the clustering result as heatmap\n\nThe datapoints are sorted according to their associated cluster index and visualized in a combined heatmap.\n*)\n\nlet clusterChart =\n    clusteredIrisData\n    //sort all data points according to their assigned cluster number\n    |\u003E Seq.sortBy (fun (clusterIndex,label,dataPoint) -\u003E clusterIndex)\n    |\u003E Seq.unzip3\n    |\u003E fun (_,labels,d) -\u003E \n        Chart.Heatmap(d,colNames=colNames,rowNames=labels)\n        // required to fit the species identifier on the left side of the heatmap\n        |\u003E Chart.withMarginSize(Left=100.)\n        |\u003E Chart.withTitle \u0022clustered iris data (k-means clustering)\u0022\n(**\n\n*)\n(*** condition: ipynb ***)\n#if IPYNB\nclusterChart\n#endif // IPYNB\n\n(***hide***)\nclusterChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n\nTo visualize the result in a three-dimensional chart, three of the four measurements are isolated after clustering and visualized as 3D-scatter plot.\n\n*)\n\nlet clusterChart3D =\n    //group clusters\n    clusteredIrisData\n    |\u003E Seq.groupBy (fun (clusterIndex,label,dataPoint) -\u003E clusterIndex)\n    //for each cluster generate a scatter plot\n    |\u003E Seq.map (fun (clusterIndex,cluster) -\u003E \n        cluster\n        |\u003E Seq.unzip3\n        |\u003E fun (clusterIndex,label,data) -\u003E \n            let clusterName = sprintf \u0022cluster %i\u0022 (Seq.head clusterIndex)\n            //for 3 dimensional representation isolate sepal length, petal length, and petal width\n            let truncData = data |\u003E Seq.map (fun x -\u003E x.[0],x.[2],x.[3]) \n            Chart.Scatter3D(truncData,mode=StyleParam.Mode.Markers,Name = clusterName,MultiText=label)\n        )\n    |\u003E Chart.combine\n    |\u003E Chart.withTitle \u0022isolated coordinates of clustered iris data (k-means clustering)\u0022\n    |\u003E Chart.withXAxisStyle colNames.[0]\n    |\u003E Chart.withYAxisStyle colNames.[2]\n    |\u003E Chart.withZAxisStyle colNames.[3]\n\n(**\n\n*)\n(*** condition: ipynb ***)\n#if IPYNB\nclusterChart3D\n#endif // IPYNB\n\n(***hide***)\nclusterChart3D |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n\n### Optimal cluster number\n\nThe identification of the optimal cluster number _k_ in terms of the average squared distance of each point to its centroid \ncan be realized by performing the clustering over a range of _k_\u0027s multiple times and taking the _k_ according to the elbow criterion.\nFurther more robust and advanced cluster number determination techniques can be found [here](https://fslab.org/FSharp.Stats/Clustering.html#Determining-the-optimal-number-of-clusters).\n\n*)\n\nlet getBestkMeansClustering bootstraps k =\n    let dispersions =\n        Array.init bootstraps (fun _ -\u003E \n            IterativeClustering.kmeans distanceFunction randomInitFactory data k\n            )\n        |\u003E Array.map (fun clusteringResult -\u003E IterativeClustering.DispersionOfClusterResult clusteringResult)\n    Seq.mean dispersions,Seq.stDev dispersions\n\nlet iterations = 10\n\nlet maximalK = 10\n\nlet bestKChart = \n    [2 .. maximalK] \n    |\u003E List.map (fun k -\u003E \n        let mean,stdev = getBestkMeansClustering iterations k\n        k,mean,stdev\n        )\n    |\u003E List.unzip3\n    |\u003E fun (ks,means,stdevs) -\u003E \n        Chart.Line(ks,means)\n        |\u003E Chart.withYErrorStyle(stdevs)\n        |\u003E Chart.withXAxisStyle \u0022k\u0022\n        |\u003E Chart.withYAxisStyle \u0022average dispersion\u0022\n        |\u003E Chart.withTitle \u0022iris data set average dispersion per k\u0022\n(**\n\n*)\n(*** condition: ipynb ***)\n#if IPYNB\nbestKChart\n#endif // IPYNB\n\n(***hide***)\nbestKChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n\n\n## Limitations\n\n  1. Outlier have a strong influence on the positioning of the centroids. \n  2. Determining the correct number of clusters in advance is critical. Often it is chosen according to the number of classes present in the dataset which isn\u0027t in the spirit of clustering procedures.\n\n## Notes\n\n  - Please note that depending on what data you want to cluster, a column wise z-score normalization may be required. In the presented example differences in sepal width have a reduced influence because\n  the absolute variation is low.\n\n## References\n\n  - FSharp.Stats documentation, fslaborg, https://fslab.org/FSharp.Stats/Clustering.html\n  - Shraddha and Saganna, A Review On K-means Data Clustering Approach, International Journal of Information \u0026 Computation Technology, Vol:4 No:17, 2014\n  - Moth\u0027d Belal, A New Algorithm for Cluster Initialization, International Journal of Computer and Information Engineering, Vol:1 No:4, 2007\n  - Singh et al., K-means with Three different Distance Metrics, International Journal of Computer Applications, 2013, DOI:10.5120/11430-6785\n  - Kodinariya and Makwana, Review on Determining of Cluster in K-means Clustering, International Journal of Advance Research in Computer Science and Management Studies, 2013\n\n## Further reading\n  \nExamples are taken from [FSharp.Stats documentation](https://fslab.org/FSharp.Stats/Clustering.html) that covers various techniques for an optimal cluster number determination.\n  \nThe next article in this series covers [hierarchical clustering using FSharp.Stats](003_clustering_hierarchical.html).\n\n*)\n\n\n"},{"uri":"https://fslab.org/001_getting-started.html","title":"Getting started\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Getting started\ncategory: datascience\nauthors: David Zimmer\nindex: 0\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: Deedle, 2.5.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: Newtonsoft.Json, 13.0.1\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: Deedle, 2.5.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: Newtonsoft.Json, 13.0.1\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n#endif // IPYNB\n\n(**\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath=content/tutorials/{{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n# Getting started\n\nGlad to see you here! Now that you found out and learned about FsLab, this section aims to illustrate how FsLab packages synergize and can be used to tackle practical data science challenges. Note that every package used througout the tutorial has its own documentation so if you are interested in Deedle, FSharp.Stats or Plotly.Net feel free to take a deeper dive.\n\n## Referencing packages\n\nFsLab is meant to be a project incubation space and can be thought of as a safe heaven for both, package developers and package users, by providing guidelines and tutorials. Packages provided by the community can be used on their own, in combination with other FsLab packages but also in combination with any other .netstandard 2.0 compatible package. From F# 5.0 on packages can be referenced using the following notation:\n\n\u0060\u0060\u0060fsharp\n// Packages hosted by the Fslab community\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n// third party .net packages \n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\u0060\u0060\u0060\n\nAfter referencing the packages, one can access their namespaces and use provided functions. In the following example we will reference the top level namespaces and then use a function provided by the FSharp.Stats package to calculate a factorial:\n*)\nopen FSharp.Stats\n\nlet factorialOf3 = SpecialFunctions.Factorial.factorial 3\n\n(*** condition: ipynb ***)\n#if IPYNB\nfactorialOf3\n#endif // IPYNB\n\n(***include-value:factorialOf3***)\n\n(**\n## Data access\nEquipped with these packages, we are now ready to tackle promises made in the first paragraph: solving a practical data science problem. \n\nWe will start by retrieving the data using the FSharp.Data package. Subsequently we will use Deedle, a powerful data frame library that makes tabular data accessible by data frame programming. (Note that the chosen names give insight on their type, however thanks to FSharp being a strongly typed language we can hover over any single value at any time to see the assigned type.)\n*)\nopen FSharp.Data\nopen Deedle\n\n// Retrieve data using the FSharp.Data package\nlet rawData = Http.RequestString @\u0022https://raw.githubusercontent.com/dotnet/machinelearning/master/test/data/housing.txt\u0022\n\n// And create a data frame object using the ReadCsvString method provided by Deedle.\n// Note: Of course you can directly provide the path to a local source.\nlet df = Frame.ReadCsvString(rawData,hasHeaders=true,separators=\u0022\\t\u0022)\n\n// Using the Print() method, we can use the Deedle pretty printer to have a look at the data set.\ndf.Print()\n\n(*** include-output ***)\n\n(**\n## Data crunching\nThe data set of choice is the Boston housing data set. As you can see from analyzing the printed output, it consists of 506 rows. Each row represents a house in the boston city area and each column encodes a feature/variable, such as the number of rooms per dwelling (RoomsPerDwelling), the median value of owner-occupied homes in $1000\u0027s (MedianHomeValue) and even variables indicating if the house is bordering river Charles (CharlesRiver, value = 1) or not (CharlesRiver, value = 0). \n\nLets consider in our analysis that we are only interested in the variables just described, furthermore we only want to keep rows where the value of the indicator variable is 0. We can use Deedle to easily create a new frame that fullfills our criteria. In this example we\u0027ll also cast the value of the column \u0022CharlesRiver\u0022 to be of type bool, this illustrates how data frame programming can become typesafe using Deedle.\n*)\n\nlet housesNotAtRiver = \n    df\n    |\u003E Frame.sliceCols [\u0022RoomsPerDwelling\u0022;\u0022MedianHomeValue\u0022;\u0022CharlesRiver\u0022]\n    |\u003E Frame.filterRowValues (fun s -\u003E s.GetAs\u003Cbool\u003E(\u0022CharlesRiver\u0022) |\u003E not ) \n\n//sprintf \u0022The new frame does now contain: %i rows and %i columns\u0022 housesNotAtRiver.RowCount housesNotAtRiver.ColumnCount\n\nhousesNotAtRiver.Print()\n\n(*** include-output ***)\n\n(**\n## Data exploration\n\nExploratory data analysis is an approach favored by many - to meet this demand we strongly advertise the use of Plotly.Net. The following snippet illustrates how we can access a column of a data frame and create an interactive chart in no time. Since we might want to get an idea of the distribution of the house prices, a histogram can come in handy: \n*)\nopen Plotly.NET\n\n// Note that we explicitly specify that we want to work with the values as floats. \n// Since the row identity is not needed anymore when plotting the distribution we can\n// directly convert the collection to a FSharp Sequence. \nlet pricesNotAtRiver : seq\u003Cfloat\u003E = \n    housesNotAtRiver\n    |\u003E Frame.getCol \u0022MedianHomeValue\u0022\n    |\u003E Series.values\n    \nlet h1 = \n    Chart.Histogram(pricesNotAtRiver)\n    |\u003E Chart.withXAxisStyle(\u0022median value of owner occupied homes in 1000s\u0022)\n    |\u003E Chart.withXAxisStyle(\u0022price distribution\u0022)\n\n(*** condition: ipynb ***)\n#if IPYNB\nh1\n#endif // IPYNB\n\n(***hide***)\nh1 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\nSince plotly charts are interactive they invite us to combine mutliple charts. Let repeat the filter step and see if houses that are located at the river show a similar distribution:\n*)\n\nlet housesAtRiver = \n    df\n    |\u003E Frame.sliceCols [\u0022RoomsPerDwelling\u0022;\u0022MedianHomeValue\u0022;\u0022CharlesRiver\u0022]\n    |\u003E Frame.filterRowValues (fun s -\u003E s.GetAs\u003Cbool\u003E(\u0022CharlesRiver\u0022))\n\nlet pricesAtRiver : seq\u003Cfloat\u003E = \n    housesAtRiver\n    |\u003E Frame.getCol \u0022MedianHomeValue\u0022\n    |\u003E Series.values\n\nlet h2 =     \n    [\n        Chart.Histogram(pricesNotAtRiver)\n        |\u003E Chart.withTraceName \u0022not at river\u0022\n        Chart.Histogram(pricesAtRiver)\n        |\u003E Chart.withTraceName \u0022at river\u0022\n    ]\n    |\u003E Chart.combine\n    |\u003E Chart.withXAxisStyle(\u0022median value of owner occupied homes in 1000s\u0022)\n    |\u003E Chart.withXAxisStyle(\u0022Comparison of price distributions\u0022)\n\n(***hide***)\nh2 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\nThe interactive chart allows us to compare the distributions directly. We can now reconstruct our own idea of the city of Boston, the sampled area, just by looking at the data e.g.:\n\nAssuming that the sampling process was homogenous while observing that there are much more houses sampled that are not located on the riverside could indicate that a spot on the river is a scarce commodity.\nThis could also be backed by analyzing the tails of the distribution: it seems that houses located at the river are given a head-start in their assigned value - the distribution of the riverside houses is truncated on the left. \n\nSuppose we would have a customer that wants two models, one to predict the prices of a house at the riverside and one that predicts the prices if this is not the case, then we can meet this demand by using FSharp.Stats in combination with Deedle. \n\nOf course we need a variable that is indicative of the house price, in this case we will check if the number of rooms per dwelling correlates with the house value:\n*)\n\nlet pricesAll :Series\u003Cint,float\u003E = \n    df\n    |\u003E Frame.getCol \u0022MedianHomeValue\u0022\n\nlet roomsPerDwellingAll :Series\u003Cint,float\u003E = \n    df\n    |\u003E Frame.getCol \u0022RoomsPerDwelling\u0022   \n\nlet correlation = \n    let tmpPrices,tmpRooms = \n        Series.zipInner pricesAll roomsPerDwellingAll    \n        |\u003E Series.values \n        |\u003E Seq.unzip\n    Correlation.Seq.pearson tmpPrices tmpRooms\n                                              \n(***include-value:correlation***)\n\n(**\nSo indeed, the number of rooms per dwelling shows a positive correlation with the house prices. With a pearson correlation of ~0.7 it does not explain the house prices completely - but this is nothing that really surprises us, as one of our hypothesis is that the location (e.g. riverside) does also have influence on the price -  however, it should be sufficient to create a linear model. \n\nNow we will use FSharp.Stats to build the two linear models ordered by the hypothetical customer. We start by defining a function that performs the fitting and plots the result:\n*)\n\nopen Fitting.LinearRegression.OrdinaryLeastSquares\n\nlet predictPricesByRooms description data = \n    let pricesAll :Series\u003C_,float\u003E = \n        data\n        |\u003E Frame.getCol \u0022MedianHomeValue\u0022\n\n    let roomsPerDwellingAll :Series\u003C_,float\u003E = \n        data\n        |\u003E Frame.getCol \u0022RoomsPerDwelling\u0022   \n\n    let fit = \n        let tmpRooms, tmpPrices = \n            Series.zipInner roomsPerDwellingAll pricesAll    \n            |\u003E Series.sortBy fst\n            |\u003E Series.values \n            |\u003E Seq.unzip\n        let coeffs = Linear.Univariable.coefficient (vector tmpRooms) (vector tmpPrices)\n        let model  = Linear.Univariable.fit coeffs \n        let predictedPrices = tmpRooms |\u003E Seq.map model\n        [\n            Chart.Point(tmpRooms,tmpPrices)\n            |\u003E Chart.withTraceName (sprintf \u0022%s: data\u0022 description )\n            Chart.Line(tmpRooms,predictedPrices)\n            |\u003E Chart.withTraceName (sprintf \u0022%s: coefficients: intercept:%f, slope:%f\u0022 description coeffs.[0] coeffs.[1])\n        ]                                  \n        |\u003E Chart.combine\n        |\u003E Chart.withXAxisStyle(\u0022rooms per dwelling\u0022)\n        |\u003E Chart.withYAxisStyle(\u0022median value\u0022)\n    fit   \n\n(**\nAfterwards, we can apply the function on our prepared datasets and have a look at the model, especially the model coefficients. \n*)\nlet modelVis = \n    [\n        predictPricesByRooms \u0022not at river\u0022 housesNotAtRiver\n        predictPricesByRooms \u0022at river\u0022 housesAtRiver\n    ]\n    |\u003E Chart.combine\n    |\u003E Chart.withSize(1200.,700.)\n\n(***hide***)\nmodelVis |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n(**\nBoth models approximate the data in a reasonable way. When we inspect the coefficients, we see that the models only differ slightly in slope, but have an absolute offset of ~7.5. This observation complements the insights gained by the explorative data analysis approach using the histogram! \n*)"},{"uri":"https://fslab.org/004_clustering_DBSCAN.html","title":"Clustering with FSharp.Stats III: DBSCAN\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Clustering with FSharp.Stats III: DBSCAN\ncategory: datascience\nauthors: Benedikt Venn\nindex: 2\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: Deedle, 2.5.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: Newtonsoft.Json, 13.0.1\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: Deedle, 2.5.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: Newtonsoft.Json, 13.0.1\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n#endif // IPYNB\n\n(**\n\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath=content/tutorials/{{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n\n# Clustering with FSharp.Stats III: DBSCAN\n\n_Summary:_ This tutorial demonstrates DBSCAN with FSharp.Stats and how to visualize the results with Plotly.NET.\n\nIn the previous article of this series [hierarchical clustering using FSharp.Stats](003_clustering_hierarchical.html) was introduced.\n\n## Introduction\n\nClustering methods can be used to group elements of a huge data set based on their similarity. Elements sharing similar properties cluster together and can be reported as coherent group.\nDensity-Based Spatial Clustering of Applications with Noise (DBSCAN) was developed to identify clusters with similar density and allows the exclusion of noise points.\n\n### Two global parameters have to be defined:\n\n  - **\u03B5 (eps)**: radius in which the neighbourhood of each point is checked \n  - **minPts**: minimal number of data points, that must fall into the neighbourhood of a region to be defined as dense\n\n### Data points are classified as:\n\n  - **Core point**: Within a radius of eps there are more (or equal) data points than minPts present.\n  - **Border point**: Within a radius of eps there are less data points than minPts present, but a core point is within the neighbourhood.\n  - **Noise point**: None of the conditions above apply.\n\n\u003Cimg style=\u0022max-width:75%\u0022 src=\u0022../../images/dbscan.png\u0022 class=\u0022center\u0022\u003E\u003C/img\u003E\n\n\u003Cbr\u003E\n\nFor demonstration of DBSCAN, the classic iris data set is used, which consists of 150 records, each of which contains four measurements and a species identifier.\nIn this tutorial we are going to perform DBSCAN on two- and three-dimensional data.\n\n## Referencing packages\n\n\u0060\u0060\u0060fsharp\n// Packages hosted by the Fslab community\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n// third party .net packages \n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\u0060\u0060\u0060\n\n*)\n\n(**\n## Loading data\n*)\nopen FSharp.Data\nopen FSharp.Stats\nopen Deedle\n\n// Retrieve data using the FSharp.Data package and read it as dataframe using the Deedle package\nlet rawData = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/iris.csv\u0022\nlet df = Frame.ReadCsvString(rawData)\n\ndf.Print()\n\n\n(*** include-output ***)\n\n(**\n\nLet\u0027s take a first look at the data with 2D and 3D scatter plots using Plotly.NET. Each of the 150 records consists of four measurements and a species identifier. \nSince the species identifier occur several times (Iris-virginica, Iris-versicolor, and Iris-setosa), we create unique labels by adding the rows index to the species identifier.\n\n*)\nopen Plotly.NET\nopen FSharp.Stats.ML.Unsupervised\n\nlet header2D = [\u0022petal_length\u0022;\u0022petal_width\u0022]\nlet header3D = [\u0022sepal_length\u0022;\u0022petal_length\u0022;\u0022petal_width\u0022]\n\n//extract petal length and petal width\nlet data2D = \n    Frame.sliceCols header2D df\n    |\u003E Frame.toJaggedArray\n\n//extract sepal length, petal length, and petal width\nlet data3D = \n    Frame.sliceCols header3D df\n    |\u003E Frame.toJaggedArray\n\nlet labels = \n    Frame.getCol \u0022species\u0022 df\n    |\u003E Series.values\n    |\u003E Seq.mapi (fun i s -\u003E sprintf \u0022%s_%i\u0022 s i)\n\nlet rawChart2D =\n    let unzippedData =\n        data2D\n        |\u003E Array.map (fun x -\u003E x.[0],x.[1])\n    Chart.Scatter(unzippedData,mode=StyleParam.Mode.Markers,MultiText=labels)\n    |\u003E Chart.withXAxisStyle header2D.[0]\n    |\u003E Chart.withYAxisStyle header2D.[1]\n    |\u003E Chart.withTitle \u0022rawChart2D\u0022\n\nlet rawChart3D =\n    let unzippedData =\n        data3D\n        |\u003E Array.map (fun x -\u003E x.[0],x.[1],x.[2])\n    Chart.Scatter3D(unzippedData,mode=StyleParam.Mode.Markers,MultiText=labels)\n    |\u003E Chart.withXAxisStyle header3D.[0]\n    |\u003E Chart.withYAxisStyle header3D.[1]\n    |\u003E Chart.withZAxisStyle header3D.[2]\n    |\u003E Chart.withTitle \u0022rawChart3D\u0022\n\n\n(*** condition: ipynb ***)\n#if IPYNB\nrawChart2D\n#endif // IPYNB\n\n(***hide***)\nrawChart2D |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\u003Cbr\u003E\n*)\n\n(*** condition: ipynb ***)\n#if IPYNB\nrawChart3D\n#endif // IPYNB\n\n(***hide***)\nrawChart3D |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n(**\n## Clustering\n\nThe function that performs DBSCAN can be found at \u0060FSharp.Stats.ML.Unsupervised.DbScan.compute\u0060. It requires four input parameters:\n\n  1. Distance measure (\u0060from FSharp.Stats.ML.DistanceMetrics\u0060) (\u0060seq\u003C\u0027T\u003E -\u003E seq\u003C\u0027T\u003E -\u003E float\u0060)\n  1. minPts (\u0060int\u0060)\n  3. eps (\u0060float\u0060)\n  4. data points as sequence of coordinate sequences (\u0060seq\u003C#seq\u003C\u0027T\u003E\u003E\u0060)\n\nThe clustering result consists of a sequence of noise point coordinates and a sequence of clusters containing all related point coordinates.\n\n*)\nopen FSharp.Stats.ML\nopen FSharp.Stats.ML.Unsupervised\n\n\nlet eps2D = 0.5\nlet eps3D = 0.7\n\nlet minPts = 20\n\nlet result2D = DbScan.compute DistanceMetrics.Array.euclidean minPts eps2D data2D\n\n(***hide***)\nlet printClusters2D = result2D.ToString()\n(*** include-value:printClusters2D ***)\n\nlet result3D = DbScan.compute DistanceMetrics.Array.euclidean minPts eps3D data3D\n\n(***hide***)\nlet printClusters3D = result3D.ToString()\n\n(*** include-value:printClusters3D ***)\n\n(**\n## Visualization of clustering result\n\nTo visualize the clustering result coordinates of each cluster and noise points are visualized separately and combined in a single scatter plot.\n\n### 2D clustering result visualization\n\n*)\n\n\n//to create a chart with two dimensional data use the following function\n    \nlet chartCluster2D = \n    result2D.Clusterlist\n    |\u003E Seq.mapi (fun i l -\u003E\n        l\n        |\u003E Seq.map (fun x -\u003E x.[0],x.[1])\n        |\u003E Seq.distinct //more efficient visualization; no difference in plot but in point numbers\n        |\u003E Chart.Point\n        |\u003E Chart.withTraceName (sprintf \u0022Cluster %i\u0022 i))\n    |\u003E Chart.combine\n\nlet chartNoise2D = \n    result2D.Noisepoints\n    |\u003E Seq.map (fun x -\u003E x.[0],x.[1])  \n    |\u003E Seq.distinct //more efficient visualization; no difference in plot but in point numbers\n    |\u003E Chart.Point\n    |\u003E Chart.withTraceName \u0022Noise\u0022\n\nlet chartTitle2D = \n    let noiseCount   = result2D.Noisepoints |\u003E Seq.length\n    let clusterCount = result2D.Clusterlist |\u003E Seq.length\n    let clPtsCount   = result2D.Clusterlist |\u003E Seq.sumBy Seq.length\n    $\u0022eps: %.1f{eps2D} minPts: %i{minPts} pts: %i{noiseCount \u002B clPtsCount} cluster: %i{clusterCount} noisePts: %i{noiseCount}\u0022 \n\nlet chart2D =\n    [chartNoise2D;chartCluster2D]\n    |\u003E Chart.combine\n    |\u003E Chart.withTitle chartTitle2D\n    |\u003E Chart.withXAxisStyle header2D.[0]\n    |\u003E Chart.withYAxisStyle header2D.[1]\n\n(*** condition: ipynb ***)\n#if IPYNB\nchart2D\n#endif // IPYNB\n\n(***hide***)\nchart2D |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n### 3D clustering result visualization\n\n\n\n*)\n\n\nlet chartCluster3D = \n    result3D.Clusterlist\n    |\u003E Seq.mapi (fun i l -\u003E\n        l\n        |\u003E Seq.map (fun x -\u003E x.[0],x.[1],x.[2])\n        |\u003E Seq.distinct //faster visualization; no difference in plot but in point number\n        |\u003E fun x -\u003E Chart.Scatter3D (x,StyleParam.Mode.Markers)\n        |\u003E Chart.withTraceName (sprintf \u0022Cluster_%i\u0022 i))\n    |\u003E Chart.combine\n\nlet chartNoise3D =\n    result3D.Noisepoints\n    |\u003E Seq.map (fun x -\u003E x.[0],x.[1],x.[2])  \n    |\u003E Seq.distinct //faster visualization; no difference in plot but in point number\n    |\u003E fun x -\u003E Chart.Scatter3D (x,StyleParam.Mode.Markers)\n    |\u003E Chart.withTraceName \u0022Noise\u0022\n\nlet chartname3D = \n    let noiseCount   = result3D.Noisepoints |\u003E Seq.length\n    let clusterCount = result3D.Clusterlist |\u003E Seq.length\n    let clPtsCount   = result3D.Clusterlist |\u003E Seq.sumBy Seq.length\n    $\u0022eps: %.1f{eps3D} minPts: %i{minPts} pts: %i{noiseCount \u002B clPtsCount} cluster: %i{clusterCount} noisePts: %i{noiseCount}\u0022 \n   \nlet chart3D = \n    [chartNoise3D;chartCluster3D]\n    |\u003E Chart.combine\n    |\u003E Chart.withTitle chartname3D\n    |\u003E Chart.withXAxisStyle header3D.[0]\n    |\u003E Chart.withYAxisStyle header3D.[1]\n    |\u003E Chart.withZAxisStyle header3D.[2]\n    \n//for faster computation you can use the squaredEuclidean distance and set your eps to its square\nlet clusteredChart3D() = DbScan.compute DistanceMetrics.Array.euclideanNaNSquared 20 (0.7**2.) data3D \n\n\n(*** condition: ipynb ***)\n#if IPYNB\nchart3D\n#endif // IPYNB\n\n(***hide***)\nchart3D |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n\n## Limitations\n\n  1. The selection of minPts and eps is critical and even small deviations can severely influence the final results\n  2. When data points are of varying density, DBSCAN is not appropriate\n\n## Notes\n\n  - Please note that depending on what data you want to cluster, a column wise z-score normalization may be required. In the presented example differences in sepal width have a reduced influence because\n  the absolute variation is low.\n\n## References\n\n  - [FSharp.Stats documentation](https://fslab.org/FSharp.Stats/Clustering.html), fslaborg, \n  - Shinde and Sankhe, Comparison of Enhanced DBSCAN Algorithms: A Review, International Journal of Engeneering Research \u0026 Technology, 2017\n  - Nagaraju et al., An effective density based approach to detect complex data clusters using notion of neighborhood difference, Int. J. Autom. Comput., 2017, https://doi.org/10.1007/s11633-016-1038-7 \n\n*)\n\n"},{"uri":"https://fslab.org/introductionII.html","title":"F# Introduction II: Scripting in F#\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: F# Introduction II: Scripting in F#\ncategory: fsharp\nauthors: Jonathan Ott\nindex: 2\n---\n*)\n(**\n# F# Introduction II: Scripting in F#\n\n## Creating a .fsx file\n\n### Visual Studio\n\n* Open Visual Studio and navigate to the \u0022File\u0022 tab, where you select to create a new file.\n* Select the \u0022F# Script File\u0022 option.  \n    \n    ![]({{root}}images/FsxVS.png)\n\n* You now have a working script file. You can write code and execute it by selecting it and pressing \u0060Alt \u002B Enter\u0060.\n\n### Visual Studio Code\n\n* Open Visual Studio Code and navigate to the \u0022File\u0022 tab, where you select to create a new file.\n* You will then be prompted to select a language. Choose F# there.  \n\n    ![]({{root}}images/FsxVSCode.png)\n\n* You now have a working script file. You can write code and execute it by selecting it and pressing \u0060Alt \u002B Enter\u0060.\n* When you are done with your file save it as .fsx.\n\n## Referencing packages\n\n* Packages on nuget can be referenced using \u0027#r \u0022nuget: PackageName\u0022\u0027:\n*)\n// References the latest stable package\n#r \u0022nuget: FSharp.Stats\u0022\n// References a sepcific package version\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.16\u0022\n(**\n* Alternatively, .dll files can be referenced directly with the following syntax:\n*)\n(***do-not-eval***)\n#r @\u0022Your\\Path\\To\\Package\\PackageName.dll\u0022\n\n(**\n## Working with notebooks\n\n* Visual Studio Code supports working with notebooks\n* To work with notebooks, you need to install the [.NET Interactive Notebooks](https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.dotnet-interactive-vscode) extension.  \n\n    ![]({{root}}images/NotebooksExt.png)\n\n* A new Notebook can be opened by pressing \u0060Ctrl \u002B Shift \u002B P\u0060 and selecting \u0022.NET Interactive: Create new blank notebook\u0022.\n* You will then be prompted to create it either as .dib or .ipynb.\n* When asked for the language, choose F#\n* Notebooks contain Text- and Codeblocks:\n* Adding a new Text- or Codeblock can be done by hovering at the upper or lower border of an existing block or upper part of the notebook and pressing \u0060\u002BCode\u0060 or \u0060\u002BMarkdown\u0060  \n\n    ![]({{root}}images/NBBlock.png)\n\n* Working with Textblocks:\n    You can edit a Textblock by doubleklicking on it. Inside a Textblock you can write plain text or style it with [Markdown](https://en.wikipedia.org/wiki/Markdown).\n    Once you are finished you can press the \u0060Esc\u0060 button.\n* Working with Codeblocks:\n    You can start editing any Codeblock by clicking in it. In there you can start writing your own code or edit existing code. Once you are done you can execute the Codeblock by pressing \u0060Ctrl \u002B Alt \u002B Enter\u0060.\n    If you want to execute all codeblocks at once, you can press on the two arrows in the upper left corner of the notebook.\n*)\n"},{"uri":"https://fslab.org/007_replicate-quality-control.html","title":"Replicate quality control\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Replicate quality control\ncategory: advanced\nauthors: Heinrich Lukas Weil    \nindex: 0\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n#r \u0022nuget: Deedle, 2.5.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: Cyjs.NET, 0.0.4\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n#r \u0022nuget: Deedle, 2.5.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: Cyjs.NET, 0.0.4\u0022\n#endif // IPYNB\n\n\n(**\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath=content/tutorials/{{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n# Replicate quality control\n\n\n_Summary:_ This tutorial demonstrates an example workflow using different FsLab libraries. The aim is to check the quality of replicate measurements by clustering the samples.\n\n\n## Introduction\n\nIn biology and other sciences, experimental procedures are often repeated several times in the same conditions. These resulting samples are called replicates. \nReplicates are especially useful to check for the reproducibility of the results and to boost their trustability.\n\nOne metric for the quality of the measurements is rather easy in principle. Samples received from a similar procedure should also result in similar measurements. \nTherefore just checking if replicates are more similar than other samples can already hand to the experimenter some implications about the quality of his samples.\nThis is especially useful when considering that usually - as the ground truth is unknown - this trustability is difficult to measure. \n\nIn this tutorial, a simple workflow will be presented for how to visualize the clustering of replicates in an experiment. For this, 3 FsLab libraries will be used:\n\n0. [FSharp.Data](https://fsprojects.github.io/FSharp.Data/) for retreiving the data file\n1. [Deedle](https://github.com/fslaborg/Deedle) for reading a frame containing the data\n2. \u0026 3. [FSharp.Stats](https://fslab.org/FSharp.Stats/) to impute missing values and cluster the samples\n4. [CyJS.NET](https://fslab.org/Cyjs.NET/) to visualize the results\n\n\n## Referencing packages\n\n\u0060\u0060\u0060fsharp\n#r \u0022nuget: FSharp.Data\u0022\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Cyjs.NET\u0022\n\ndo fsi.AddPrinter(fun (printer:Deedle.Internal.IFsiFormattable) -\u003E \u0022\\n\u0022 \u002B (printer.Format()))\n\u0060\u0060\u0060\n\n## Loading Data \n\nIn this tutorial, an in silico generated dataset is used.  \n\n\u0060FSharp.Data\u0060 and \u0060Deedle\u0060 are used to load the data into the fsi.\n\n*)\n\nopen FSharp.Data\nopen Deedle\n\n// Load the data \nlet rawData = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/InSilicoGeneExpression.csv\u0022\n\n// Create a deedle frame and index the rows with the values of the \u0022Key\u0022 column.\nlet rawFrame : Frame\u003Cstring,string\u003E = \n    Frame.ReadCsvString(rawData)\n    |\u003E Frame.indexRows \u0022Key\u0022\n\n(***hide***)\nrawFrame.Print()\n\n\n(*** include-output ***)\n\n(** \n\n## Data imputation\n\nMissing data is a constant companion of many data scientists. And it\u0027s not the best company, as missing values [can introduce a substantial amount of bias, make the handling and analysis of the data more arduous, and create reductions in efficiency](https://en.wikipedia.org/wiki/Imputation_(statistics)).\n\nTo tackle this, missing values can be substituted in a step called \u0060imputation\u0060. Different approaches for this exist. Here a k-nearest neighbour imputation is shown, which works as follows: \nFor each observation with missing values, the k most similar other observations are chosen. Then the missing value of this observation is substituted by the mean of these values in the neighbouring observations.\n\n*)\n\nopen FSharp.Stats\nopen FSharp.Stats.ML\n\n// Select the imputation method: kNearestImpute where the 2 nearest observations are considered\nlet kn : Impute.MatrixBaseImputation\u003Cfloat[],float\u003E = Impute.kNearestImpute 2\n\n// Impute the missing values using the \u0022imputeBy\u0022 function. The values of the deedle frame are first transformed into the input type of this function.\nlet imputedData = \n    rawFrame \n    |\u003E Frame.toJaggedArray \n    |\u003E Impute.imputeBy kn Ops.isNan\n\n// Creating a new frame from the old keys and the new imputed data\nlet imputedFrame = \n    Frame.ofJaggedArray imputedData\n    |\u003E Frame.indexRowsWith rawFrame.RowKeys\n    |\u003E Frame.indexColsWith rawFrame.ColumnKeys\n\n(***hide***)\nimputedFrame.Print()\n\n(*** include-output ***)\n(** \n\n## Hierarchical clustering\n\nTo sort the level of closeness between samples, we perform a hierarchical clustering. Details about this can be found [here](003_clustering_hierarchical.html) and [here](https://fslab.org/FSharp.Stats/Clustering.html#Hierarchical-clustering).\n\n*)\n\nopen FSharp.Stats.ML.Unsupervised\n\n// Retreive the sample columns from the frame\nlet samples = \n    imputedFrame\n    |\u003E Frame.getNumericCols\n    |\u003E Series.observations\n    |\u003E Seq.map (fun (k,vs) -\u003E \n        k,\n        vs\n        |\u003E Series.values\n    )\n\n// Run the hierarchical clustering on the samples\n// The clustering is performed on labeled samples (name,values) so that these labels later appear in the cluster tree\nlet clustering = \n    HierarchicalClustering.generate \n        (fun (name1,values1) (name2,values2) -\u003E DistanceMetrics.euclidean values1 values2) // perform the distance calculation only on the values, not the labels\n        HierarchicalClustering.Linker.wardLwLinker\n        samples\n    |\u003E HierarchicalClustering.mapClusterLeaftags fst // only keep the labels in the cluster tree\n\n(*** include-value:clustering ***)\n\n(** \n\n## Data visualization\n\nFinally, the clustering results can be visualized to check for replicate clustering. For this we use \u0060Cyjs.NET\u0060, an FsLab library which makes use of the \u0060Cytoscape.js\u0060 network visualization tool.\n\nFurther information about styling the graphs can be found [here](https://fslab.org/Cyjs.NET/).\n*)\n\n\nopen Cyjs.NET\n\n// Function for flattening the cluster tree to an edgelist\nlet hClustToEdgeList (f : int -\u003E \u0027T) (hClust : HierarchicalClustering.Cluster\u003C\u0027T\u003E) =\n    let rec loop (d,nodeLabel) cluster=\n        match cluster with\n        | HierarchicalClustering.Node (id,dist,_,c1,c2) -\u003E\n            let t = f id\n            loop (dist,t) c1\n            |\u003E List.append (loop (dist,t) c2)\n            |\u003E List.append [nodeLabel,t,d] \n        | HierarchicalClustering.Leaf (_,_,label)-\u003E [(nodeLabel,label,d)]\n    loop (0., f 0) hClust\n\nlet rawEdgeList = hClustToEdgeList (string) clustering\n\n// The styled vertices, samnples are coloured based on the condition they belong to. So replicates of one condition have the same colour\nlet cytoVertices = \n    rawEdgeList\n    |\u003E List.collect (fun (v1,v2,w) -\u003E\n        [v1;v2]\n    )\n    |\u003E List.distinct\n    |\u003E List.map (fun v -\u003E \n        let label,color,size = \n            match v.Split \u0027_\u0027 with\n            | [|\u0022Condition0\u0022;_|] -\u003E \u0022Condition0\u0022, \u0022#6FB1FC\u0022,\u002240\u0022\n            | [|\u0022Condition1\u0022;_|] -\u003E \u0022Condition1\u0022, \u0022#EDA1ED\u0022,\u002240\u0022\n            | [|\u0022Condition2\u0022;_|] -\u003E \u0022Condition2\u0022, \u0022#F5A45D\u0022,\u002240\u0022\n            | _ -\u003E \u0022\u0022,\u0022#DDDDDD\u0022,\u002210\u0022\n\n        let styling = [CyParam.label label; CyParam.color color; CyParam.width size]\n        Elements.node (v) styling\n    )\n\n// Helper function to transform the distances between samples to weights\nlet distanceToWeight = \n    let max = rawEdgeList |\u003E List.map (fun (a,b,c) -\u003E c) |\u003E List.max\n    fun distance -\u003E 1. - (distance / max)   \n\n\n// Styled edges\nlet cytoEdges = \n    rawEdgeList\n    |\u003E List.mapi (fun i (v1,v2,weight) -\u003E \n        let styling = [CyParam.weight (distanceToWeight weight)]\n        Elements.edge (\u0022e\u0022 \u002B string i) v1 v2 styling\n    )\n\n// Resulting cytograph\nlet cytoGraph = \n\n    CyGraph.initEmpty ()\n    |\u003E CyGraph.withElements cytoVertices\n    |\u003E CyGraph.withElements cytoEdges\n    |\u003E CyGraph.withStyle \u0022node\u0022 \n        [\n            CyParam.content =. CyParam.label\n            CyParam.shape =. CyParam.shape\n            CyParam.color =. CyParam.color\n            CyParam.width =. CyParam.width\n        ]\n    |\u003E CyGraph.withLayout (Layout.initCose (id))  \n\n(** \n\n\u0060\u0060\u0060fsharp\n// Send the cytograph to the browser\ncytoGraph\n|\u003E CyGraph.show\n\u0060\u0060\u0060\n\n*)\n\n(***hide***)\ncytoGraph\n|\u003E CyGraph.withSize(600, 400) \n|\u003E HTML.toEmbeddedHTML\n\n(*** include-it-raw ***)\n\n\n(** \n\n## Interpretation\n\nAs can be seen in the graph, replicates of one condition cluster together. This is a good sign for the quality of the experiment. \nIf one replicate of a condition does not behave this way, it can be considered an outlier.\nIf the replicates don\u0027t cluster together at all, there might be some problems with the experiment.\n\n*)"},{"uri":"https://fslab.org/003_clustering_hierarchical.html","title":"Clustering with FSharp.Stats II: hierarchical clustering\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Clustering with FSharp.Stats II: hierarchical clustering\ncategory: datascience\nauthors: Benedikt Venn\nindex: 2\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: Deedle, 2.5.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: Newtonsoft.Json, 13.0.1\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: Deedle, 2.5.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: Newtonsoft.Json, 13.0.1\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n#endif // IPYNB\n\n\n(**\n\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath=content/tutorials/{{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n# Clustering with FSharp.Stats II: hierarchical clustering\n\n_Summary:_ This tutorial demonstrates hierarchical clustering with FSharp.Stats and how to visualize the results with Plotly.NET.\n\nIn the previous article of this series [k-means clustering using FSharp.Stats](002_clustering_kMeans.html) was introduced.\n\n## Introduction\n\nClustering methods can be used to group elements of a huge data set based on their similarity. Elements sharing similar properties cluster together and can be reported as coherent group.\nMany clustering algorithms require a predefined cluster number, that has to be provided by the experimenter.\nHierarchical clustering (hClust) does not require such cluster number definition. Instead, hierarchical clustering results in a tree structure, that has a single cluster (node) on its root and recursively splits up into clusters of \nelements that are more similar to each other than to elements of other clusters. For generating multiple clustering results with different number of clusters, \nthe clustering has to performed only once. Subsequently a cluster number can be defined to split up the clustering tree in the desired number of clusters.\nThe clustering tree is often represented as dendrogram.\n\n### There are two types of hClust:\n\n  - Agglomerative (bottom-up): Each data point is in its own cluster and the nearest ones are merged recursively. It is referred as agglomerative hierarchical clustering.\n\n  - Divisive (top-down): All data points are in the same cluster and you divide the cluster into two that are far away from each other.\n\n  - The presented implementation is an agglomerative type.\n\n### Distance measures\n\nThere are several distance metrics, that can be used as distance function. The commonly used one probably is Euclidean distance.\n\n### Linker\n\nWhen the distance between two clusters is calculated, there are several linkage types to choose from:\n\n  - **complete linkage**: maximal pairwise distance between the clusters (prone to break large clusters)\n\n  - **single linkage**: minimal pairwise distance between the clusters (sensitive to outliers)\n\n  - **centroid linkage**: distance between the two cluster centroids\n\n  - **average linkage**: average pairwise distance between the clusters (sensitive to cluster shape and size)\n\n  - **median linkage**: median pairwise distance between the clusters\n\n\n\u003Cimg style=\u0022max-width:100%\u0022 src=\u0022../../images/hClust.png\u0022\u003E\u003C/img\u003E\n\n\u003Cbr\u003E\n\n\nFor demonstration of hierarchical clustering, the classic iris data set is used, which consists of 150 records, each of which contains four measurements and a species identifier.\n\n## Referencing packages\n\n\u0060\u0060\u0060fsharp\n// Packages hosted by the Fslab community\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n// third party .net packages \n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\u0060\u0060\u0060\n\n*)\n\n(**\n## Loading data\n*)\nopen FSharp.Data\nopen Deedle\n\n// Retrieve data using the FSharp.Data package and read it as dataframe using the Deedle package\nlet rawData = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/iris.csv\u0022\nlet df = Frame.ReadCsvString(rawData)\n\ndf.Print()\n\n\n(*** include-output ***)\n\n(**\n\nLet\u0027s take a first look at the data with heatmaps using Plotly.NET. Each of the 150 records consists of four measurements and a species identifier. \nSince the species identifier occur several times (Iris-virginica, Iris-versicolor, and Iris-setosa), we create unique labels by adding the rows index to the species identifier.\n\n*)\nopen Plotly.NET\n\nlet colNames = [\u0022sepal_length\u0022;\u0022sepal_width\u0022;\u0022petal_length\u0022;\u0022petal_width\u0022]\n\n// isolate data as float [] []\nlet data = \n    Frame.dropCol \u0022species\u0022 df\n    |\u003E Frame.toJaggedArray\n    \n\n// isolate labels as seq\u003Cstring\u003E\nlet labels = \n    Frame.getCol \u0022species\u0022 df\n    |\u003E Series.values\n    |\u003E Seq.mapi (fun i s -\u003E sprintf \u0022%s_%i\u0022 s i)\n    |\u003E Array.ofSeq\n\nlet dataChart = \n    Chart.Heatmap(data,colNames=colNames,rowNames=labels)\n    // required to fit the species identifier on the left side of the heatmap\n    |\u003E Chart.withMarginSize(Left=100.)\n    |\u003E Chart.withTitle \u0022raw iris data\u0022\n\n\n(*** condition: ipynb ***)\n#if IPYNB\ndataChart\n#endif // IPYNB\n\n(***hide***)\ndataChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n## Clustering\n\nThe function that performs hierarchical clustering can be found at \u0060FSharp.Stats.ML.Unsupervised.HierarchicalClustering.generate\u0060. It requires three input parameters:\n\n  1. Distance measure working on \u0060\u0027T\u0060 (from \u0060FSharp.Stats.ML.DistanceMetrics\u0060)\n  2. Linkage type\n  3. Data to cluster as \u0060\u0027T\u0060\n\n*)\n\nopen FSharp.Stats.ML\nopen FSharp.Stats.ML.Unsupervised\n\nlet distanceMeasure = DistanceMetrics.euclideanNaNSquared\n\nlet linker = HierarchicalClustering.Linker.centroidLwLinker\n\n// calculates the clustering and reports a single root cluster (node), \n// that may recursively contains further nodes\nlet clusterResultH = \n    HierarchicalClustering.generate distanceMeasure linker data\n\n// If a desired cluster number is specified, the following function cuts the cluster according\n// to the depth, that results in the respective number of clusters (here 3). Only leaves are reported.\nlet threeClusters = HierarchicalClustering.cutHClust 3 clusterResultH\n\n(**\n\nEvery cluster leaf contains its raw values and an index that indicates the position of the respective data \npoint in the raw data. The index can be retrieved from leaves using HierarchicalClustering.getClusterId.\n\n*)\n\n// Detailed information for 3 clusters are given\nlet inspectThreeClusters =\n    threeClusters\n    |\u003E List.map (fun cluster -\u003E \n        cluster\n        |\u003E List.map (fun leaf -\u003E \n            labels.[HierarchicalClustering.getClusterId leaf]\n            )\n        )\n\n(*** condition: ipynb ***)\n#if IPYNB\ninspectThreeClusters\n|\u003E List.mapi (fun i x -\u003E \n    let truncCluster = x.[0..4] |\u003E String.concat \u0022; \u0022 \n    sprintf \u0022Cluster%i: [%s ...]\u0022 i truncCluster \n    )\n|\u003E String.concat \u0022\\n\u0022\n#endif // IPYNB\n\n(***hide***)\ninspectThreeClusters\n|\u003E List.mapi (fun i x -\u003E \n    let truncCluster = x.[0..4] |\u003E String.concat \u0022; \u0022 \n    sprintf \u0022Cluster%i: [%s ...]\u0022 i truncCluster \n    )\n|\u003E String.concat \u0022\u003Cbr\u003E\u0022\n(*** include-it-raw ***)\n\n(**\n\nTo break up the tree structure but maintain the clustering order, the cluster tree has to be flattened.\n\n*)\n\n// To recursevely flatten the cluster tree into leaves only, use flattenHClust.\n// A leaf list is reported, that does not contain any cluster membership, \n// but is sorted by the clustering result.\nlet hLeaves = \n    clusterResultH\n    |\u003E HierarchicalClustering.flattenHClust\n    \n// Takes the sorted cluster result and reports a tuple of label and data value.\nlet dataSortedByClustering =    \n    hLeaves\n    |\u003E Seq.choose (fun c -\u003E \n        let label  = labels.[HierarchicalClustering.getClusterId c]\n        let values = HierarchicalClustering.tryGetLeafValue c\n        match values with\n        | None -\u003E None\n        | Some x -\u003E Some (label,x)\n        )\n\n(**\n\nThe visualization again is performed using a Plotly.NET heatmap. \n        \n*)\n\nlet hClusteredDataHeatmap = \n    let (hlable,hdata) =\n        dataSortedByClustering\n        |\u003E Seq.unzip\n    Chart.Heatmap(hdata,colNames=colNames,rowNames=hlable)\n    // required to fit the species identifier on the left side of the heatmap\n    |\u003E Chart.withMarginSize(Left=100.)\n    |\u003E Chart.withTitle \u0022Clustered iris data (hierarchical clustering)\u0022\n\n(*** condition: ipynb ***)\n#if IPYNB\nhClusteredDataHeatmap\n#endif // IPYNB\n\n(***hide***)\nhClusteredDataHeatmap |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n(**\n\n\n## Limitations\n\n  1. There is no strong guidance on which distance function and linkage type should be used. It often is chosen arbitrarily according to the user\u0027s experience.\n  2. The visual interpretation of the dendrogram is difficult, since swapping the direction of some bifurcations may totally disturbe the visual impression.\n\n## Notes\n\n  - Please note that depending on what data you want to cluster, a column wise z-score normalization may be required. In the presented example differences in sepal width have a reduced influence because\n  the absolute variation is low.\n\n## References\n\n  - Vijaya et al., A Review on Hierarchical Clustering Algorithms, Journal of Engineering and Applied Sciences, 2017\n  - Rani and Rohil, A Study of Hierarchical Clustering Algorithm, International Journal of Information and Computation Technology, 2013\n  - FSharp.Stats documentation, fslaborg, https://fslab.org/FSharp.Stats/Clustering.html\n\n## Further reading\n\nExamples are taken from [FSharp.Stats documentation](https://fslab.org/FSharp.Stats/Clustering.html) that covers various techniques for an optimal cluster number determination.\n\nThe next article in this series covers [DBSCAN using FSharp.Stats](004_clustering_DBSCAN.html).\n\n*)\n\n\n"},{"uri":"https://fslab.org/external.html","title":"Here is a list of usefull external (non-fslab) F# resources:\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: External F# resources\ncategory: fsharp\nauthors: Various\nindex: 0\n---\n*)\n\n(**\n# Here is a list of usefull external (non-fslab) F# resources:\n\n## Learning and documentation\n- Official F# documentation: https://docs.microsoft.com/en-us/dotnet/fsharp/\n- F# module on Microsoft LEARN: https://docs.microsoft.com/en-us/learn/modules/fsharp-first-steps/\n- Website of the F# Software Foundation: https://fsharp.org/\n\n## Blogs \u0026 other content\n- fsharp for fun and profit: https://fsharpforfunandprofit.com/\n- fsharp weekly: https://sergeytihon.com/category/f-weekly/\n\n*)"},{"uri":"https://fslab.org/009_correlation-network.html","title":"Correlation network\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Correlation network\ncategory: advanced\nauthors: Heinrich Lukas Weil    \nindex: 2\n---\n*)\n(***condition:prepare***)\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n#r \u0022nuget: Deedle, 2.5.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: Cyjs.NET, 0.0.4\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n#r \u0022nuget: Deedle, 2.5.0\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: Cyjs.NET, 0.0.4\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n\n#endif // IPYNB\n\n\n(**\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath=content/tutorials/{{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n# Correlation network\n\n\n_Summary:_ This tutorial demonstrates an example workflow using different FsLab libraries. The aim is to create a correlation network, finding a threshold for which to filter and visualizing the result.\n\n\n## Introduction\n\nNetworks provide a mathematical representation of connections found everywhere, e.g. computers connected through the internet, friends connected by friendships or animals connected in the food web. \nThis mathematical representation allows for many different, but universal approaches for creating, manipulating and interrogating these networks for new information. E.g. the most important nodes (or vertices)\ncan be identified for different metrics or the most efficient connection between two nodes can be found. \n\nOne widely used kind of network in biology is the gene co-expression network. Here the nodes are genes and the edges (or links) between them are how similar their expression patterns are. One measure for \nthis similarity is the correlation between the expression patterns. This kind of network is often used for finding interesting candidates, by identifying genes which are highly connected with known genes of interest.\n\nIn this tutorial, a simple workflow will be presented for how to create and visualize a correlation network from experimental gene expression data. For this, 4 FsLab libraries will be used:\n\n0. [FSharp.Data](https://fsprojects.github.io/FSharp.Data/) for retreiving the data file\n1. [Deedle](https://github.com/fslaborg/Deedle) for reading a frame containing the data\n2. \u0026 3. [FSharp.Stats](https://fslab.org/FSharp.Stats/) to calculate correlations and finding a critical threshold\n4. [CyJS.NET](https://fslab.org/Cyjs.NET/) to visualize the results\n\n\n## Referencing packages\n\n\u0060\u0060\u0060fsharp\n#r \u0022nuget: FSharp.Data\u0022\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Cyjs.NET\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n\ndo fsi.AddPrinter(fun (printer:Deedle.Internal.IFsiFormattable) -\u003E \u0022\\n\u0022 \u002B (printer.Format()))\n\n// The edge filtering method presented in this tutorial requires an Eigenvalue decomposition. \n// FSharp.Stats uses the one implemented in the LAPACK library. \n// To enable it just reference the lapack folder in the FSharp.Stats nuget package:\nFSharp.Stats.ServiceLocator.setEnvironmentPathVariable @\u0022C:\\Users\\USERNAME\\.nuget\\packages\\fsharp.stats\\0.4.2\\netlib_LAPACK\u0022 // \nFSharp.Stats.Algebra.LinearAlgebra.Service()\n\n\u0060\u0060\u0060\n\n## Loading Data \n\nIn this tutorial, an multi experiment ecoli gene expression dataset is used.  \n\n\u0060FSharp.Data\u0060 and \u0060Deedle\u0060 are used to load the data into the fsi.\n\n*)\n\nopen FSharp.Data\nopen Deedle\n\n// Load the data \nlet rawData = Http.RequestString @\u0022https://raw.githubusercontent.com/HLWeil/datasets/main/data/ecoliGeneExpression.tsv\u0022\n\n// Create a deedle frame and index the rows with the values of the \u0022Key\u0022 column.\nlet rawFrame : Frame\u003Cstring,string\u003E = \n    Frame.ReadCsvString(rawData, separators = \u0022\\t\u0022)\n    |\u003E Frame.take 500\n    |\u003E Frame.indexRows \u0022Key\u0022\n\n(***hide***)\nrawFrame.Print()\n\n(*** include-output ***)\n\n(** \n\n## Create a correlation network\n\nNetworks can be represented in many different ways. One representation which is computationally efficient in many approaches is the adjacency matrix. \nHere every node is represented by an index and the strength of the connection between nodes is the value in the matrix at the position of their indices.\n\nIn our case, the nodes of our network are genes in Escherichia coli (a well studied bacterium). In a correlation network, the strength of this connection is the correlation. \nThe correlation between these genes is calculated over the expression of these genes over different experiments. For this we use the pearson correlation.\n\n*)\n\nopen FSharp.Stats\nopen Plotly.NET\n\n// Get the rows as a matrix\nlet rows = \n    rawFrame \n    |\u003E Frame.toJaggedArray \n    |\u003E Matrix.ofJaggedArray\n\n// Create a correlation network by computing the pearson correlation between every tow rows\nlet correlationNetwork = \n    Correlation.Matrix.rowWisePearson rows\n\n// Histogram over the correlations for visualizing the distribution\nlet correlationHistogram = \n    correlationNetwork\n    |\u003E Matrix.toJaggedArray\n    |\u003E Array.mapi (fun i a -\u003E a |\u003E Array.indexed |\u003E Array.choose (fun (j,v) -\u003E if i = j then None else Some v))\n    |\u003E Array.concat\n    |\u003E Chart.Histogram\n\n\n(** \n\n\u0060\u0060\u0060fsharp\n// Send the histogram to the browser\ncorrelationHistogram\n|\u003E Chart.show\n\u0060\u0060\u0060\n*)\n\n(***hide***)\ncorrelationHistogram\n|\u003E GenericChart.toEmbeddedHTML\n\n(*** include-it-raw ***)\n\n(** \nAs can be seen, the correlation between the most genes is relatively weak. The correlations roughly follow a right skewed gaussian distribution. So in this dataset genes tend to be more likely to be correlated than anti-correlated.\n*)\n\n(** \n\n## Critical threshold finding\n\nCreating this correlation network is not the endproduct you want though, as everything is still connected with everything. Many useful algorithms, like module finding, can only distinguish between \nwhether an edge between two vertices exists or not, instead of taking into consideration the strength of the connection. Therefore, many questions you want the network to answer, require a selection step, \nin which strong connections are kept and weak ones are discarded. This is called thresholding. For this different algorithms exist. Here we will use an algorithm based on Random Matrix Theory (RMT). \n\nThe basic idea behind this RMT approach is filtering the network until a modular state is reached. Modularity is a measure for how much nodes in a network form groups, where connections between same-group members is \nstronger or more likely than between members of different groups. In general, biological networks are generally regarded as modular, as usually more simple parts (like proteins resulting from gene expression)\nneed to work closely together to form more complex functions (like photosynthesis). \n\n*)\n(***hide***)\nSystem.IO.File.ReadAllText \u0022../../images/RMT_detailed.html\u0022\n(*** include-it-raw ***)\n(**\n\nFinding this threshold is a repetitive process shown above. For each threshold, the eigenvalues of the matrix are calculated, normalized and the spacing between these eigenvalues is calculated. For an evenly filled matrix, the \nfrequency of these spacings follows the Wigner\u0027s surmise (see left picture above). If a certain number of edges is filtered and an underlying modular structure is revealed, the spacings start following the Poisson distribution.\nThe algorithm searches the point where this switch from one distribution to the other is reached with a given accuracy (see right picture above).   \n\n*)\n\n\n(*** do-not-eval ***)\n// Calculate the critical threshold with an accuracy of 0.01\nlet threshold,_ = Testing.RMT.compute 0.9 0.01 0.05 correlationNetwork\n\n(***hide***)\nlet thr = 0.8203125\n\n// Set all correlations less strong than the critical threshold to 0\nlet filteredNetwork = \n    correlationNetwork\n    |\u003E Matrix.map (fun v -\u003E if (abs v) \u003E thr then v else 0.)\n\n\n// (***hide***)\n\n// Histogram over the correlations for visualizing the distribution\nlet correlationHistogramFiltered = \n    filteredNetwork\n    |\u003E Matrix.toJaggedArray\n    |\u003E Array.mapi (fun i a -\u003E a |\u003E Array.indexed |\u003E Array.choose (fun (j,v) -\u003E if i = j || v = 0. then None else Some v))\n    |\u003E Array.collect id\n    |\u003E Chart.Histogram\n\n\n(** \n\n\u0060\u0060\u0060fsharp\n// Send the histogram to the browser\ncorrelationHistogramFiltered\n|\u003E Chart.show\n\u0060\u0060\u0060\n*)\n\n(***hide***)\ncorrelationHistogramFiltered\n|\u003E GenericChart.toEmbeddedHTML\n\n(*** include-it-raw ***)\n\n(** \nAfter filtering the edges according the critical threshold found using RMT, only the strongly correlated genes are regarded as linked. As the distribution of all correlations was slightly skewed to higher values, only few anti correlations meet the threshold.\n*)\n\n(** \n\n## Data visualization\n\nFinally, the resulting network can be visualized. For this we use \u0060Cyjs.NET\u0060, an FsLab library which makes use of the \u0060Cytoscape.js\u0060 network visualization tool.\n\nFurther information about styling the graphs can be found [here](https://fslab.org/Cyjs.NET/).\n*)\n\n\nopen Cyjs.NET\n\n\n// The styled vertices. The size is based on the degree of this vertex, so that more heavily connected nodes are emphasized\nlet cytoVertices = \n    rawFrame.RowKeys\n    |\u003E Seq.toList\n    |\u003E List.indexed\n    |\u003E List.choose (fun (i,v) -\u003E \n        let degree = \n            Matrix.getRow filteredNetwork i \n            |\u003E Seq.filter ((\u003C\u003E) 0.)\n            |\u003E Seq.length\n        let styling = [CyParam.label v; CyParam.weight (sqrt (float degree) \u002B 1. |\u003E (*) 10.)]\n\n        if degree \u003E 1 then \n            Some (Elements.node (string i) styling)\n        else \n            None\n    )\n\n// Styled edges\nlet cytoEdges = \n    let len = filteredNetwork.Dimensions |\u003E fst\n    [\n        for i = 0 to len - 1 do\n            for j = i \u002B 1 to len - 1 do\n                let v = filteredNetwork.[i,j]\n                if v \u003C\u003E 0. then yield i,j,v\n    ]\n    |\u003E List.mapi (fun i (v1,v2,weight) -\u003E \n        let styling = [CyParam.weight (0.2 * weight)]\n        Elements.edge (\u0022e\u0022 \u002B string i) (string v1) (string v2) styling\n    )\n\n// Resulting cytograph\nlet cytoGraph = \n\n    CyGraph.initEmpty ()\n    |\u003E CyGraph.withElements cytoVertices\n    |\u003E CyGraph.withElements cytoEdges\n    |\u003E CyGraph.withStyle \u0022node\u0022 \n        [\n            CyParam.shape \u0022circle\u0022\n            CyParam.content =. CyParam.label\n            CyParam.width =. CyParam.weight\n            CyParam.height =. CyParam.weight\n            CyParam.Text.Align.center\n            CyParam.Border.color \u0022#A00975\u0022\n            CyParam.Border.width 3\n        ]\n    |\u003E CyGraph.withStyle \u0022edge\u0022 \n        [\n            CyParam.Line.color \u0022#3D1244\u0022\n        ]\n    |\u003E CyGraph.withLayout (Layout.initCose (Layout.LayoutOptions.Cose(NodeOverlap = 400,ComponentSpacing = 100)))  \n\n(** \n\n\u0060\u0060\u0060fsharp\n// Send the cytograph to the browser\ncytoGraph\n|\u003E CyGraph.withSize (1300,1000)\n|\u003E CyGraph.show\n\u0060\u0060\u0060\n\n*)\n\n(***hide***)\ncytoGraph\n|\u003E CyGraph.withSize (1300,1000)\n|\u003E HTML.toEmbeddedHTML\n\n(*** include-it-raw ***)\n\n\n(** \n\n## Interpretation\n\nAs can be seen, the network was filtered, resulting in different, partly completely separated, modules.\n*)"},{"uri":"https://fslab.org/008_sequence_features.html","title":"Modelling and visualizing sequence features with BioFSharp and Plotly.NET\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Modelling and visualizing sequence features with BioFSharp and Plotly.NET\ncategory: advanced\nauthors: Kevin Schneider\nindex: 1\n---\n*)\n\n#r \u0022nuget: BioFSharp, 2.0.0-beta7\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta6\u0022\n#r \u0022nuget: Newtonsoft.JSON, 12.0.3\u0022\n#r \u0022nuget: DynamicObj\u0022\n\nopen BioFSharp\nopen System.IO\n\ntype SequenceFeature = {\n    Name: string\n    //zero-based\n    Start: int\n    //zero-based\n    End: int\n    Length: int\n    Abbreviation: char\n    Metadata: Map\u003Cstring,string\u003E\n    FeatureType: string\n} with\n    static member create \n        (\n            name: string,\n            featureStart: int,\n            featureEnd: int,\n            ?Abbreviation: char,\n            ?Metadata: Map\u003Cstring,string\u003E,\n            ?FeatureType: string\n        ) =\n            if featureStart \u003C 0 || featureEnd \u003C 0 || featureStart \u003E featureEnd then\n                failwith $\u0022invalid feature stretch ({featureStart},{featureEnd})\u0022\n            else\n                {\n                    Name            = name        \n                    Start           = featureStart\n                    End             = featureEnd  \n                    Length          = featureEnd - featureStart \u002B 1\n                    Abbreviation    = Abbreviation |\u003E Option.defaultValue \u0027 \u0027\n                    Metadata        = Metadata |\u003E Option.defaultValue (Map.ofList [])\n                    FeatureType     = FeatureType |\u003E Option.defaultValue \u0022\u0022\n                }\n\n    static member tryGetIntersection (feature1:SequenceFeature) (feature2:SequenceFeature) =\n        let s1,e1 = feature1.Start, feature1.End\n        let s2,e2 = feature2.Start, feature2.End\n        \n        if (s2 \u003E e1) || (s1 \u003E e2) then\n            None\n        else\n            Some ((max s1 s2), (min e1 e2))\n\ntype AnnotatedSequence\u003C\u0027T when \u0027T :\u003E IBioItem\u003E = \n    {\n        Tag: string\n        Sequence : seq\u003C\u0027T\u003E\n        Features: Map\u003Cstring,SequenceFeature list\u003E\n    } \n\nmodule AnnotatedSequence =\n    \n    let create tag sequence (featureMap: Map\u003Cstring,SequenceFeature list\u003E) =\n\n        let mutable hasInvalidFeatures = false\n        let mutable invalidFeatures: (string*(SequenceFeature*SequenceFeature)) list = []\n\n        let isOverlap (stretch1:int * int) (stretch2: int * int) =\n            let s1, e1 = stretch1\n            let s2, e2 = stretch2\n\n            (s1 \u003C= s2 \u0026\u0026 e1 \u003E= s2)\n            || (s1 \u003C= s2 \u0026\u0026 e1 \u003E= e2)\n            || (s1 \u003C= e2 \u0026\u0026 e1 \u003E= e2)\n            || (s1 \u003E= s2 \u0026\u0026 e1 \u003C= e2)\n\n        featureMap\n        |\u003E Map.iter (fun key features -\u003E\n            let rec loop (featureList:SequenceFeature list) =\n                match featureList with\n                | f::rest -\u003E \n                    for frest in rest do \n                        if isOverlap (f.Start, f.End) (frest.Start, frest.End) then \n                            hasInvalidFeatures \u003C- true\n                            invalidFeatures \u003C- (key,(f,frest))::invalidFeatures\n                    loop rest\n                | [] -\u003E ()\n            loop features\n        )\n        if hasInvalidFeatures then\n            failwith $\u0022\u0022\u0022At least one  sequence feature annotation collection contains overlapping annotations. This is not supported. Please annotate them as separate feature lists.\nOffending annotations: \n{invalidFeatures}\n\u0022\u0022\u0022         \n        else\n            {\n                Tag = tag\n                Sequence = sequence\n                Features= featureMap\n            }\n\n    let addFeatures (featureKey: string) (features: SequenceFeature list) (anns: AnnotatedSequence\u003C_\u003E) =\n        {\n            anns with\n                Features = \n                    if Map.containsKey featureKey anns.Features then\n                        anns.Features |\u003E Map.add featureKey (features @ anns.Features.[featureKey])\n                    else\n                        anns.Features |\u003E Map.add featureKey features\n                \n        }\n\n    let toStrings (anns: AnnotatedSequence\u003C_\u003E) =\n        let sequenceString = anns.Sequence |\u003E Seq.map (BioItem.symbol \u003E\u003E string) |\u003E String.concat \u0022\u0022\n        let emptyFormatString = [for i in 1 .. (Seq.length anns.Sequence) do yield \u0022 \u0022] |\u003E String.concat \u0022\u0022\n        let featureFormats =\n            anns.Features\n            |\u003E Map.map (fun key features -\u003E \n                features\n                |\u003E Seq.fold (fun (acc:string) (feature) -\u003E\n                    let featureStretch = [for _ in 1 .. feature.Length do yield (feature.Abbreviation |\u003E string)] |\u003E String.concat \u0022\u0022\n                    acc\n                        .Remove(feature.Start, feature.Length)\n                        .Insert(feature.Start, featureStretch)\n                ) emptyFormatString\n            )\n        sequenceString,featureFormats\n\n    let format (anns: AnnotatedSequence\u003C_\u003E) =\n        let sequenceString, featureStrings = anns |\u003E toStrings\n        let longestId = \n            [\u0022Sequence\u0022; yield! (featureStrings |\u003E Map.toList |\u003E List.map fst)] \n            |\u003E Seq.maxBy (fun x -\u003E x.Length)\n            |\u003E fun s -\u003E s.Length\n\n        let ids = \n            [\u0022Sequence\u0022; yield! (featureStrings |\u003E Map.toList |\u003E List.map fst)]\n            |\u003E List.map (fun s -\u003E s.PadRight(longestId\u002B4))\n        \n        let blocks = \n            [sequenceString; yield! (featureStrings |\u003E Map.toList |\u003E List.map snd)]\n            |\u003E List.mapi (fun index seqString -\u003E\n                let id = ids.[index]\n                let splits = \n                    seqString.ToCharArray() \n                    |\u003E Seq.map string\n                    |\u003E Seq.chunkBySize 60 \n                    |\u003E Seq.map (String.concat \u0022\u0022)\n\n                let innerSplits = \n                    splits |\u003E Seq.map (fun s -\u003E \n                        s.ToCharArray() \n                        |\u003E Seq.map string\n                        |\u003E Seq.chunkBySize 10 \n                        |\u003E Seq.map (String.concat \u0022\u0022)\n                )\n\n                innerSplits \n                |\u003E Seq.mapi (fun i strs -\u003E  \n                    let line = \n                        strs \n                        |\u003E Seq.fold (fun acc elem -\u003E sprintf \u0022%s %s\u0022 acc elem) \u0022\u0022 \n                    $\u0022{id} {(string (((i\u002B1)*60) - 60 \u002B 1)).PadLeft(10)}{line}\u0022 \n                )\n                |\u003E Array.ofSeq\n            )\n\n        [for i in 0 .. blocks.[0].Length-1 do\n            for b in blocks do yield b.[i]\n        ]\n        |\u003E String.concat System.Environment.NewLine\n        |\u003E fun s -\u003E $\u0022{System.Environment.NewLine}{s}{System.Environment.NewLine}\u0022\n\n(**\n# Modelling and visualizing sequence features with BioFSharp and Plotly.NET\n\n### Table of contents\n\n- [Assigning secondary structure for proteins based on .pdb files](#Assigning-secondary-structure-for-proteins-based-on-pdb-files)\n- [Comparing structural annotations](#Comparing-structural-annotations)\n- [Generalizing sequence features]()\n    - [Implementing the Sequence feature](#Implementing-the-Sequence-feature)\n    - [Implementing the Annotated Sequence](#Implementing-the-Annotated-Sequence)\n- [Visualizing sequence features with Plotly.NET](#Visualizing-sequence-features-with-Plotly-NET)\n    - [Plotting sequences with Plotly.NET](#Plotting-sequences-with-Plotly-NET)\n    - [A sequence feature view plot for AnnotatedSequence](#A-sequence-feature-view-plot-for-AnnotatedSequence)\n\n\n## Assigning secondary structure for proteins based on .pdb files\n\nI recently started to work with a lot of structural protein data with the aim of extracting features based on the proteins secondary structures.\n\nThis involved assigning secondary structures for \u0060.pdb\u0060 files, which is a file format that contains positional information about each atom in a polipeptide chain.\nAs in many bioinformatic fields, tried-and-tested algorithms for this are several decades old but seem to be still the gold standard. \nThe algorithm that pops up most is [**DSSP**](https://swift.cmbi.umcn.nl/gv/dssp/) (Dictionary of Protein Secondary Structure). You can clearly see the age in every ounce of that website.\n\nDSSP was originally used to assign all secondary structures for the [PDB (Protein Data bank)](https://www.rcsb.org/). I cannot find a source if that is still the case though. \n\u0060.pdb\u0060 files obtained from PDB usually already contain a section with the assigned structures, but this is not true for example for the output of alpha fold, which only predicts the raw atom positions without any structure assignment.\n\nUsing dssp is straight forward, it can be installed directly via apt on ubuntu, and there is a biocontainer available [here](https://biocontainers.pro/tools/dssp)\n\ndssp itself is also very easy to use. Once in the container, simply run\n\n\u0060\u0060\u0060bash\ndssp -i \u003C.pdb file\u003E -o \u003Cdssp file\u003E\n\u0060\u0060\u0060\n\nThe output format of DSSP is weird, but writing parsers is not too hard. It contains metadata sections indicated by the line start, which are not very interesting fort my purposes.\nThe structure assignments are contained in a fixed-column data format further down the file. \n\nHere is an example of how it looks like:\n\n\u0060\u0060\u0060no-highlight\n#  RESIDUE AA STRUCTURE BP1 BP2  ACC     N-H--\u003EO    O--\u003EH-N    N-H--\u003EO    O--\u003EH-N    TCO  KAPPA ALPHA  PHI   PSI    X-CA   Y-CA   Z-CA            CHAIN\n  1    1 A M              0   0  235      0, 0.0     4,-0.1     0, 0.0     0, 0.0   0.000 360.0 360.0 360.0  58.6   -7.4   17.5   38.1               \n  2    2 A Y     \u003E  \u002B     0   0  202      2,-0.1     4,-0.6     3,-0.1     0, 0.0   0.539 360.0  69.8-121.3  -9.6   -8.6   17.8   34.5               \n  3    3 A Y  H  \u003E S\u002B     0   0  209      1,-0.2     4,-1.1     2,-0.2     3,-0.3   0.865  91.2  58.3 -82.3 -33.1   -5.5   19.3   32.5               \n  4    4 A F  H  \u003E S\u002B     0   0  193      1,-0.2     4,-1.7     2,-0.2    -1,-0.2   0.861 101.0  56.5 -67.1 -33.2   -3.2   16.2   32.7               \n  5    5 A S  H  \u003E S\u002B     0   0   91      1,-0.2     4,-1.5     2,-0.2    -1,-0.2   0.835 104.5  51.5 -71.2 -31.9   -5.6   13.8   31.0               \n  6    6 A R  H  X S\u002B     0   0  204     -4,-0.6     4,-1.4    -3,-0.3    -1,-0.2   0.816 108.4  51.3 -75.1 -30.1   -6.0   16.0   27.8               \n  7    7 A V  H  X S\u002B     0   0   96     -4,-1.1     4,-1.8     2,-0.2    -2,-0.2   0.924 110.2  49.0 -72.1 -41.8   -2.2   16.3   27.3               \n  8    8 A A  H  X S\u002B     0   0   54     -4,-1.7     4,-1.9     1,-0.2    -2,-0.2   0.860 109.1  52.8 -65.7 -36.0   -1.8   12.5   27.5               \n  9    9 A A  H  X S\u002B     0   0   65     -4,-1.5     4,-1.7     2,-0.2    -1,-0.2   0.885 108.6  50.6 -67.1 -36.6   -4.6   11.9   25.0               \n 10   10 A R  H  X S\u002B     0   0  206     -4,-1.4     4,-1.6     2,-0.2    -2,-0.2   0.888 110.4  48.5 -68.7 -39.2   -2.9   14.3   22.5               \n 11   11 A T  H  X S\u002B     0   0   84     -4,-1.8     4,-1.6     2,-0.2    -2,-0.2   0.894 109.7  52.6 -70.1 -36.5    0.5   12.5   22.7               \netc.\n\u0060\u0060\u0060\n\nWriting a parser for that section was straight forward. I added it to [BioFSharp.IO]() if you are interested in using it yourself.\n\n## Comparing structural annotations\n\nWithout going into too much detail, one of the things I am interested in is how the structural assignments of DSSP relate to other structural annotations for it.\nAn example would be **intrinsically disordered stretches**, parts of the chain that do not have a structure, but this disorder is actually crucial for the proteins function.\n\nYou can read more about disorder in protein structures [here](https://en.wikipedia.org/wiki/Intrinsically_disordered_proteins). An awesome ressource for disorder annotations is [DisProt](https://disprot.org/). You can download its annotations in an easily usable tsv format (no custom parsing yay).\nWith these two annotations at hand, i started scripting with BioFSharp and Plotly.NET to get visual comparisons of both features (DSSP structure and disprot annotation).\n\nMy first attempts involved chunking the sequence and annotations by 60 and creating a annotated heatmap, assigning color based on the one character code of the structure. It achieved the goal, but was very hard to read, especially for large sequences.\nI wont even include the source code for this, because it obviously sucks:\n\n\u003Cbr\u003E\n\u003Chr\u003E\n\n![heatmap]({{root}}images/sequence_features_heatmap.png))\n\n_Fig1: My first pitiful attempt at visualizing sequence features_\n\u003Chr\u003E\n\u003Cbr\u003E\n\nAt this point, i thought i was pretty much near the goal of my project (i calculated some fancy metrics downstream from the features that do not belong in this post),\nand therefore content with the visualization. But as often happens in any kind of project - especially in academia - the scale of the project increased and i wanted to include more features in my calculations.\n\nOne was the secondary structure assigment of [Stride](http://webclu.bio.wzw.tum.de/stride/) - basically an improved version of DSSP. Also, i wanted to look at different disprot annotations individually.\nAt this point, a generic solution for both handling sequence features as well as their visualization was needed.\n\nStride is not as straight-forward to use as DSSP. I ended up creating my own docker container that builds it from [source](http://webclu.bio.wzw.tum.de/stride/install.html):\n\n\u0060\u0060\u0060dockerfile\nFROM biocontainers/biocontainers:vdebian-buster-backports_cv1\n\nUSER root\nRUN apt-get update \u0026\u0026 (apt-get install -t buster-backports -y gcc || apt-get install -y gcc) \u0026\u0026 (apt-get install -t buster-backports -y make || apt-get install -y make) \u0026\u0026 apt-get clean \u0026\u0026 apt-get purge\n\nWORKDIR /bin/stride\nCOPY ./stride.tar.gz /bin/stride\n\nENV DEBIAN_FRONTEND noninteractive\nRUN tar -zxf stride.tar.gz\nRUN make\nENV PATH=\u0022/bin/stride/:${PATH}\u0022\n\nWORKDIR /data\nUSER biodocker\n\u0060\u0060\u0060\n\n## Implementing the Sequence feature\n\nA sequence feature in its most basic form just need start and end index within the sequence. They are usually abbreviated by a one-character code in most visualizations, and DSSP as well as Stride use on-letter codes for their assignment. \nI added additional metadata such as the name, type, and length of the feature, as well as arbitrary metadata. The full implementation in BioFSharp can be seen [here]()\n\n\u0060\u0060\u0060\ntype SequenceFeature = \n    {\n        Name: string\n        //zero-based\n        Start: int\n        //zero-based\n        End: int\n        Length: int\n        Abbreviation: char\n        Metadata: Map\u003Cstring,string\u003E\n        FeatureType: string\n    }\n\n\u0060\u0060\u0060\n\n## Implementing the Annotated Sequence\n\nAn annotated sequence is a sequence which has feature annotations. I decided to model these as a Map of sequence features, where the key represents the feature type, and the list contains the individual feature stretches of that type.\nThe sequence can also be tagged with a string to give it an identifier:\n\n\u0060\u0060\u0060\ntype AnnotatedSequence\u003C\u0027T when \u0027T :\u003E IBioItem\u003E = \n    {\n        Tag: string\n        Sequence : seq\u003C\u0027T\u003E\n        Features: Map\u003Cstring,SequenceFeature list\u003E\n    } \n\n\u0060\u0060\u0060\n\nThe full implementation with all additional functions can be found in BioFSharp [here]()\n\nBased on this type, i first created a pretty printer in the fasta style to see if i was going in the right direction:\n\n*)\nopen BioFSharp\n\nlet testSeq = \n    AnnotatedSequence.create\n        \u0022Test\u0022\n        (\u0022ATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAG\u0022 |\u003E BioArray.ofNucleotideString)\n        (Map.ofList [\n            \u0022Feature1\u0022, [SequenceFeature.create(\u0022F1\u0022,0,10,\u0027A\u0027)]\n            \u0022Feature2\u0022, [SequenceFeature.create(\u0022F2\u0022,0,10,\u0027B\u0027); SequenceFeature.create(\u0022F2\u0022,100,120,\u0027B\u0027)]\n            \u0022Feature3\u0022, [SequenceFeature.create(\u0022F3\u0022,30,90,\u0027C\u0027)]\n\n        ])\n\nAnnotatedSequence.format testSeq\n(***include-it***)\n\n(**\nSo with this type modelling i was able to annotate a sequence with arbitrary features and visualize their positions. This text-based representation has the same problems as my heatmap approach though: it gets quite hard to read with increasing sequence length and feature count.\nStill, this is a nice pretty prionter for usage with \u0060fsi.AddPrinter\u0060.\n\n# Visualizing sequence features with Plotly.NET\n\nI took heavy inspiration from DisProt\u0027s sequence viewer, which displays feature lanes below the actual sequence as bars.\n\n## Plotting sequences with Plotly.NET\n\nTo plot a sequence of characters on a 2D plot, we can leverage Plotly.NETs \u0060Annotations\u0060. \nTo give the annotations points that can trigger hovertext, i added an invisible line trace behind them.\n*)\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n\nopen Plotly.NET\nopen Plotly.NET.LayoutObjects\n\nlet testSeqChart = \n    Chart.Line(\n        [for i in 0..3 -\u003E (i,1)], \n        MultiText=[\u0022A\u0022;\u0022T\u0022;\u0022G\u0022;\u0022C\u0022], \n        Opacity=0.0,\n        ShowLegend = false,\n        LineColor= Color.fromKeyword Black\n    )\n    |\u003E Chart.withAnnotations (\n        [\u0022A\u0022;\u0022T\u0022;\u0022G\u0022;\u0022C\u0022]\n        |\u003E Seq.mapi (fun x text -\u003E\n                Annotation.init(\n                    x,1,\n                    Text=(string text),\n                    ShowArrow=false,\n                    Font = Font.init(Size=16.)\n                )\n        )\n    )\n\n(**\n\u003Chr\u003E\n*)\n\n(***hide***)\ntestSeqChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n_Fig 2: A simple sequence plot using Plotly.NET\u0027s Annotations._\n\u003Chr\u003E\n\u003Cbr\u003E\n*)\n\n(**\nWith some additional styling, we can make this look pretty good already:\n\n- Remove the Y axis\n- Mirror the X Axis\n- Add spike lines per default (very usefull later when combining with the feature traces)\n\n*)\n\ntype Chart with\n    static member SequencePlot\n        (\n            annotationText: #seq\u003Cstring\u003E,\n            ?FontSize: float\n        ) =\n            let fontSize = defaultArg FontSize 16.\n\n            Chart.Line(\n                [for i in 0..((Seq.length annotationText) - 1) -\u003E (i,1)], \n                MultiText=annotationText, \n                Opacity=0.0,\n                ShowLegend = false,\n                LineColor= Color.fromKeyword Black\n            )\n            |\u003E Chart.withXAxis(\n                LinearAxis.init(\n                    Visible=true, \n                    ShowLine= true, \n                    ShowTickLabels = true, \n                    ShowSpikes= true, \n                    ZeroLine = false, \n                    Range= StyleParam.Range.MinMax(0.,60.), // as default, show the first 60 characters. Double click to zoom out.\n                    Title = Title.init(\u0022Sequence index (0-based)\u0022, Font=Font.init(Size=fontSize)),\n                    TickFont = Font.init(Size=fontSize),\n                    Ticks = StyleParam.TickOptions.Inside,\n                    Mirror = StyleParam.Mirror.AllTicks\n                )\n            )        \n            |\u003E Chart.withYAxis(\n                LinearAxis.init(Visible=false, ShowLine= false, ShowTickLabels = false, ShowGrid = false, ZeroLine=false)\n            )\n            |\u003E Chart.withAnnotations (\n                annotationText\n                |\u003E Seq.mapi (fun x text -\u003E\n                    Annotation.init(\n                        x,1,\n                        Text=(string text),\n                        ShowArrow=false,\n                        Font = Font.init(Size=fontSize)\n                    )\n                )\n            )\n\nlet seqPlot = \n    Chart.SequencePlot(testSeq.Sequence |\u003E Seq.map (BioItem.symbol \u003E\u003E string))\n    |\u003E Chart.withSize(1000)\n\n(**\n\u003Chr\u003E\n*)\n\n(***hide***)\nseqPlot |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n_Fig 3: A better styled version of the Sequence plot._\n\u003Chr\u003E\n\u003Cbr\u003E\n*)\n\n(**\n## A sequence feature view plot for AnnotatedSequence\n\nNow we need to add the feature traces. While Plotly.NET supports shapes to draw on a Plot, these have the disadvantage of not triggering hover events (at least to my knowledge).\n\nSo i decided to render each feature as a horizontal Bar trace, setting its \u0060Base\u0060 property (the Bar start) to the feature start, and the length accordingly.\n\nUsing \u0060Chart.SingleStack\u0060 in shared axis mode together with the previous sequence plot, this has the additional advantage that spikelines of the sequence plot span over the features (try hovering over the sequence below)\n\n*)\n\nlet featureTraceTestPlot = \n    [\n        Chart.SequencePlot(testSeq.Sequence |\u003E Seq.map (BioItem.symbol \u003E\u003E string))\n        [\n            Chart.Bar([\u0022Feature1\u0022, 20], Base=10, ShowLegend = false)\n            Chart.Bar([\u0022Feature1\u0022, 20], Base=41, ShowLegend = false)\n            Chart.Bar([\u0022Feature2\u0022, 50], Base=20, ShowLegend = false)\n        ]\n        |\u003E Chart.combine\n    ]\n    |\u003E Chart.SingleStack(Pattern=StyleParam.LayoutGridPattern.Coupled)\n    |\u003E Chart.withSize(1000)\n\n(**\n\u003Chr\u003E\n*)\n\n(***hide***)\nfeatureTraceTestPlot |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n_Fig 4: Bar traces with different bases can be used in a stacked chart to indicate features mapping to the sequence position of the sequence plot on top._\n\u003Chr\u003E\n\u003Cbr\u003E\n*)\n\n(**\n\nThat looks exactly like i wanted it to turn out!\n\nThe rest is now a matter of styling. here is what i did additionally (in words):\n\n- render all features with the same color, unless indicated otherwise by a color mapping function\n- As seen on the plot above, When there are multiple features in a single lane, they get rendered with a y offset. This can be overcome by setting the barmode of the chart layout to \u0060Overlay\u0060\n- Add a x axis range slider to give more exploratory power\n\nAnd here is the final result (in code):\n\n*)\n\n\ntype Chart with\n    static member SequenceFeatureView\n        (\n            annotatedSequence: AnnotatedSequence\u003C_\u003E,\n            ?FontSize: float,\n            ?ColorMapping: seq\u003C(string*Color)\u003E,\n            ?ShowRangeSlider: bool\n        ) =\n            let showRangeSlider = defaultArg ShowRangeSlider true\n            let sequenceString = annotatedSequence.Sequence |\u003E Seq.map (BioItem.symbol \u003E\u003E string)\n\n            let featureColorMap = \n                ColorMapping\n                |\u003E Option.defaultValue Seq.empty\n                |\u003E Map.ofSeq\n\n            let featurePlots =\n                annotatedSequence.Features\n                |\u003E Map.toSeq\n                |\u003E Seq.map (fun (featureName,features) -\u003E\n                    features\n                    |\u003E List.map (fun f -\u003E\n                        Chart.Bar(\n                            [featureName,f.Length-1], \n                            Width=0.8, \n                            Base=f.Start, \n                            Text = $\u0022({f.Start}-{f.End}):  {f.Abbreviation}\u0022, \n                            TextPosition = StyleParam.TextPosition.Inside,\n                            ShowLegend = false,\n                            MarkerColor = (Map.tryFind featureName featureColorMap |\u003E Option.defaultValue (Color.fromKeyword Black))\n                        )\n                    \n                    )\n                )\n                |\u003E Seq.concat\n\n            [\n                Chart.SequencePlot(sequenceString, ?FontSize = FontSize)\n                |\u003E Chart.withYAxis(\n                    LinearAxis.init(Domain = StyleParam.Range.MinMax(0.81,1.))\n                )\n\n                featurePlots\n                |\u003E Chart.combine\n                |\u003E Chart.withYAxis(\n                    LinearAxis.init(ShowGrid=true, FixedRange = false, Domain = StyleParam.Range.MinMax(0.,0.79))\n                )\n            ]\n            |\u003E Chart.SingleStack(Pattern = StyleParam.LayoutGridPattern.Coupled)\n            |\u003E fun c -\u003E \n                if showRangeSlider then\n                    c\n                    |\u003E Chart.withXAxisRangeSlider(\n                        RangeSlider.init(BorderColor=Color.fromKeyword Gray, BorderWidth=1.)\n                    )\n                else\n                    c\n            |\u003E Chart.withConfig(\n                Config.init(ModeBarButtonsToAdd=[\n                    StyleParam.ModeBarButton.ToggleSpikelines\n                ])\n            )\n            |\u003E Chart.withLayout(\n                Layout.init(\n                    BarMode = StyleParam.BarMode.Overlay\n                )\n            )\n            |\u003E Chart.withTitle $\u0022Sequence feature view for {annotatedSequence.Tag}\u0022\n\n(**\nHere is what it looks like with a big test sequence:\n*)\n\nlet bigTestSeq = \n    AnnotatedSequence.create\n        \u0022test sequence\u0022\n        (\u0022ATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGTGTC\u0022 |\u003E BioArray.ofNucleotideString)\n        (Map.ofList [\n            \u0022Feature 1\u0022, [SequenceFeature.create(\u0022F\u0022,1,33,\u0027X\u0027);  SequenceFeature.create(\u0022F\u0022,50,60,\u0027D\u0027)]\n            \u0022Feature 2\u0022, [SequenceFeature.create(\u0022F\u0022,0,30,\u0027L\u0027);  SequenceFeature.create(\u0022F\u0022,40,50,\u0027E\u0027); SequenceFeature.create(\u0022F\u0022,52,100,\u0027L\u0027)]\n            \u0022Feature 3\u0022, [SequenceFeature.create(\u0022F\u0022,8,83,\u0027X\u0027);  SequenceFeature.create(\u0022F\u0022,84,100,\u0027D\u0027)]\n            \u0022Feature 4\u0022, [SequenceFeature.create(\u0022F\u0022,80,85,\u0027L\u0027); SequenceFeature.create(\u0022F\u0022,40,50,\u0027E\u0027); SequenceFeature.create(\u0022F\u0022,52,79,\u0027L\u0027)]            \n            \u0022Feature 5\u0022, [SequenceFeature.create(\u0022F\u0022,1,33,\u0027X\u0027);  SequenceFeature.create(\u0022F\u0022,50,60,\u0027D\u0027)]\n            \u0022Feature 6\u0022, [SequenceFeature.create(\u0022F\u0022,0,30,\u0027L\u0027);  SequenceFeature.create(\u0022F\u0022,40,50,\u0027E\u0027); SequenceFeature.create(\u0022F\u0022,52,100,\u0027L\u0027)]\n            \u0022Feature 7\u0022, [SequenceFeature.create(\u0022F\u0022,8,83,\u0027X\u0027);  SequenceFeature.create(\u0022F\u0022,84,100,\u0027D\u0027)]\n            \u0022Feature 8\u0022, [SequenceFeature.create(\u0022F\u0022,80,85,\u0027L\u0027); SequenceFeature.create(\u0022F\u0022,40,50,\u0027E\u0027); SequenceFeature.create(\u0022F\u0022,52,79,\u0027L\u0027)]\n            \u0022Feature 9\u0022, [SequenceFeature.create(\u0022F\u0022,1,33,\u0027X\u0027);  SequenceFeature.create(\u0022F\u0022,50,60,\u0027D\u0027)]\n            \u0022Feature 10\u0022,[SequenceFeature.create(\u0022F\u0022,0,30,\u0027L\u0027);  SequenceFeature.create(\u0022F\u0022,40,50,\u0027E\u0027); SequenceFeature.create(\u0022F\u0022,52,100,\u0027L\u0027)]\n            \u0022Feature 11\u0022,[SequenceFeature.create(\u0022F\u0022,8,83,\u0027X\u0027);  SequenceFeature.create(\u0022F\u0022,84,100,\u0027D\u0027)]\n            \u0022Feature 12\u0022,[SequenceFeature.create(\u0022F\u0022,80,85,\u0027L\u0027); SequenceFeature.create(\u0022F\u0022,40,50,\u0027E\u0027); SequenceFeature.create(\u0022F\u0022,52,79,\u0027L\u0027)]            \n            \u0022Feature 13\u0022,[SequenceFeature.create(\u0022F\u0022,1,33,\u0027X\u0027);  SequenceFeature.create(\u0022F\u0022,50,60,\u0027D\u0027)]\n            \u0022Feature 14\u0022,[SequenceFeature.create(\u0022F\u0022,0,30,\u0027L\u0027);  SequenceFeature.create(\u0022F\u0022,40,50,\u0027E\u0027); SequenceFeature.create(\u0022F\u0022,52,100,\u0027L\u0027)]\n            \u0022Feature 15\u0022,[SequenceFeature.create(\u0022F\u0022,8,83,\u0027X\u0027);  SequenceFeature.create(\u0022F\u0022,84,100,\u0027D\u0027)]\n            \u0022Feature 16\u0022,[SequenceFeature.create(\u0022F\u0022,80,85,\u0027L\u0027); SequenceFeature.create(\u0022F\u0022,40,50,\u0027E\u0027); SequenceFeature.create(\u0022F\u0022,52,79,\u0027L\u0027)]\n        ])\n\nlet finalChart =\n    Chart.SequenceFeatureView(\n        bigTestSeq,\n        ColorMapping = [\u0022Feature 10\u0022, Color.fromKeyword DarkSalmon] // show feature 10 in a different color\n    )\n    |\u003E Chart.withSize(1000)\n\n(**\n\u003Chr\u003E\n*)\n\n(***hide***)\nfinalChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n_Fig 5: The final result of my feature view plotting efforts._\n\u003Chr\u003E\n*)"},{"uri":"https://fslab.org/010_q_values.html","title":"q values\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: q values\ncategory: advanced\nauthors: Benedikt Venn\nindex: 3\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: FSharpAux, 1.1.0\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.15\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: FSharpAux, 1.1.0\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.15\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n#endif // IPYNB\n\nopen FSharp.Data\nopen Plotly.NET\nopen Plotly.NET.StyleParam\nopen Plotly.NET.LayoutObjects\n\n// Extension of chart module for more automated chart styling\nmodule Chart = \n    let myAxis name = \n        LinearAxis.init(Title=Title.init name,Mirror=StyleParam.Mirror.All,Ticks=StyleParam.TickOptions.Inside,ShowGrid=false,ShowLine=true)\n        \n    let withAxisTitles x y chart = \n        chart \n        |\u003E Chart.withTemplate ChartTemplates.lightMirrored\n        |\u003E Chart.withXAxis (myAxis x) \n        |\u003E Chart.withYAxis (myAxis y)\n(**\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath=content/tutorials/{{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n# q values\n\n_Summary:_ This blog post provides insight into the definition, calculation, and interpretation of q-values. _[Benedikt Venn](https://github.com/bvenn)_, 21 Jan 2022\n\n_TLDR:_ A q value defines the proportion of false positives there are within all discoveries that were called significant up to the current item.\n\n### Table of contents\n\n- [Introduction](#Introduction)\n- [The multiple testing problem](#The-multiple-testing-problem)\n- [False discovery rate](#False-discovery-rate)\n    - [q value](#q value)\n    - [Variants](#Variants)\n- [Quality plots](#Quality-plots)\n- [Definitions and Notes](#Definitions-and-Notes)\n- [FAQ](#FAQ)\n- [References](#References)\n\n*)\n\n\n\n(**\n## Referencing packages\n\n\u0060\u0060\u0060fsharp\n#r \u0022nuget: FSharpAux, 1.1.0\u0022             //required for auxiliary functions\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022 //required for charting\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022          //required for all calculations\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022           //required to read the pvalue set\n\nopen Plotly.NET\nopen Plotly.NET.StyleParam\nopen Plotly.NET.LayoutObjects\n\n// Extension of chart module for more automated chart styling\nmodule Chart = \n    let myAxis name = LinearAxis.init(Title=Title.init name,Mirror=StyleParam.Mirror.All,Ticks=StyleParam.TickOptions.Inside,ShowGrid=false,ShowLine=true)\n    let withAxisTitles x y chart = \n        chart \n        |\u003E Chart.withTemplate ChartTemplates.lightMirrored\n        //|\u003E Chart.withXAxis (myAxis x) \n        //|\u003E Chart.withYAxis (myAxis y)\n        |\u003E Chart.withXAxisStyle x\n        |\u003E Chart.withYAxisStyle y\n\n\u0060\u0060\u0060\n\n## Introduction\n\n\u003Cb\u003EHigh throughput techniques\u003C/b\u003E like microarrays with its successor RNA-Seq and mass spectrometry proteomics lead to an huge data amount.\nThousands of features (e.g. transcripts or proteins) are measured simultaneously. \u003Cb\u003EDifferential expression analysis\u003C/b\u003E aims to identify features, that change significantly\nbetween two conditions. A common experimental setup is the analysis of which genes are over- or underexpressed between e.g. a wild type and a mutant.\n\nHypothesis tests aim to identify differences between two or more samples. The most common statistical test is the \u003Cb\u003Et test\u003C/b\u003E that tests a difference of means. Hypothesis tests report \na p value, that correspond the probability of obtaining results at least as extreme as the observed results, assuming that the null hypothesis is correct. In other words:\n\n_\u003Ccenter\u003EIf there is no effect (no mean difference), a p value of 0.05 indicates that in 5 % of the tests a false positive is reported.\u003C/center\u003E_\n\n\u003Chr\u003E\n\nConsider two population distributions that follow a normal distribution. Both have the \u003Cb\u003Esame\u003C/b\u003E mean and standard deviation.\n*)\n\n\n\nopen FSharpAux\nopen FSharp.Stats\n\n\nlet distributionA = Distributions.Continuous.normal 10.0 1.0\nlet distributionB = Distributions.Continuous.normal 10.0 1.0\n\nlet distributionChartAB = \n    [\n        Chart.Area([5. .. 0.01 .. 15.] |\u003E List.map (fun x -\u003E x,distributionA.PDF x),\u0022distA\u0022)\n        Chart.Area([5. .. 0.01 .. 15.] |\u003E List.map (fun x -\u003E x,distributionB.PDF x),\u0022distB\u0022)\n    ]\n    |\u003E Chart.combine\n    |\u003E Chart.withAxisTitles \u0022variable X\u0022 \u0022relative count\u0022\n    //|\u003E Chart.withXAxisStyle \u0022variable X\u0022\n    //|\u003E Chart.withYAxisStyle \u0022relative count\u0022\n    |\u003E Chart.withSize (900.,600.)\n    |\u003E Chart.withTitle \u0022null hypothesis\u0022\n\n\n(**\u003Ccenter\u003E*)\n(***hide***)\ndistributionChartAB |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\u003C/center\u003E\n\nSamples with sample size 5 are randomly drawn from both population distributions.\nBoth samples are tested \u003Cb\u003Eif a mean difference exist\u003C/b\u003E using a two sample t test where equal variances of the underlying population distribution are assumed.\n\n*)\n\nlet getSample n (dist: Distributions.Distribution\u003Cfloat,float\u003E) =\n    Vector.init n (fun _ -\u003E dist.Sample())\n    \nlet sampleA = getSample 5 distributionA\nlet sampleB = getSample 5 distributionB\n\nlet pValue = (Testing.TTest.twoSample true sampleA sampleB).PValue\n\n(***hide***)\npValue\n(***include-it***)\n\n(**\n10,000 tests are performed, each with new randomly drawn samples. This corresponds to an experiment in which \u003Cb\u003Enone of the features changed\u003C/b\u003E \nNote, that the mean intensities are arbitrary and must not be the same for all features! In the presented case all feature intensities are in average 10.\nThe same simulation can be performed with pairwise comparisons from distributions that differ for each feature, but are the same within the feature.\n\u003Cb\u003EThe resulting p values are uniformly distributed between 0 and 1\u003C/b\u003E\n\n\u003Cbr\u003E\n\n\u003Ccenter\u003E\u003Cimg style=\u0022max-width:50%\u0022 src=\u0022../../images/qvalue_01.svg\u0022\u003E\u003C/img\u003E\u003C/center\u003E\n\n_Fig 1: p value distribution of the null hypothesis._\n\u003Chr\u003E\n\u003Cbr\u003E\n\n*)\n(***hide***)\nlet nullDist = \n    Array.init 10000 (fun x -\u003E \n        let sA = getSample 5 distributionA\n        let sB = getSample 5 distributionB\n        (Testing.TTest.twoSample true sA sB).PValue\n        )\n\n\nlet nullDistributionChart = \n    nullDist \n    |\u003E Distributions.Frequency.create 0.025 \n    |\u003E Map.toArray \n    |\u003E Array.map (fun (k,c) -\u003E k,float c) \n    |\u003E Chart.StackedColumn \n    |\u003E Chart.withTraceName \u0022alt\u0022\n    //|\u003E Chart.withAxisTitles \u0022pvalue\u0022 \u0022frequency\u0022\n    |\u003E Chart.withXAxisStyle \u0022pvalue\u0022\n    |\u003E Chart.withYAxisStyle \u0022frequency\u0022\n\nlet thresholdLine =\n    Shape.init(ShapeType.Line,0.05,0.05,0.,300.)\n\n(**\n\nSamples are called significantly different, if their p value is below a certain significance threshold ($\\alpha$ level). While \u0022the lower the better\u0022, a common threshold\nis a p value of 0.05 or 0.01. In the presented case in average $10,000 * 0.05 = 500$ tests are \u003Cb\u003Esignificant (red box), even though the populations do not differ\u003C/b\u003E. They are called \u003Cb\u003Efalse \npositives (FP)\u003C/b\u003E. Now lets repeat the same experiment, but this time sample 70% of the time from null features (no difference) and \u003Cb\u003Eadd 30% samples of truly \ndiffering\u003C/b\u003E distributions. Therefore a third populations is generated, that differ in mean, but has an equal standard deviation:\n\n*)\n\nlet distributionC = Distributions.Continuous.normal 11.5 1.0\n\n(***hide***)\nlet distributionChartAC = \n    [\n        Chart.Area([5. .. 0.01 .. 15.] |\u003E List.map (fun x -\u003E x,distributionA.PDF x),\u0022distA\u0022)\n        Chart.Area([5. .. 0.01 .. 15.] |\u003E List.map (fun x -\u003E x,distributionC.PDF x),\u0022distC\u0022)\n    ]\n    |\u003E Chart.combine\n    //|\u003E Chart.withAxisTitles  \u0022variable X\u0022 \u0022relative count\u0022\n    |\u003E Chart.withXAxisStyle \u0022variable X\u0022\n    |\u003E Chart.withYAxisStyle \u0022relative count\u0022\n    |\u003E Chart.withSize (1000.,600.)\n    |\u003E Chart.withTitle \u0022alternative hypothesis\u0022\n\n//distributionChartAC |\u003E GenericChart.toChartHTML\n\n(**\n\n\u003Ccenter\u003E\u003Cimg style=\u0022max-width:50%\u0022 src=\u0022../../images/qvalue_02.svg\u0022\u003E\u003C/img\u003E\u003C/center\u003E\n\n_Fig 2: p value distribution of the alternative hypothesis. Blue coloring indicate p values deriving from distribution A and B (null). \nOrange coloring indicate p values deriving from distribution A and C (truly differing)._\n\n\nThe pvalue distribution of the tests resulting from truly differing populations are \u003Cb\u003Eright skewed\u003C/b\u003E, while the null tests again show a homogeneous distribution between 0 and 1. \nMany, but not all of the tests that come from the truly differing populations are below 0.05, and therefore would be reported as significant.\nIn average 350 null features would be reported as significant even though they derive from null features (blue bars, 10,000 x 0.7 x 0.05 = 350).\n\n\n##The multiple testing problem\n\nThe hypothesis testing framework with the p value definition given above was \u003Cb\u003Edeveloped for performing just one test. If many tests are performed, like in modern high throughput studies, the probability to obtain a \nfalse positive result increases.\u003C/b\u003E The probability of at least one false positive is called Familywise error rate (FWER) and can be determined by $FWER=1-(1-\\alpha)^m$ where \n$\\alpha$ corresponds to the significance threshold (here 0.05) and $m$ is the number of performed tests.\n\n*)\n\n(***hide***)\n\nlet bonferroniLine = \n    Shape.init(ShapeType.Line,0.,35.,0.05,0.05,Line=Line.init(Dash=DrawingStyle.Dash))\n\nlet fwer = \n    [1..35]\n    |\u003E List.map (fun x -\u003E \n        x,(1. - (1. - 0.05)**(float x))\n        )\n    |\u003E Chart.Point\n    //|\u003E Chart.withAxisTitles \u0022#tests\u0022 \u0022p(at least one FP)\u0022 \n    |\u003E Chart.withXAxisStyle \u0022#tests\u0022\n    |\u003E Chart.withYAxisStyle(\u0022p(at least one FP)\u0022,MinMax=(0.,1.))\n    |\u003E Chart.withShape bonferroniLine\n    |\u003E Chart.withTitle \u0022FWER\u0022\n\n(*** condition: ipynb ***)\n#if IPYNB\nfwer\n#endif // IPYNB\n\n(**\u003Ccenter\u003E*)\n(***hide***)\nfwer |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\u003C/center\u003E\n\n_Fig 3: Family wise error rate depending on number of performed tests. The black dashed line indicates the Bonferroni corrected FWER by $p^* = \\frac{\\alpha}{m}$ ._\n\n\nWhen 10,000 null features are tested with a p value threshold of 0.05, in average 500 tests are reported significant even if there is not a single comparisons in which the \npopulation differ. **If some of the features are in fact different, the number of false positives consequently decreases (remember, the p value is defined for tests of null features).**\n\nWhy the interpretation of high throughput data based on p values is difficult: The more features are measured, the more false positives you can expect. If 100 differentially \nexpressed genes are identified by p value thresholding, without further information about the magnitude of expected changes and the total number of measured transcripts, the \ndata is useless. \n\nThe p value threshold has no straight-forward interpretation when many tests are performed. Of course you could restrict the family wise error rate to 0.05, regardless \nhow many tests are performed. This is realized by dividing the $\\alpha$ significance threshold by the number of tests, which is known as Bonferroni correction: $p^* = \\frac{\\alpha}{m}$.\nThis correction drastically limit the false positive rate, but in an experiment with a huge count of expected changes, it additionally would result in many false negatives. The \nFWER should be chosen if the costs of follow up studies to tests the candidates are dramatic or there is a huge waste of time to potentially study false positives.\n\n##False discovery rate\n\nA more reasonable measure of significance with a simple interpretation is the so called false discovery rate (FDR). **It describes the rate of expected false positives within the \noverall reported significant features.** The goal is to identify as many sig. features as possible while incurring a relatively low proportion of false positives.\nConsequently a set of reported significant features together with the \u003Cb\u003EFDR describes the confidence of this set\u003C/b\u003E, without the requirement to \nsomehow incorporate the uncertainty that is introduced by the total number of tests performed. In the simulated case of 7,000 null tests and 3,000 tests resulting from truly \ndiffering distributions above, the FDR can be calculated exactly. Therefore at e.g. a p value of 0.05 the number of false positives (blue in red box) are divided by the number \nof significant reported tests (false positives \u002B true positives). \n\n\n\n\n\u003Cbr\u003E\n\u003Chr\u003E\n\n\u003Ccenter\u003E\u003Cimg style=\u0022max-width:75%\u0022 src=\u0022../../images/qvalue_03.svg\u0022\u003E\u003C/img\u003E\u003C/center\u003E\n\n_Fig 4: p value distribution of the alternative hypothesis._\n\u003Chr\u003E\n\u003Cbr\u003E\n\nGiven the conditions described in the first chapter, the FDR of this experiment with a p value threshold of 0.05 is 0.173. Out of the 2019 reported significant comparisons, in average 350 \nare expected to be false positives, which gives an straight forward interpretation of the data confidence. In real-world experiments the proportion of null tests and tests \nderiving from an actual difference is of course unknown. **The proportion of null tests however tends to be distributed equally in the p value histogram.** By identification of \nthe average null frequency, a proportion of FP and TP can be determined and the FDR can be defined. This frequency estimate is called $\\pi_0$, which leads to an FDR definition of:\n\n\n\n\u003Cbr\u003E\n\n\n\u003Ccenter\u003E\u003Cimg style=\u0022max-width:75%\u0022 src=\u0022../../images/qvalue_04.svg\u0022\u003E\u003C/img\u003E\u003C/center\u003E\n\n_Fig 5: FDR calculation on simulated data._\n\n\u003Cbr\u003E\n\n*)\n\n\n\n(**\n\n\n\n###q value\n\nConsequently for each presented p value a corresponding FDR can be calculated. The minimum local FDR at each p value is called q value. \n\n$$\\hat q(p_i) = min_{t \\geq p_i} \\hat{FDR}(p_i)$$\n\n\nSince the q value is not monotonically increasing, it is smoothed by assigning the lowest FDR of all p values, that are equal or higher the current one.\n\n**By defining $\\pi_0$, all other parameters can be calculated from the given p value distribution to determine the all q values.** The most prominent \nFDR-controlling method is known as Benjamini-Hochberg correction. It sets $\\pi_0$ as 1, assuming that all features are null. In studies with an expected high proportion of true \npositives, a $\\pi_0$ of 1 is too conservative, since there definitely are true positives in the data. \n\nA better estimation of $\\pi_0$ is given in the following:\n\n\u003Cb\u003ETrue positives are assumed to be right skewed while null tests are distributed equally between 0 and 1\u003C/b\u003E. Consequently the right flat region of the p value histogram tends to correspond \nto the true frequency of null comparisons (Fig 5). As \u003Cb\u003Ereal world example\u003C/b\u003E 9856 genes were measured in triplicates under two conditions (control and treatment). The p value distribution of two \nsample t tests looks as follows:\n\n\n*)\n\nlet examplePVals = \n    let rawData = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/pvalExample.txt\u0022\n    rawData.Split \u0027\\n\u0027\n    |\u003E Array.tail\n    |\u003E Array.map float\n\n(***hide***)\n\n//number of tests\nlet m =  \n    examplePVals\n    |\u003E Array.length\n    |\u003E float\n\nlet nullLine =\n    Shape.init(ShapeType.Line,0.,1.,1.,1.,Line=Line.init(Dash=DrawingStyle.Dash))\n\nlet empLine =\n    Shape.init(ShapeType.Line,0.,1.,0.4,0.4,Line=Line.init(Dash=DrawingStyle.DashDot,Color=Color.fromHex \u0022#FC3E36\u0022))\n\nlet exampleDistribution = \n    [\n        [\n        examplePVals\n        |\u003E Distributions.Frequency.create 0.025\n        |\u003E Map.toArray \n        |\u003E Array.map (fun (k,c) -\u003E k,float c / (m * 0.025))\n        |\u003E Chart.Column\n        |\u003E Chart.withTraceName \u0022density\u0022\n        //|\u003E Chart.withAxisTitles \u0022p value\u0022 \u0022density\u0022\n        |\u003E Chart.withXAxisStyle \u0022p value\u0022\n        |\u003E Chart.withYAxisStyle \u0022density\u0022\n        |\u003E Chart.withShapes [nullLine;empLine]\n\n        examplePVals\n        |\u003E Distributions.Frequency.create 0.025\n        |\u003E Map.toArray \n        |\u003E Array.map (fun (k,c) -\u003E k,float c)\n        |\u003E Chart.Column\n        |\u003E Chart.withTraceName \u0022gene count\u0022\n        //|\u003E Chart.withAxisTitles \u0022p value\u0022 \u0022gene count\u0022\n        |\u003E Chart.withXAxisStyle \u0022p value\u0022\n        |\u003E Chart.withYAxisStyle \u0022gene count\u0022\n        ]\n    ]\n    |\u003E Chart.Grid()\n    |\u003E Chart.withSize(1100.,550.)\n\n\n(*** condition: ipynb ***)\n#if IPYNB\nexampleDistribution\n#endif // IPYNB\n\n(**\u003Ccenter\u003E*)\n(***hide***)\nexampleDistribution |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\u003C/center\u003E\n\n_Fig 6: p value distributions of real world example. The frequency is given on the right, its density on the left. The black dashed line indicates the distribution, if all features\nwere null. The red dash-dotted line indicates the visual estimated pi0._\n\n\u003Cbr\u003E\n\u003Chr\u003E\n\n\n\nBy performing t tests for all comparisons 3743 (38 %) of the genes lead to a pvalue lower than 0.05.\nBy eye, you would estimate $\\pi_0$ as 0.4, indicating, only a small fraction of the genes are unaltered (null). After q value calculations, you would filter for a specific FDR (e.g. 0.05) and \nend up with an p value threshold of 0.04613, indicating a FDR of max. 0.05 in the final reported 3642 genes. \n\n\u0060\u0060\u0060no-highlight\npi0     = 0.4\nm       = 9856\nD(p)    = number of sig. tests at given p\nFP(p)   = p*0.4*9856\nFDR(p)  = FP(p) / D(p)\n\u0060\u0060\u0060\n\nFDR(0.04613) = 0.4995 \n\u003Cbr\u003E\n\n\n*)\n(***hide***)\nlet pi0 = 0.4\n\nlet getD p = \n    examplePVals \n    |\u003E Array.sumBy (fun x -\u003E if x \u003C= p then 1. else 0.) \n\nlet getFP p = p * pi0 * m\n\nlet getFDR p = (getFP p) / (getD p)\n\nlet qvaluesNotSmoothed = \n    examplePVals\n    |\u003E Array.sort\n    |\u003E Array.map (fun x -\u003E \n        x, getFDR x)\n    |\u003E Chart.Line \n    |\u003E Chart.withTraceName \u0022not smoothed\u0022\nlet qvaluesSmoothed = \n    let pValsSorted =\n        examplePVals\n        |\u003E Array.sortDescending\n    let rec loop i lowest acc  = \n        if i = pValsSorted.Length then \n            acc |\u003E List.rev\n        else \n            let p = pValsSorted.[i]\n            let q = getFDR p\n            if q \u003E lowest then  \n                loop (i\u002B1) lowest ((p,lowest)::acc)\n            else loop (i\u002B1) q ((p,q)::acc)\n    loop 0 1. []\n    |\u003E Chart.Line\n    |\u003E Chart.withTraceName \u0022smoothed\u0022\nlet eXpos = examplePVals |\u003E Array.filter (fun x -\u003E x \u003C= 0.046135) |\u003E Array.length\nlet p2qValeChart =\n    [qvaluesNotSmoothed;qvaluesSmoothed]\n    |\u003E Chart.combine\n    |\u003E Chart.withYAxisStyle(\u0022\u0022,MinMax=(0.,1.))\n    //|\u003E Chart.withAxisTitles \u0022p value\u0022 \u0022q value\u0022\n    |\u003E Chart.withXAxisStyle \u0022p value\u0022\n    |\u003E Chart.withYAxisStyle \u0022q value\u0022\n    |\u003E Chart.withShape empLine\n    |\u003E Chart.withTitle (sprintf \u0022#[genes with q value \u003C 0.05] = %i\u0022 eXpos)\n\n\n(*** condition: ipynb ***)\n#if IPYNB\np2qValeChart\n#endif // IPYNB\n\n(**\u003Ccenter\u003E*)\n(***hide***)\np2qValeChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\u003C/center\u003E\n\n_Fig 7: FDR calculation on experiment data. Please zoom into the very first part of the curve to inspect the monotonicity._\n\u003Chr\u003E\n\n\n\n###The automatic detection of $\\pi_0$ is facilitated as follows\n\n\nFor a range of $\\lambda$ in e.g. $\\{0.0  ..  0.05  ..  0.95\\}$, calculate $\\hat \\pi_0 (\\lambda) = \\frac {\\#[p_j \u003E \\lambda]}{m(1 - \\lambda)}$\n\n*)\n\n\nlet pi0Est = \n    [|0. .. 0.05 .. 0.95|]\n    |\u003E Array.map (fun lambda -\u003E \n        let num = \n            examplePVals \n            |\u003E Array.sumBy (fun x -\u003E if x \u003E lambda then 1. else 0.) \n        let den = float examplePVals.Length * (1. - lambda)\n        lambda, num/den\n        )\n\n(***hide***)\nlet pi0EstChart = \n    pi0Est \n    |\u003E Chart.Point\n    |\u003E Chart.withYAxisStyle(\u0022\u0022,MinMax=(0.,1.))\n    |\u003E Chart.withXAxisStyle(\u0022\u0022,MinMax=(0.,1.))\n    //|\u003E Chart.withAxisTitles \u0022$\\lambda$\u0022 \u0022$\\hat \\pi_0(\\lambda)$\u0022\n    |\u003E Chart.withXAxisStyle \u0022$\\lambda$\u0022\n    |\u003E Chart.withYAxisStyle \u0022$\\hat \\pi_0(\\lambda)$\u0022\n    |\u003E Chart.withMathTex(true)\n    |\u003E Chart.withConfig(\n        Config.init(\n            Responsive=true, \n            ModeBarButtonsToAdd=[\n                ModeBarButton.DrawLine\n                ModeBarButton.DrawOpenPath\n                ModeBarButton.EraseShape\n                ]\n            )\n        )\n\n\n(*** condition: ipynb ***)\n#if IPYNB\npi0EstChart\n#endif // IPYNB\n\n(**\u003Ccenter\u003E*)\n(***hide***)\npi0EstChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\u003C/center\u003E\n\n_Fig 8: pi0 estimation._\n\u003Chr\u003E\n\nThe resulting diagram shows, that with increasing $\\lambda$ its function value $\\hat \\pi_0(\\lambda)$ tends to $\\pi_0$. The calculation \u003Cb\u003Erelates the actual proportion of tests greater than $\\lambda$ to the proportion of $\\lambda$ range the corresponding p values are in\u003C/b\u003E.\nIn Storey \u0026 Tibshirani 2003 this curve is fitted with a \u003Cb\u003Ecubic spline\u003C/b\u003E. A weighting of the knots by $(1 - \\lambda)$ is recommended \nbut not specified in the final publication. Afterwards the function value at $\\hat \\pi_0(1)$ is defined as final estimator of $\\pi_0$. This is often referred to as the _smoother method_.\n\nAnother method (_bootstrap method_) (Storey et al., 2004), that does not depend on fitting is based on \u003Cb\u003Ebootstrapping\u003C/b\u003E and was introduced in Storey et al. (2004). It is implemented in FSharp.Stats:\n\n  1. Determine the minimal $\\hat \\pi_0 (\\lambda)$ and call it $min \\hat \\pi_0$ . \n\n  2. For each $\\lambda$, bootstrap the p values (e.g. 100 times) and calculate the mean squared error (MSE) from the difference of resulting $\\hat \\pi_0^b$ to $min  \\hat \\pi_0$. The minimal MSE indicates the best $\\lambda$. With $\\lambda$ \ndefined, $\\pi_0$ can be determined. \u003Cb\u003ENote: When bootstrapping an data set of size n, n elements are drawn with replacement.\u003C/b\u003E\n\n\n\n*)\n\n\n(***hide***)\nlet getpi0Bootstrap (lambda:float[]) (pValues:float[]) =\n    let rnd = System.Random()\n    let m = pValues.Length |\u003E float\n    let getpi0hat lambda pVals=\n        let hits = \n            pVals \n            |\u003E Array.sumBy (fun x -\u003E if x \u003E lambda then 1. else 0.) \n        hits / (m * (1. - lambda))\n    \n    //calculate MSE for each lambda\n    let getMSE lambda =\n        let mse = \n            //generate 100 bootstrap samples of p values and calculate the MSE at given lambda\n            Array.init 100 (fun b -\u003E \n                Array.sampleWithReplacement rnd pValues pValues.Length  \n                |\u003E getpi0hat lambda\n                )\n        mse\n    lambda\n    |\u003E Array.map (fun l -\u003E l,getMSE l)\n    \n\nlet minimalpihat = \n    //FSharp.Stats.Testing.MultipleTesting.Qvalues.pi0hats  [|0. .. 0.05 .. 0.96|] examplePVals |\u003E Array.minBy snd |\u003E snd\n    0.3686417749\n\nlet minpiHatShape = \n    Shape.init(ShapeType.Line,0.,1.,minimalpihat,minimalpihat,Line=Line.init(Dash=DrawingStyle.Dash))\n\nlet bootstrappedPi0 =\n    getpi0Bootstrap [|0. .. 0.05 .. 0.95|] examplePVals\n    |\u003E Array.map (fun (l,x) -\u003E \n        Chart.BoxPlot(x=Array.init x.Length (fun _ -\u003E l),y=x,Fillcolor=Color.fromHex\u0022#1F77B4\u0022,MarkerColor=Color.fromHex\u0022#1F77B4\u0022,Name=sprintf \u0022%.2f\u0022 l))\n    |\u003E Chart.combine\n    |\u003E Chart.withYAxisStyle(\u0022\u0022,MinMax=(0.,1.))\n    //|\u003E Chart.withAxisTitles \u0022$\\lambda$\u0022 \u0022$\\hat \\pi_0$\u0022\n    |\u003E Chart.withXAxisStyle \u0022$\\lambda$\u0022\n    |\u003E Chart.withYAxisStyle \u0022$\\hat \\pi_0$\u0022\n    |\u003E Chart.withMathTex(true)\n    |\u003E Chart.withShape minpiHatShape\n    |\u003E Chart.withConfig(\n        Config.init(\n            Responsive=true, \n            ModeBarButtonsToAdd=[\n                ModeBarButton.DrawLine\n                ModeBarButton.DrawOpenPath\n                ModeBarButton.EraseShape\n                ]\n            )\n        )\n\n\n(*** condition: ipynb ***)\n#if IPYNB\nbootstrappedPi0\n#endif // IPYNB\n\nbootstrappedPi0 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n\n_Fig 9: Bootstrapping for pi0 estimation. The dashed line indicates the minimal pi0 from Fig. 8.\nThe bootstrapped pi0 distribution that shows the least variation to the dashed line is the optimal. In the presented example it is either 0.8 or 0.85._\n\u003Chr\u003E\n\nFor an $\\lambda$, range of $\\{0.0  ..  0.05  ..  0.95\\}$ the bootstrapping method determines either 0.8 or 0.85 as optimal $\\lambda$ and therefore $optimal  \\hat \\pi_0$ is either $0.3703$ or $0.3686$.\n\nThe \u003Cb\u003Eautomated estimation\u003C/b\u003E of $\\pi_0$ based on bootstrapping is implemented in \u0060FSharp.Stats.Testing.MultipleTesting.Qvalues\u0060.\n\n*)\nopen Testing.MultipleTesting\n\nlet pi0Stats = Qvalues.pi0BootstrapWithLambda [|0.0 .. 0.05 .. 0.95|] examplePVals\n\n\n(*** condition: ipynb ***)\n#if IPYNB\npi0Stats\n#endif // IPYNB\n\n(***hide***)\npi0Stats \n(***include-it***)\n\n\n(**\nSubsequent to $\\pi_0$ estimation the \u003Cb\u003Eq values can be determined\u003C/b\u003E from a list of p values.\n*)\n\nlet qValues = Qvalues.ofPValues pi0Stats examplePVals\n\n(*** condition: ipynb ***)\n#if IPYNB\nqValues\n#endif // IPYNB\n\n(***hide***)\nqValues \n(***include-it***)\n\n(**\n###Variants\n\nA robust variant of q value determination exists, that is more conservative for small p values when\nthe total number of p values is low. Here the number of false positives is divided by the number of \ntotal discoveries multiplied by the FWER at the current p value. The correction takes into account \nthe probability of a false positive being reported in the first place.\n\nEspecially when the population distributions do not follow a perfect normal distribution or the p value distribution looks strange, \nthe usage of the robust version is recommended.\n\n\u003Ccenter\u003E\n\n$qval = {\\#FP \\over \\#Discoveries}$ \n\n$qval_{robust} = {\\#FP \\over \\#Discoveries \\times (1-(1-p)^m)}$ \n\n\u003C/center\u003E\n\n*)\n\nlet qvaluesRobust = \n    Testing.MultipleTesting.Qvalues.ofPValuesRobust pi0Stats examplePVals\n\nlet qChart =    \n    [\n        Chart.Line(Array.sortBy fst (Array.zip examplePVals qValues),Name=\u0022qValue\u0022)\n        Chart.Line(Array.sortBy fst (Array.zip examplePVals qvaluesRobust),Name=\u0022qValueRobust\u0022)\n    ]\n    |\u003E Chart.combine\n    //|\u003E Chart.withAxisTitles \u0022p value\u0022 \u0022q value\u0022\n    |\u003E Chart.withXAxisStyle \u0022p value\u0022\n    |\u003E Chart.withYAxisStyle \u0022q value\u0022\n\n(*** condition: ipynb ***)\n#if IPYNB\nqChart\n#endif // IPYNB\n\n(***hide***)\nqChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n(**\n_Fig 10: Comparison of q values and robust q values, that is more conservative at low p values._\n\n\n##Quality plots\n\n*)\n\nlet pi0Line = \n    Shape.init(ShapeType.Line,0.,1.,pi0Stats,pi0Stats,Line=Line.init(Dash=DrawingStyle.Dash))\n\n// relates the q value to each p value\nlet p2q = \n    Array.zip examplePVals qValues\n    |\u003E Array.sortBy fst\n    |\u003E Chart.Line\n    |\u003E Chart.withShape pi0Line\n    //|\u003E Chart.withAxisTitles \u0022p value\u0022 \u0022q value\u0022\n    |\u003E Chart.withXAxisStyle \u0022p value\u0022\n    |\u003E Chart.withYAxisStyle \u0022q value\u0022\n\n// shows the p values distribution for an visual inspection of pi0 estimation\nlet pValueDistribution =\n    let frequencyBins = 0.025 \n    let m = examplePVals.Length |\u003E float\n    examplePVals \n    |\u003E Distributions.Frequency.create frequencyBins \n    |\u003E Map.toArray \n    |\u003E Array.map (fun (k,c) -\u003E k,float c / frequencyBins / m) \n    |\u003E Chart.StackedColumn \n    |\u003E Chart.withTraceName \u0022p values\u0022\n    //|\u003E Chart.withAxisTitles \u0022p value\u0022 \u0022frequency density\u0022\n    |\u003E Chart.withXAxisStyle \u0022p value\u0022\n    |\u003E Chart.withYAxisStyle \u0022frequency density\u0022\n    |\u003E Chart.withShape pi0Line\n\n// shows pi0 estimation in relation to lambda\nlet pi0Estimation = \n    //Testing.MultipleTesting.Qvalues.pi0hats [|0. .. 0.05 .. 0.96|] examplePVals\n    [|0. .. 0.05 .. 0.95|]\n    |\u003E Array.map (fun lambda -\u003E \n        let num =   \n            examplePVals \n            |\u003E Array.sumBy (fun x -\u003E if x \u003E lambda then 1. else 0.)\n        let den = float examplePVals.Length * (1. - lambda)\n        lambda, num/den\n        )\n    |\u003E Chart.Point\n    //|\u003E Chart.withAxisTitles \u0022$\\lambda$\u0022 \u0022$\\hat \\pi_0(\\lambda)$\u0022\n    |\u003E Chart.withXAxisStyle \u0022$\\lambda$\u0022\n    |\u003E Chart.withYAxisStyle \u0022$\\hat \\pi_0(\\lambda)$\u0022\n    |\u003E Chart.withMathTex(true)\n\n\n\n(*** condition: ipynb ***)\n#if IPYNB\np2q\n#endif // IPYNB\n\n(***hide***)\np2q |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n_Fig 11: p value relation to q values. At a p value of 1 the q value is equal to pi0 (black dashed line)._\n*)\n\n(*** condition: ipynb ***)\n#if IPYNB\npValueDistribution\n#endif // IPYNB\n\n(***hide***)\npValueDistribution |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n_Fig 12: p value density distribution. The dashed line indicates pi0 estimated by Storeys bootstrapping method._\n*)\n\n(*** condition: ipynb ***)\n#if IPYNB\npi0Estimation\n#endif // IPYNB\n\n(***hide***)\npi0Estimation |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n_Fig 13: Visual pi0 estimation._\n*)\n\n(**\n##Definitions and Notes\n  - Benjamini-Hochberg (BH) correction is equal to q values with $\\pi_0 = 1$\n  - Storey \u0026 Tibshirani (2003):\n    - _\u0022The 0.05 q-value cut-off is arbitrary, and we do not recommend that this value necessarily be used.\u0022_\n    - _\u0022The q-value for a particular feature is the expected proportion of false positives occurring up through that feature on the list.\u0022_\n    - _\u0022The precise definition of the q-value for a particular feature is the following. The q-value for a particular feature is the minimum false discovery rate that can be attained when calling all features up through that one on the list significant.\u0022_\n    - _\u0022The Benjamini \u0026 Hochberg (1995) methodology also forces one to choose an acceptable FDR level before any data are seen, which is often going to be impractical.\u0022_\n  - To improve the q value estimation if the effects are asymmetric, meaning that negative effects are stronger than positives, or vice versa a method was published in 2014 by Orr et al.. They estimate a global $m_0$ and then split the p values \n  in two groups before calculating q values for each p value set. The applicability of this strategy however is questionable, as the number of up- and downregulated features must be equal, which is not the case in most biological experimental setups.\n  - The distinction of FDR and pFDR (positive FDR) is not crucial in the presented context, because in high throughput experiments with m\u003E\u003E100: Pr(R \u003E 0) ~ 1 (Storey \u0026 Tibshirani, 2003, Appendix Remark A).\n  - The local FDR (lFDR) is sometimes referred to as the probability that for the current p value the null hypothesis is true (Storey 2011).\n  - If you have found typos, errors, or misleading statements, please feel free to file a pull request or contact me.\n\n\n##FAQ\n  - Why are q values lower than their associated p values?\n    - q values are not necessarily greater than their associated p values. q values can maximal be pi0. The definition of p values is not the same as for q values! A q\n    value defines what proportion of the reported discoveries may be false.\n\n  - Which cut off should I use?\n    - _\u0022The 0.05 q-value cut-off is arbitrary, and we do not recommend that this value necessarily be used.\u0022_ (Storey 2003). It depends on your experimental design and the number of false positives you are willing to accept.\n    If there are _20 discoveries_, you may argue to accept if _2_ of them are false positives (FDR=0.1). On the other hand, if there are _10,000 discoveries_ with _1,000 false positives_ (FDR=0.1) you may should reduce the FDR. Thereby the \n    proportion of false positives decreases. Of course in this case the number of positives will decrease as well. It all breaks down to the matter of willingness to accept a certain number of false positives within your study. \n    Studies, that aim to identify the presence of an specific protein of interest, the FDR should be kept low, because it inflates the risk, that this particular candidate is a false positive.\n    If confirmatory follow up studies are cheap, you can increase the FDR, if they are **expensive**, you should restrict the number of false positives to **avoid unpleasant discussions with your supervisor**. \n    \n  - In my study gene RBCM has an q value of 0.03. Does that indicate, there is a 3% chance, that it is an false positive?\n    - No, actually the change that this particular gene is an false positive may actually be higher, because there may be genes that are much more significant than MSH2. The q value indicates, \n    that 3% of the genes that are as or more extreme than RBCM are false positives (Storey 2003).\n\n  - Should I use the default or robust version for my study?\n\n  - When should I use q values over BH correction, or other multiple testing variants?\n    - There is no straight forward answer to this question. If you are able to define a confident pi0 estimate by eye when inspecting the p value distribution, then the q value approach may be feasible.\n    If you struggle in defining pi0, because the p value distribution has an odd shape or there are too few p values on which you base your estimate, it is better to choose the more conservative BH correction, or even\n    consider other methodologies.\n\n##References\n  - Storey JD, Tibshirani R, Statistical significance for genomewide studies, 2003 [DOI: 10.1073/pnas.1530509100](https://www.pnas.org/content/100/16/9440)\n  - Storey JD, Taylor JE, Siegmund D, Strong Control, Conservative Point Estimation and Simultaneous Conservative Consistency of False Discovery Rates: A Unified Approach, 2004, [http://www.jstor.org/stable/3647634](https://www.jstor.org/stable/3647634?seq=1#metadata_info_tab_contents).\n  - Storey JD, Princeton University, 2011, [preprint](http://genomics.princeton.edu/storeylab/papers/Storey_FDR_2011.pdf)\n  - Orr M, Liu P, Nettleton D, An improved method for computing q-values when the distribution of effect sizes is asymmetric, 2014, [doi: 10.1093/bioinformatics/btu432](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4609005/)\n  - NettletonD et al., Estimating the Number of True Null Hypotheses from a Histogram of p Values., 2006, http://www.jstor.org/stable/27595607.\n  - Benjamini Y, Hochberg Y, On the Adaptive Control of the False Discovery Rate in Multiple Testing With Independent Statistics, 2000, [doi:10.3102/10769986025001060](https://journals.sagepub.com/doi/10.3102/10769986025001060)\n\n*)\n"},{"uri":"https://fslab.org/introductionIII.html","title":"F# Introduction III: Library Setup\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: F# Introduction III: Library Setup\ncategory: fsharp\nauthors: Kevin Schneider, Jonathan Ott\nindex: 3\n---\n*)\n\n(***hide***)\n#r \u0022nuget: BlackFox.Fake.BuildTask\u0022\n#r \u0022nuget: Fake.Core.Target\u0022\n#r \u0022nuget: Fake.Core.Process\u0022\n#r \u0022nuget: Fake.Core.ReleaseNotes\u0022\n#r \u0022nuget: Fake.IO.FileSystem\u0022\n#r \u0022nuget: Fake.DotNet.Cli\u0022\n#r \u0022nuget: Fake.DotNet.MSBuild\u0022\n#r \u0022nuget: Fake.DotNet.AssemblyInfoFile\u0022\n#r \u0022nuget: Fake.DotNet.Paket\u0022\n#r \u0022nuget: Fake.DotNet.FSFormatting\u0022\n#r \u0022nuget: Fake.DotNet.Fsi\u0022\n#r \u0022nuget: Fake.DotNet.NuGet\u0022\n#r \u0022nuget: Fake.Api.Github\u0022\n#r \u0022nuget: Fake.DotNet.Testing.Expecto \u0022\n#r \u0022nuget: Fake.Tools.Git\u0022\n\n(**\n# F# Introduction III: Library Setup\n\nThis guide shows an example setup for a library. This is not the only way on how to do this, but merely a possibility. As always, this guide is meant as a starting point to be expanded upon. \nFor example, unit tests and full buildchains with automatic releases can be added to this template. \nThe installation of .NET 5.0 or dotnet SDK 3.1 LTS is required. It is also recommended to use [GitHub](https://github.com/) when following this example.\n\n## Initializing the repository\n\n* An easy way to initialize a repository is by creating a new one using GitHub and cloning it.\n    * You can automatically add a readme, a .gitignore with many entries for Visual Studio already added and a license of choice.\n\n    ![]({{root}}images/InitRepo.png)\n\n* After you cloned the initialized repository, it should look like this:  \n\n    ![]({{root}}images/Lib1.png)\n\n## Initializing the library\n\n* The stock library template is just fine (change framework if you know what you are doing):\n    \u0060dotnet new classlib -lang F# -n \u0022YourNameHere\u0022 --framework net5.0 -o src/YourNameHere\u0060\n* Add an entry for the \u0027pkg\u0027 folder to your \u0060.gitignore\u0060\n* Create a \u0060RELEASE_NOTES.md\u0060 file in the project root, make sure to add at least one version header like this:\n\n\u0060\u0060\u0060\n### 0.0.1 - 28/7/2021\n\u0060\u0060\u0060\n* Add a solution to your projekt with \u0060dotnet new sln --name YourNameHere\u0060\n* After you completed the previous steps your folder should look like this:  \n\n    ![]({{root}}images/Lib2.png)\n\n## Initializing the buildchain with FAKE\n\n* Initialize a local tool manifest that will keep track of the usable local dotnet tools in this project.\n    * In the project root: \u0060dotnet new tool-manifest\u0060\n* In the project root: Install the fake cli as local tool: \u0060dotnet tool install fake-cli\u0060\n* In the project root: Install paket as local tool: \u0060dotnet tool install paket\u0060\n* In the project root: Create a new empty \u0060build.fsx\u0060 file\n* Your folder should now look like this:  \n\n    ![]({{root}}images/Lib3.png)\n\n* Open the \u0060build.fsx\u0060 file (intellisense will not work right after creating it) and add the following content.\n\nFirst, lets reference the dependencies of the build script. In fake they are loaded via the \u0060paket\u0060 manager:\n\n\u0060\u0060\u0060fsharp\n#r \u0022paket:\nnuget BlackFox.Fake.BuildTask\nnuget Fake.Core.Target\nnuget Fake.Core.Process\nnuget Fake.Core.ReleaseNotes\nnuget Fake.IO.FileSystem\nnuget Fake.DotNet.Cli\nnuget Fake.DotNet.MSBuild\nnuget Fake.DotNet.AssemblyInfoFile\nnuget Fake.DotNet.Paket\nnuget Fake.DotNet.FSFormatting\nnuget Fake.DotNet.Fsi\nnuget Fake.DotNet.NuGet\nnuget Fake.Api.Github\nnuget Fake.DotNet.Testing.Expecto \nnuget Fake.Tools.Git //\u0022\n\u0060\u0060\u0060\n\nThen, we open the dependencies. Note that for getting intellisense, you will have to run the script once with the fake runner (see [here](#Running-the-build-script)).\n*)\n\n#if !FAKE\n#load \u0022./.fake/build.fsx/intellisense.fsx\u0022\n#r \u0022netstandard\u0022 // Temp fix for https://github.com/dotnet/fsharp/issues/5216\n#endif\n\nopen BlackFox.Fake\nopen System.IO\nopen Fake.Core\nopen Fake.DotNet\nopen Fake.IO\nopen Fake.IO.FileSystemOperators\nopen Fake.IO.Globbing.Operators\nopen Fake.Tools\n\n[\u003CAutoOpen\u003E]\n/// user interaction prompts for critical build tasks where you may want to interrupt when you see wrong inputs.\nmodule MessagePrompts =\n\n    let prompt (msg:string) =\n        System.Console.Write(msg)\n        System.Console.ReadLine().Trim()\n        |\u003E function | \u0022\u0022 -\u003E None | s -\u003E Some s\n        |\u003E Option.map (fun s -\u003E s.Replace (\u0022\\\u0022\u0022,\u0022\\\\\\\u0022\u0022))\n\n    let rec promptYesNo msg =\n        match prompt (sprintf \u0022%s [Yn]: \u0022 msg) with\n        | Some \u0022Y\u0022 | Some \u0022y\u0022 -\u003E true\n        | Some \u0022N\u0022 | Some \u0022n\u0022 -\u003E false\n        | _ -\u003E System.Console.WriteLine(\u0022Sorry, invalid answer\u0022); promptYesNo msg\n\n    let releaseMsg = \u0022\u0022\u0022This will stage all uncommitted changes, push them to the origin and bump the release version to the latest number in the RELEASE_NOTES.md file. \n        Do you want to continue?\u0022\u0022\u0022\n\n    let releaseDocsMsg = \u0022\u0022\u0022This will push the docs to gh-pages. Remember building the docs prior to this. Do you want to continue?\u0022\u0022\u0022\n\n/// Executes a dotnet command in the given working directory\nlet runDotNet cmd workingDir =\n    let result =\n        DotNet.exec (DotNet.Options.withWorkingDirectory workingDir) cmd \u0022\u0022\n    if result.ExitCode \u003C\u003E 0 then failwithf \u0022\u0027dotnet %s\u0027 failed in %s\u0022 cmd workingDir\n(**\nNote: This \u0060build.fsx\u0060 will be gradually epxanded\n\n* Add the \u0060ProjectInfo\u0060 module to the \u0060build.fsx\u0060 file, which will contain all relevant metadata for the buildchain except nuget package metadata (more on that later).\n* Replace all strings with the correct ones for your project.\n*)\n/// Metadata about the project\nmodule ProjectInfo = \n\n    let project = \u0022LibraryExample\u0022\n\n    let summary = \u0022An example Library\u0022\n\n    let configuration = \u0022Release\u0022\n\n    // Git configuration (used for publishing documentation in gh-pages branch)\n    // The profile where the project is posted\n    let gitOwner = \u0022YourGitProfile\u0022\n    let gitName = \u0022YourNameHere\u0022\n\n    let gitHome = sprintf \u0022%s/%s\u0022 \u0022https://github.com\u0022 gitOwner\n\n    let projectRepo = sprintf \u0022%s/%s/%s\u0022 \u0022https://github.com\u0022 gitOwner gitName\n\n    let website = \u0022/YourNameHere\u0022\n\n    let pkgDir = \u0022pkg\u0022\n\n    let release = ReleaseNotes.load \u0022RELEASE_NOTES.md\u0022\n\n    let stableVersion = SemVer.parse release.NugetVersion\n\n    let stableVersionTag = (sprintf \u0022%i.%i.%i\u0022 stableVersion.Major stableVersion.Minor stableVersion.Patch )\n\n    let mutable prereleaseSuffix = \u0022\u0022\n\n    let mutable prereleaseTag = \u0022\u0022\n\n    let mutable isPrerelease = false\n(**\n* Add the \u0060BasicTasks\u0060 module to the \u0060build.fsx\u0060 file, which will contain the minimal build chain.\n*)\n/// Barebones, minimal build tasks\nmodule BasicTasks = \n\n    open ProjectInfo\n\n    let setPrereleaseTag = BuildTask.create \u0022SetPrereleaseTag\u0022 [] {\n        printfn \u0022Please enter pre-release package suffix\u0022\n        let suffix = System.Console.ReadLine()\n        prereleaseSuffix \u003C- suffix\n        prereleaseTag \u003C- (sprintf \u0022%s-%s\u0022 release.NugetVersion suffix)\n        isPrerelease \u003C- true\n    }\n\n    let clean = BuildTask.create \u0022Clean\u0022 [] {\n        !! \u0022src/**/bin\u0022\n        \u002B\u002B \u0022src/**/obj\u0022\n        \u002B\u002B \u0022pkg\u0022\n        \u002B\u002B \u0022bin\u0022\n        |\u003E Shell.cleanDirs \n    }\n\n    let build = BuildTask.create \u0022Build\u0022 [clean] {\n        !! \u0022src/**/*.*proj\u0022\n        |\u003E Seq.iter (DotNet.build id)\n    }\n\n    let copyBinaries = BuildTask.create \u0022CopyBinaries\u0022 [clean; build] {\n        let targets = \n            !! \u0022src/**/*.??proj\u0022\n            -- \u0022src/**/*.shproj\u0022\n            |\u003E  Seq.map (fun f -\u003E ((Path.getDirectory f) \u003C/\u003E \u0022bin\u0022 \u003C/\u003E configuration, \u0022bin\u0022 \u003C/\u003E (Path.GetFileNameWithoutExtension f)))\n        for i in targets do printfn \u0022%A\u0022 i\n        targets\n        |\u003E  Seq.iter (fun (fromDir, toDir) -\u003E Shell.copyDir toDir fromDir (fun _ -\u003E true))\n    }\n(**\n* At the bottom of the \u0060build.fsx\u0060 file, add the following lines:\n*)\nopen BasicTasks\nBuildTask.runOrDefault copyBinaries\n(**\n* Create a \u0060build.cmd\u0060 or \u0060build.sh\u0060 file (or both) with the following lines:\n\n### build.cmd\n\n\u0060\u0060\u0060shell\ndotnet tool restore\ndotnet fake build %*\n\u0060\u0060\u0060\n\n### build.sh\n\n\u0060\u0060\u0060shell\n#!/usr/bin/env bash\n\nset -eu\nset -o pipefail\n\ndotnet tool restore\ndotnet fake build \u0022$@\u0022\n\u0060\u0060\u0060\n\n## Running the build script\n\n* You can now run your build via calling either \u0060build.cmd\u0060 or \u0060build.sh\u0060.\n    * Optionally, you can pass the \u0060-t\u0060 argument with it to execute a specific build task, e.g \u0060./build.cmd -t clean\u0060 to execute the clean target.\n    * The first time you run the build.cmd will also enable intellisense for the fake build script\n* After building for the first time your folder will look like this:  \n\n    ![]({{root}}images/Lib4.png)\n\n## Packing a nuget package\n\n* Add nuget package metadata to the project file (src/LibraryExample/LibraryExample.fsproj) and adapt accordingly:\n\n\u0060\u0060\u0060\n\u003CPropertyGroup\u003E\n    \u003CAuthors\u003EYourName\u003C/Authors\u003E\n    \u003CDescription\u003EYour description here\u003C/Description\u003E\n    \u003CSummary\u003EYour summary here\u003C/Summary\u003E\n    \u003CPackageLicenseExpression\u003EMIT\u003C/PackageLicenseExpression\u003E\n    \u003CPackageProjectUrl\u003Ehttps://fslab.org/projectName/\u003C/PackageProjectUrl\u003E\n    \u003CPackageIconUrl\u003Ehttps://fslab.org/projectName/img/logo.png\u003C/PackageIconUrl\u003E\n    \u003CPackageTags\u003Edocumentation fsharp csharp dotnet\u003C/PackageTags\u003E\n    \u003CRepositoryUrl\u003Ehttps://github.com/fslaborg/projectName\u003C/RepositoryUrl\u003E\n    \u003CRepositoryType\u003Egit\u003C/RepositoryType\u003E\n    \u003CFsDocsLicenseLink\u003Ehttps://github.com/fslaborg/projectName/blob/master/LICENSE\u003C/FsDocsLicenseLink\u003E\n    \u003CFsDocsReleaseNotesLink\u003Ehttps://github.com/fslaborg/projectName/blob/master/RELEASE_NOTES.md\u003C/FsDocsReleaseNotesLink\u003E\n\u003C/PropertyGroup\u003E\n\u0060\u0060\u0060\n\n* Add the \u0060PackageTasks\u0060 module to the \u0060build.fsx\u0060 file, which will take care of building nuget packages for both stable and prerelease packages:\n*)\n\n/// Package creation\nmodule PackageTasks = \n\n    open ProjectInfo\n\n    open BasicTasks\n\n    let pack = BuildTask.create \u0022Pack\u0022 [clean; build; copyBinaries] {\n        if promptYesNo (sprintf \u0022creating stable package with version %s OK?\u0022 stableVersionTag ) \n            then\n                !! \u0022src/**/*.*proj\u0022\n                |\u003E Seq.iter (Fake.DotNet.DotNet.pack (fun p -\u003E\n                    let msBuildParams =\n                        {p.MSBuildParams with \n                            Properties = ([\n                                \u0022Version\u0022,stableVersionTag\n                                \u0022PackageReleaseNotes\u0022,  (release.Notes |\u003E String.concat \u0022\\r\\n\u0022)\n                            ] @ p.MSBuildParams.Properties)\n                        }\n                    {\n                        p with \n                            MSBuildParams = msBuildParams\n                            OutputPath = Some pkgDir\n                    }\n                ))\n        else failwith \u0022aborted\u0022\n    }\n\n    let packPrerelease = BuildTask.create \u0022PackPrerelease\u0022 [setPrereleaseTag; clean; build; copyBinaries] {\n        if promptYesNo (sprintf \u0022package tag will be %s OK?\u0022 prereleaseTag )\n            then \n                !! \u0022src/**/*.*proj\u0022\n                //-- \u0022src/**/Plotly.NET.Interactive.fsproj\u0022\n                |\u003E Seq.iter (Fake.DotNet.DotNet.pack (fun p -\u003E\n                            let msBuildParams =\n                                {p.MSBuildParams with \n                                    Properties = ([\n                                        \u0022Version\u0022, prereleaseTag\n                                        \u0022PackageReleaseNotes\u0022,  (release.Notes |\u003E String.toLines )\n                                    ] @ p.MSBuildParams.Properties)\n                                }\n                            {\n                                p with \n                                    VersionSuffix = Some prereleaseSuffix\n                                    OutputPath = Some pkgDir\n                                    MSBuildParams = msBuildParams\n                            }\n                ))\n        else\n            failwith \u0022aborted\u0022\n    }\n(**\n* You can test both targets with \u0060./build.cmd -t Pack\u0060 or \u0060./build.cmd -t PackPrerelease\u0060 respectively.\n* The packages can be found in the \u0060pkg\u0060 folder in the project root. Since you do not want to host your nuget packages on github, do also remove this folder from source control by adding /pkg to your .gitignore file.\n* If you want users of your nuget package to have a pleasant debugging experience you can make use of [sourcelink](https://github.com/dotnet/sourcelink).\n    * To install this package, navigate to the folder of your project, e.g. src/LibraryExample and call: \u0060dotnet add package Microsoft.SourceLink.GitHub --version 1.0.0\u0060\n\n## Documentation\n\n* In the project root: Install fsdocs as local tool: \u0060dotnet tool install FSharp.Formatting.CommandTool\u0060\n* In the project root: Install the fslab documentation template: \u0060dotnet new -i FsLab.DocumentationTemplate::*\u0060\n* Initialize the fslab documentation template: \u0060dotnet new fslab-docs\u0060\n* Add the \u0060DocumentationTasks\u0060 module to the \u0060build.fsx\u0060 file, which will take care initializing documentation files and developing them:\n*)\n/// Build tasks for documentation setup and development\nmodule DocumentationTasks =\n\n    open ProjectInfo\n\n    open BasicTasks\n\n    let buildDocs = BuildTask.create \u0022BuildDocs\u0022 [build; copyBinaries] {\n        printfn \u0022building docs with stable version %s\u0022 stableVersionTag\n        runDotNet \n            (sprintf \u0022fsdocs build --eval --clean --property Configuration=Release --parameters fsdocs-package-version %s\u0022 stableVersionTag)\n            \u0022./\u0022\n    }\n\n    let buildDocsPrerelease = BuildTask.create \u0022BuildDocsPrerelease\u0022 [setPrereleaseTag; build; copyBinaries] {\n        printfn \u0022building docs with prerelease version %s\u0022 prereleaseTag\n        runDotNet \n            (sprintf \u0022fsdocs build --eval --clean --property Configuration=Release --parameters fsdocs-package-version %s\u0022 prereleaseTag)\n            \u0022./\u0022\n    }\n\n    let watchDocs = BuildTask.create \u0022WatchDocs\u0022 [build; copyBinaries] {\n        printfn \u0022watching docs with stable version %s\u0022 stableVersionTag\n        runDotNet \n            (sprintf \u0022fsdocs watch --eval --clean --property Configuration=Release --parameters fsdocs-package-version %s\u0022 stableVersionTag)\n            \u0022./\u0022\n    }\n\n    let watchDocsPrerelease = BuildTask.create \u0022WatchDocsPrerelease\u0022 [setPrereleaseTag; build; copyBinaries] {\n        printfn \u0022watching docs with prerelease version %s\u0022 prereleaseTag\n        runDotNet \n            (sprintf \u0022fsdocs watch --eval --clean --property Configuration=Release --parameters fsdocs-package-version %s\u0022 prereleaseTag)\n            \u0022./\u0022\n    }\n(**\n* To create a new documentation file, run \u0060./build.cmd -t InitDocsPage\u0060\n* Add \u0060tmp/\u0060 to \u0060.gitignore\u0060\n* To run fsdocs in watchmode (hot reaload local hosting of your docs for live development), run \u0060dotnet fsdocs watch\u0060\n* Your repository should now look like this:  \n\n    ![]({{root}}images/Lib5.png)\n\n## Adding nuget packages\n\n* Navigate to your project folder (i. e. \u0060src/LibraryExample\u0060)\n* If you want to specify a package source other than nuget.com (e.g. a local package) you can specify other sources after adding a nuget.config file to your project root:\n\n\u0060\u0060\u0060\n\u003C?xml version=\u00221.0\u0022 encoding=\u0022utf-8\u0022?\u003E\n\u003Cconfiguration\u003E\n\u003C/configuration\u003E\n\u0060\u0060\u0060\n\n* The following example would add the local lib folder as a new nuget source to your local nuget.config file: \u0060dotnet nuget add source ./lib --configfile nuget.config\u0060\n\n\u0060\u0060\u0060\n\u003C?xml version=\u00221.0\u0022 encoding=\u0022utf-8\u0022?\u003E\n\u003Cconfiguration\u003E\n  \u003CpackageSources\u003E\n    \u003Cadd key=\u0022Package source 1\u0022 value=\u0022./lib\u0022 /\u003E\n  \u003C/packageSources\u003E\n\u003C/configuration\u003E\n\u0060\u0060\u0060\n\n* Calling \u0060dotnet add package PackageName --version PackageVersion\u0060 will still start to search for the package on nuget.com, but if this call is unsuccesful, Package source 1 will be used as a fallback. For a more complete view on how to use nuget.config files please visit the [offical documentation](https://docs.microsoft.com/en-us/nuget/consume-packages/configuring-nuget-behavior) or have a look at [this](https://blogs.naxam.net/configure-nuget-package-sources-for-your-project-cd8b96397360) blog post.\n*)"},{"uri":"https://fslab.org/006_savitzky_golay_temperature.html","title":"Smoothing data with the Savitzky-Golay filter\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Smoothing data with the Savitzky-Golay filter\ncategory: datascience\nauthors: Kevin Frey\nindex: 4\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: FSharp.Data, 4.2.7\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.3\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#endif // IPYNB\n\n(**\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath=content/tutorials/{{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n\n# Smoothing data with the Savitzky-Golay filter\n\n_Summary:_ This tutorial demonstrates how to access a public dataset for temperature data with [FSharp.Data](https://fsprojects.github.io/FSharp.Data/), how to smooth the data points with \nthe Savitzky-Golay filter from [FSharp.Stats](https://fslab.org/FSharp.Stats/) and finally how to visualize the results with [Plotly.NET](https://plotly.net).\n\n## Introduction: \n\nThe Savitzky-Golay is a type of low-pass filter, particularly suited for smoothing noisy data. The main idea behind this approach is to make for each point a \nleast-square fit with a polynomial of high order over a odd-sized window centered at the point. One advantage of the Savitzky-Golay filter is that portions \nof high frequencies are not simply cut off, but are preserved due to the polynomial regression. This allows the filter to preserve properties of the distribution \nsuch as relative maxima, minima, and dispersion, which are usually distorted by flattening or shifting by conventional methods such as moving average.\n\nThis is useful when trying to identify general trends in highly fluctuating data sets, or to smooth out noise to improve the ability to find minima and maxima of the data trend.\nTo showcase this we will plot a temperature dataset from the \u0022[Deutscher Wetterdienst](https://www.dwd.de/DE/leistungen/klimadatendeutschland/klimadatendeutschland.html)\u0022, \na german organization for climate data. We will do this for both the original data points and a smoothed version.\n\n![windowed polynomial regression](https://upload.wikimedia.org/wikipedia/commons/8/89/Lissage_sg3_anim.gif)\n\nThe image shows the moving window for polynomial regression used in the Savitzky-Golay filter [@wikipedia](https://upload.wikimedia.org/wikipedia/commons/8/89/Lissage_sg3_anim.gif)\n\n\n## Referencing packages\n\n\u0060\u0060\u0060fsharp\n// Packages hosted by the Fslab community\n#r \u0022nuget: FSharp.Stats\u0022\n// third party .net packages \n#r \u0022nuget: FSharp.Data\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.16\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n\u0060\u0060\u0060\n\n*)\n\n\n(**\n## Loading data\n\nWe will start by retrieving the data. This is done with the [FSharp.Data](https://fsprojects.github.io/FSharp.Data/) package \nand will return a single string in the original format.\n*)\n\n// Get data from Deutscher Wetterdienst\n// Explanation for Abbreviations: https://www.dwd.de/DE/leistungen/klimadatendeutschland/beschreibung_tagesmonatswerte.html\nlet rawData = FSharp.Data.Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/WeatherDataAachen-Orsbach_daily_1year.txt\u0022\n\n// print first 1000 characters to console.\nrawData.[..1000] |\u003E printfn \u0022%s\u0022\n\n(*** include-output ***)\n\n(**\n\nCurrently the data set is not in a format, that is easily parsable. Normally you would try to use \nthe Deedle package to read in the data into a [Deedle](https://fslab.org/Deedle/) data frame. As this is not possible here, we will do some ugly formatting.\n\n## Data Formatting/Parsing\n*)\n\nopen System\nopen System.Text.RegularExpressions\n\n/// Tuple of 4 data arrays representing the measured temperature for over a year.\nlet processedData = \n    // First separate the huge string in lines\n    rawData.Split([|\u0027\\n\u0027|], StringSplitOptions.RemoveEmptyEntries)\n    // Skip the first 5 rows until the real data starts, also skip the last row (length-2) to remove a \u0022\u003C/pre\u003E\u0022 at the end\n    |\u003E fun arr -\u003E arr.[5..arr.Length-2]\n    |\u003E Array.map (fun data -\u003E \n        // Regex pattern that will match groups of whitespace\n        let whitespacePattern = @\u0022\\s\u002B\u0022\n        // This is needed to tell regex to replace hits with a tabulator\n        let matchEval = MatchEvaluator(fun _ -\u003E @\u0022\\t\u0022 )\n        // The original data columns are separated by different amounts of whitespace.\n        // Therefore, we need a flexible string parsing option to replace any amount of whitespace with a single tabulator.\n        // This is done with the regex pattern above and the fsharp core library \u0022System.Text.RegularExpressions\u0022 \n        let tabSeparated = Regex.Replace(data, whitespacePattern, matchEval)\n        tabSeparated\n        // Split each row by tabulator will return rows with an equal amount of values, which we can access.\n        |\u003E fun dataStr -\u003E dataStr.Split([|@\u0022\\t\u0022|], StringSplitOptions.RemoveEmptyEntries)\n        |\u003E fun dataArr -\u003E \n            // Second value is the date of measurement, which we will parse to the DateTime type\n            DateTime.ParseExact(dataArr.[1], \u0022yyyyMMdd\u0022, Globalization.CultureInfo.InvariantCulture),\n            // 5th value is minimal temperature at that date.\n            float dataArr.[4],\n            // 6th value is average temperature over 24 timepoints at that date.\n            float dataArr.[5],\n            // 7th value is maximal temperature at that date.\n            float dataArr.[6]\n    )\n    // Sort by date\n    |\u003E Array.sortBy (fun (day,tn,tm,tx) -\u003E day)\n    // Unzip the array of value tuples, to make the different values easier accessible\n    |\u003E fun arr -\u003E \n        arr |\u003E Array.map (fun (day,tn,tm,tx) -\u003E day.ToShortDateString()),\n        arr |\u003E Array.map (fun (day,tn,tm,tx) -\u003E tm),\n        arr |\u003E Array.map (fun (day,tn,tm,tx) -\u003E tx),\n        arr |\u003E Array.map (fun (day,tn,tm,tx) -\u003E tn)\n\n(*** include-value:processedData ***)\n\n(**\n## Exploring the data set with Plotly.NET\n\nNext we create a create chart function with [Plotly.NET](https://plotly.net) to produce a visual representation of our data set.\n*)\n\nopen Plotly.NET\nopen Plotly.NET.LayoutObjects\n\n// Because our data set is already rather wide we want to move the legend from the right side of the plot\n// to the right center. As this function is not defined for fsharp we will use the underlying js bindings (https://plotly.com/javascript/legend/#positioning-the-legend-inside-the-plot).\n// Declarative style in F# using underlying DynamicObj\n// https://plotly.net/#Declarative-style-in-F-using-the-underlying\nlet legend = \n    let tmp = Legend()\n    tmp?yanchor \u003C- \u0022top\u0022\n    tmp?y \u003C- 0.99\n    tmp?xanchor \u003C- \u0022left\u0022\n    tmp?x \u003C- 0.5\n    tmp\n\n/// This function will take \u0027processedData\u0027 as input and return a range chart with a line for the average temperature\n/// and a different colored area for the range between minimal and maximal temperature at that date.\nlet createTempChart (days,tm,tmUpper,tmLower) =\n    Chart.Range(\n        // data arrays\n        days, tm, tmUpper, tmLower,\n        StyleParam.Mode.Lines_Markers,\n        Color= Color.fromString \u0022#3D1244\u0022,\n        RangeColor= Color.fromString \u0022#F99BDE\u0022,\n        // Name for line in legend\n        Name=\u0022Average temperature over 24 timepoints each day\u0022,\n        // Name for lower point when hovering over chart\n        LowerName=\u0022Min temp\u0022,\n        // Name for upper point when hovering over chart\n        UpperName=\u0022Max temp\u0022\n    )\n    // Configure the chart with the legend from above\n    |\u003E Chart.withLegend legend\n    // Add name to y axis\n    |\u003E Chart.withYAxisStyle(\u0022daily temperature [\u00B0C]\u0022)\n    |\u003E Chart.withSize (1000.,600.)\n\n/// Chart for original data set \nlet rawChart =\n    processedData \n    |\u003E createTempChart\n\n\n(***hide***)\nrawChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n(**\n\nAs you can see the data looks chaotic and is difficult to analyze. Trends are hidden in daily \ntemperature fluctuations and correlating events with temperature can get difficult. So next we want to\nsmooth the data to clearly see temperature trends.\n\n## Savitzky-Golay filter\n\nWe will use the \u0060Signal.Filtering.savitzkyGolay\u0060 function from [FSharp.Stats](https://fslab.org/FSharp.Stats/).\n\nParameters:\n\n- windowSize (\u0060int\u0060) the length of the window. Must be an odd integer number.\n- order (\u0060int\u0060) the order of the polynomial used in the filtering. Must be less then \u0060windowSize\u0060 - 1.\n- deriv (\u0060int\u0060) the order of the derivative to compute (default = 0 means only smoothing)\n- rate (\u0060int\u0060) this factor will influence amplitude when using Savitzky-Golay for derivation\n- data (\u0060float array\u0060) the values of the time history of the signal.\n\n*)\n\nopen FSharp.Stats\n\nlet smootheTemp ws order (days,tm,tmUpper,tmLower) =\n    let tm\u0027 = Signal.Filtering.savitzkyGolay ws order 0 1 tm\n    let tmUpper\u0027 = Signal.Filtering.savitzkyGolay ws order 0 1 tmUpper\n    let tmLower\u0027 = Signal.Filtering.savitzkyGolay ws order 0 1 tmLower\n    days,tm\u0027,tmUpper\u0027,tmLower\u0027\n\nlet smoothedChart =\n    processedData\n    |\u003E smootheTemp 31 4\n    |\u003E createTempChart \n\n\n(***hide***)\nsmoothedChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)"}]