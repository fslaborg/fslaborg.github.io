[{"uri":"https://fslab.org/008_sequence_features.html","title":"Modelling and visualizing sequence features with BioFSharp and Plotly.NET\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Modelling and visualizing sequence features with BioFSharp and Plotly.NET\ncategory: advanced\nauthors: Kevin Schneider\nindex: 1\n---\n*)\n\n#r \u0022nuget: BioFSharp, 2.0.0-beta7\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta6\u0022\n#r \u0022nuget: Newtonsoft.JSON, 12.0.3\u0022\n#r \u0022nuget: DynamicObj\u0022\n\nopen BioFSharp\nopen System.IO\n\ntype SequenceFeature = {\n    Name: string\n    //zero-based\n    Start: int\n    //zero-based\n    End: int\n    Length: int\n    Abbreviation: char\n    Metadata: Map\u003Cstring,string\u003E\n    FeatureType: string\n} with\n    static member create \n        (\n            name: string,\n            featureStart: int,\n            featureEnd: int,\n            ?Abbreviation: char,\n            ?Metadata: Map\u003Cstring,string\u003E,\n            ?FeatureType: string\n        ) =\n            if featureStart \u003C 0 || featureEnd \u003C 0 || featureStart \u003E featureEnd then\n                failwith $\u0022invalid feature stretch ({featureStart},{featureEnd})\u0022\n            else\n                {\n                    Name            = name        \n                    Start           = featureStart\n                    End             = featureEnd  \n                    Length          = featureEnd - featureStart \u002B 1\n                    Abbreviation    = Abbreviation |\u003E Option.defaultValue \u0027 \u0027\n                    Metadata        = Metadata |\u003E Option.defaultValue (Map.ofList [])\n                    FeatureType     = FeatureType |\u003E Option.defaultValue \u0022\u0022\n                }\n\n    static member tryGetIntersection (feature1:SequenceFeature) (feature2:SequenceFeature) =\n        let s1,e1 = feature1.Start, feature1.End\n        let s2,e2 = feature2.Start, feature2.End\n        \n        if (s2 \u003E e1) || (s1 \u003E e2) then\n            None\n        else\n            Some ((max s1 s2), (min e1 e2))\n\ntype AnnotatedSequence\u003C\u0027T when \u0027T :\u003E IBioItem\u003E = \n    {\n        Tag: string\n        Sequence : seq\u003C\u0027T\u003E\n        Features: Map\u003Cstring,SequenceFeature list\u003E\n    } \n\nmodule AnnotatedSequence =\n    \n    let create tag sequence (featureMap: Map\u003Cstring,SequenceFeature list\u003E) =\n\n        let mutable hasInvalidFeatures = false\n        let mutable invalidFeatures: (string*(SequenceFeature*SequenceFeature)) list = []\n\n        let isOverlap (stretch1:int * int) (stretch2: int * int) =\n            let s1, e1 = stretch1\n            let s2, e2 = stretch2\n\n            (s1 \u003C= s2 \u0026\u0026 e1 \u003E= s2)\n            || (s1 \u003C= s2 \u0026\u0026 e1 \u003E= e2)\n            || (s1 \u003C= e2 \u0026\u0026 e1 \u003E= e2)\n            || (s1 \u003E= s2 \u0026\u0026 e1 \u003C= e2)\n\n        featureMap\n        |\u003E Map.iter (fun key features -\u003E\n            let rec loop (featureList:SequenceFeature list) =\n                match featureList with\n                | f::rest -\u003E \n                    for frest in rest do \n                        if isOverlap (f.Start, f.End) (frest.Start, frest.End) then \n                            hasInvalidFeatures \u003C- true\n                            invalidFeatures \u003C- (key,(f,frest))::invalidFeatures\n                    loop rest\n                | [] -\u003E ()\n            loop features\n        )\n        if hasInvalidFeatures then\n            failwith $\u0022\u0022\u0022At least one  sequence feature annotation collection contains overlapping annotations. This is not supported. Please annotate them as separate feature lists.\nOffending annotations: \n{invalidFeatures}\n\u0022\u0022\u0022         \n        else\n            {\n                Tag = tag\n                Sequence = sequence\n                Features= featureMap\n            }\n\n    let addFeatures (featureKey: string) (features: SequenceFeature list) (anns: AnnotatedSequence\u003C_\u003E) =\n        {\n            anns with\n                Features = \n                    if Map.containsKey featureKey anns.Features then\n                        anns.Features |\u003E Map.add featureKey (features @ anns.Features.[featureKey])\n                    else\n                        anns.Features |\u003E Map.add featureKey features\n                \n        }\n\n    let toStrings (anns: AnnotatedSequence\u003C_\u003E) =\n        let sequenceString = anns.Sequence |\u003E Seq.map (BioItem.symbol \u003E\u003E string) |\u003E String.concat \u0022\u0022\n        let emptyFormatString = [for i in 1 .. (Seq.length anns.Sequence) do yield \u0022 \u0022] |\u003E String.concat \u0022\u0022\n        let featureFormats =\n            anns.Features\n            |\u003E Map.map (fun key features -\u003E \n                features\n                |\u003E Seq.fold (fun (acc:string) (feature) -\u003E\n                    let featureStretch = [for _ in 1 .. feature.Length do yield (feature.Abbreviation |\u003E string)] |\u003E String.concat \u0022\u0022\n                    acc\n                        .Remove(feature.Start, feature.Length)\n                        .Insert(feature.Start, featureStretch)\n                ) emptyFormatString\n            )\n        sequenceString,featureFormats\n\n    let format (anns: AnnotatedSequence\u003C_\u003E) =\n        let sequenceString, featureStrings = anns |\u003E toStrings\n        let longestId = \n            [\u0022Sequence\u0022; yield! (featureStrings |\u003E Map.toList |\u003E List.map fst)] \n            |\u003E Seq.maxBy (fun x -\u003E x.Length)\n            |\u003E fun s -\u003E s.Length\n\n        let ids = \n            [\u0022Sequence\u0022; yield! (featureStrings |\u003E Map.toList |\u003E List.map fst)]\n            |\u003E List.map (fun s -\u003E s.PadRight(longestId\u002B4))\n        \n        let blocks = \n            [sequenceString; yield! (featureStrings |\u003E Map.toList |\u003E List.map snd)]\n            |\u003E List.mapi (fun index seqString -\u003E\n                let id = ids.[index]\n                let splits = \n                    seqString.ToCharArray() \n                    |\u003E Seq.map string\n                    |\u003E Seq.chunkBySize 60 \n                    |\u003E Seq.map (String.concat \u0022\u0022)\n\n                let innerSplits = \n                    splits |\u003E Seq.map (fun s -\u003E \n                        s.ToCharArray() \n                        |\u003E Seq.map string\n                        |\u003E Seq.chunkBySize 10 \n                        |\u003E Seq.map (String.concat \u0022\u0022)\n                )\n\n                innerSplits \n                |\u003E Seq.mapi (fun i strs -\u003E  \n                    let line = \n                        strs \n                        |\u003E Seq.fold (fun acc elem -\u003E sprintf \u0022%s %s\u0022 acc elem) \u0022\u0022 \n                    $\u0022{id} {(string (((i\u002B1)*60) - 60 \u002B 1)).PadLeft(10)}{line}\u0022 \n                )\n                |\u003E Array.ofSeq\n            )\n\n        [for i in 0 .. blocks.[0].Length-1 do\n            for b in blocks do yield b.[i]\n        ]\n        |\u003E String.concat System.Environment.NewLine\n        |\u003E fun s -\u003E $\u0022{System.Environment.NewLine}{s}{System.Environment.NewLine}\u0022\n\n(**\n# Modelling and visualizing sequence features with BioFSharp and Plotly.NET\n\n### Table of contents\n\n- [Assigning secondary structure for proteins based on .pdb files](#Assigning-secondary-structure-for-proteins-based-on-pdb-files)\n- [Comparing structural annotations](#Comparing-structural-annotations)\n- [Generalizing sequence features]()\n    - [Implementing the Sequence feature](#Implementing-the-Sequence-feature)\n    - [Implementing the Annotated Sequence](#Implementing-the-Annotated-Sequence)\n- [Visualizing sequence features with Plotly.NET](#Visualizing-sequence-features-with-Plotly-NET)\n    - [Plotting sequences with Plotly.NET](#Plotting-sequences-with-Plotly-NET)\n    - [A sequence feature view plot for AnnotatedSequence](#A-sequence-feature-view-plot-for-AnnotatedSequence)\n\n\n## Assigning secondary structure for proteins based on .pdb files\n\nI recently started to work with a lot of structural protein data with the aim of extracting features based on the proteins secondary structures.\n\nThis involved assigning secondary structures for \u0060.pdb\u0060 files, which is a file format that contains positional information about each atom in a polipeptide chain.\nAs in many bioinformatic fields, tried-and-tested algorithms for this are several decades old but seem to be still the gold standard. \nThe algorithm that pops up most is [**DSSP**](https://swift.cmbi.umcn.nl/gv/dssp/) (Dictionary of Protein Secondary Structure). You can clearly see the age in every ounce of that website.\n\nDSSP was originally used to assign all secondary structures for the [PDB (Protein Data bank)](https://www.rcsb.org/). I cannot find a source if that is still the case though. \n\u0060.pdb\u0060 files obtained from PDB usually already contain a section with the assigned structures, but this is not true for example for the output of alpha fold, which only predicts the raw atom positions without any structure assignment.\n\nUsing dssp is straight forward, it can be installed directly via apt on ubuntu, and there is a biocontainer available [here](https://biocontainers.pro/tools/dssp)\n\ndssp itself is also very easy to use. Once in the container, simply run\n\n\u0060\u0060\u0060bash\ndssp -i \u003C.pdb file\u003E -o \u003Cdssp file\u003E\n\u0060\u0060\u0060\n\nThe output format of DSSP is weird, but writing parsers is not too hard. It contains metadata sections indicated by the line start, which are not very interesting fort my purposes.\nThe structure assignments are contained in a fixed-column data format further down the file. \n\nHere is an example of how it looks like:\n\n\u0060\u0060\u0060no-highlight\n#  RESIDUE AA STRUCTURE BP1 BP2  ACC     N-H--\u003EO    O--\u003EH-N    N-H--\u003EO    O--\u003EH-N    TCO  KAPPA ALPHA  PHI   PSI    X-CA   Y-CA   Z-CA            CHAIN\n  1    1 A M              0   0  235      0, 0.0     4,-0.1     0, 0.0     0, 0.0   0.000 360.0 360.0 360.0  58.6   -7.4   17.5   38.1               \n  2    2 A Y     \u003E  \u002B     0   0  202      2,-0.1     4,-0.6     3,-0.1     0, 0.0   0.539 360.0  69.8-121.3  -9.6   -8.6   17.8   34.5               \n  3    3 A Y  H  \u003E S\u002B     0   0  209      1,-0.2     4,-1.1     2,-0.2     3,-0.3   0.865  91.2  58.3 -82.3 -33.1   -5.5   19.3   32.5               \n  4    4 A F  H  \u003E S\u002B     0   0  193      1,-0.2     4,-1.7     2,-0.2    -1,-0.2   0.861 101.0  56.5 -67.1 -33.2   -3.2   16.2   32.7               \n  5    5 A S  H  \u003E S\u002B     0   0   91      1,-0.2     4,-1.5     2,-0.2    -1,-0.2   0.835 104.5  51.5 -71.2 -31.9   -5.6   13.8   31.0               \n  6    6 A R  H  X S\u002B     0   0  204     -4,-0.6     4,-1.4    -3,-0.3    -1,-0.2   0.816 108.4  51.3 -75.1 -30.1   -6.0   16.0   27.8               \n  7    7 A V  H  X S\u002B     0   0   96     -4,-1.1     4,-1.8     2,-0.2    -2,-0.2   0.924 110.2  49.0 -72.1 -41.8   -2.2   16.3   27.3               \n  8    8 A A  H  X S\u002B     0   0   54     -4,-1.7     4,-1.9     1,-0.2    -2,-0.2   0.860 109.1  52.8 -65.7 -36.0   -1.8   12.5   27.5               \n  9    9 A A  H  X S\u002B     0   0   65     -4,-1.5     4,-1.7     2,-0.2    -1,-0.2   0.885 108.6  50.6 -67.1 -36.6   -4.6   11.9   25.0               \n 10   10 A R  H  X S\u002B     0   0  206     -4,-1.4     4,-1.6     2,-0.2    -2,-0.2   0.888 110.4  48.5 -68.7 -39.2   -2.9   14.3   22.5               \n 11   11 A T  H  X S\u002B     0   0   84     -4,-1.8     4,-1.6     2,-0.2    -2,-0.2   0.894 109.7  52.6 -70.1 -36.5    0.5   12.5   22.7               \netc.\n\u0060\u0060\u0060\n\nWriting a parser for that section was straight forward. I added it to [BioFSharp.IO]() if you are interested in using it yourself.\n\n## Comparing structural annotations\n\nWithout going into too much detail, one of the things I am interested in is how the structural assignments of DSSP relate to other structural annotations for it.\nAn example would be **intrinsically disordered stretches**, parts of the chain that do not have a structure, but this disorder is actually crucial for the proteins function.\n\nYou can read more about disorder in protein structures [here](https://en.wikipedia.org/wiki/Intrinsically_disordered_proteins). An awesome ressource for disorder annotations is [DisProt](https://disprot.org/). You can download its annotations in an easily usable tsv format (no custom parsing yay).\nWith these two annotations at hand, i started scripting with BioFSharp and Plotly.NET to get visual comparisons of both features (DSSP structure and disprot annotation).\n\nMy first attempts involved chunking the sequence and annotations by 60 and creating a annotated heatmap, assigning color based on the one character code of the structure. It achieved the goal, but was very hard to read, especially for large sequences.\nI wont even include the source code for this, because it obviously sucks:\n\n\u003Cbr\u003E\n\u003Chr\u003E\n\n![heatmap](/img/heatmap.png)\n\n_Fig1: My first pitiful attempt at visualizing sequence features_\n\u003Chr\u003E\n\u003Cbr\u003E\n\nAt this point, i thought i was pretty much near the goal of my project (i calculated some fancy metrics downstream from the features that do not belong in this post),\nand therefore content with the visualization. But as often happens in any kind of project - especially in academia - the scale of the project increased and i wanted to include more features in my calculations.\n\nOne was the secondary structure assigment of [Stride](http://webclu.bio.wzw.tum.de/stride/) - basically an improved version of DSSP. Also, i wanted to look at different disprot annotations individually.\nAt this point, a generic solution for both handling sequence features as well as their visualization was needed.\n\nStride is not as straight-forward to use as DSSP. I ended up creating my own docker container that builds it from [source](http://webclu.bio.wzw.tum.de/stride/install.html):\n\n\u0060\u0060\u0060dockerfile\nFROM biocontainers/biocontainers:vdebian-buster-backports_cv1\n\nUSER root\nRUN apt-get update \u0026\u0026 (apt-get install -t buster-backports -y gcc || apt-get install -y gcc) \u0026\u0026 (apt-get install -t buster-backports -y make || apt-get install -y make) \u0026\u0026 apt-get clean \u0026\u0026 apt-get purge\n\nWORKDIR /bin/stride\nCOPY ./stride.tar.gz /bin/stride\n\nENV DEBIAN_FRONTEND noninteractive\nRUN tar -zxf stride.tar.gz\nRUN make\nENV PATH=\u0022/bin/stride/:${PATH}\u0022\n\nWORKDIR /data\nUSER biodocker\n\u0060\u0060\u0060\n\n## Implementing the Sequence feature\n\nA sequence feature in its most basic form just need start and end index within the sequence. They are usually abbreviated by a one-character code in most visualizations, and DSSP as well as Stride use on-letter codes for their assignment. \nI added additional metadata such as the name, type, and length of the feature, as well as arbitrary metadata. The full implementation in BioFSharp can be seen [here]()\n\n\u0060\u0060\u0060\ntype SequenceFeature = \n    {\n        Name: string\n        //zero-based\n        Start: int\n        //zero-based\n        End: int\n        Length: int\n        Abbreviation: char\n        Metadata: Map\u003Cstring,string\u003E\n        FeatureType: string\n    }\n\n\u0060\u0060\u0060\n\n## Implementing the Annotated Sequence\n\nAn annotated sequence is a sequence which has feature annotations. I decided to model these as a Map of sequence features, where the key represents the feature type, and the list contains the individual feature stretches of that type.\nThe sequence can also be tagged with a string to give it an identifier:\n\n\u0060\u0060\u0060\ntype AnnotatedSequence\u003C\u0027T when \u0027T :\u003E IBioItem\u003E = \n    {\n        Tag: string\n        Sequence : seq\u003C\u0027T\u003E\n        Features: Map\u003Cstring,SequenceFeature list\u003E\n    } \n\n\u0060\u0060\u0060\n\nThe full implementation with all additional functions can be found in BioFSharp [here]()\n\nBased on this type, i first created a pretty printer in the fasta style to see if i was going in the right direction:\n\n*)\nopen BioFSharp\n\nlet testSeq = \n    AnnotatedSequence.create\n        \u0022Test\u0022\n        (\u0022ATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAG\u0022 |\u003E BioArray.ofNucleotideString)\n        (Map.ofList [\n            \u0022Feature1\u0022, [SequenceFeature.create(\u0022F1\u0022,0,10,\u0027A\u0027)]\n            \u0022Feature2\u0022, [SequenceFeature.create(\u0022F2\u0022,0,10,\u0027B\u0027); SequenceFeature.create(\u0022F2\u0022,100,120,\u0027B\u0027)]\n            \u0022Feature3\u0022, [SequenceFeature.create(\u0022F3\u0022,30,90,\u0027C\u0027)]\n\n        ])\n\nAnnotatedSequence.format testSeq\n(***include-it***)\n\n(**\nSo with this type modelling i was able to annotate a sequence with arbitrary features and visualize their positions. This text-based representation has the same problems as my heatmap approach though: it gets quite hard to read with increasing sequence length and feature count.\nStill, this is a nice pretty prionter for usage with \u0060fsi.AddPrinter\u0060.\n\n# Visualizing sequence features with Plotly.NET\n\nI took heavy inspiration from DisProt\u0027s sequence viewer, which displays feature lanes below the actual sequence as bars.\n\n## Plotting sequences with Plotly.NET\n\nTo plot a sequence of characters on a 2D plot, we can leverage Plotly.NETs \u0060Annotations\u0060. \nTo give the annotations points that can trigger hovertext, i added an invisible line trace behind them.\n*)\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.11\u0022\n\nopen Plotly.NET\nopen Plotly.NET.LayoutObjects\n\nlet testSeqChart = \n    Chart.Line(\n        [for i in 0..3 -\u003E (i,1)], \n        Labels=[\u0022A\u0022;\u0022T\u0022;\u0022G\u0022;\u0022C\u0022], \n        Opacity=0.0,\n        ShowLegend = false,\n        Color= Color.fromKeyword Black\n    )\n    |\u003E Chart.withAnnotations (\n        [\u0022A\u0022;\u0022T\u0022;\u0022G\u0022;\u0022C\u0022]\n        |\u003E Seq.mapi (fun x text -\u003E\n                Annotation.init(\n                    x,1,\n                    Text=(string text),\n                    ShowArrow=false,\n                    Font = Font.init(Size=16.)\n                )\n        )\n    )\n\n(**\n\u003Chr\u003E\n*)\n\n(***hide***)\ntestSeqChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n_Fig 2: A simple sequence plot using Plotly.NET\u0027s Annotations._\n\u003Chr\u003E\n\u003Cbr\u003E\n*)\n\n(**\nWith some additional styling, we can make this look pretty good already:\n\n- Remove the Y axis\n- Mirror the X Axis\n- Add spike lines per default (very usefull later when combining with the feature traces)\n\n*)\n\ntype Chart with\n    static member SequencePlot\n        (\n            annotationText: #seq\u003Cstring\u003E,\n            ?FontSize: float\n        ) =\n            let fontSize = defaultArg FontSize 16.\n\n            Chart.Line(\n                [for i in 0..((Seq.length annotationText) - 1) -\u003E (i,1)], \n                Labels=annotationText, \n                Opacity=0.0,\n                ShowLegend = false,\n                Color= Color.fromKeyword Black\n            )\n            |\u003E Chart.withXAxis(\n                LinearAxis.init(\n                    Visible=true, \n                    ShowLine= true, \n                    ShowTickLabels = true, \n                    ShowSpikes= true, \n                    ZeroLine = false, \n                    Range= StyleParam.Range.MinMax(0.,60.), // as default, show the first 60 characters. Double click to zoom out.\n                    Title = Title.init(\u0022Sequence index (0-based)\u0022, Font=Font.init(Size=fontSize)),\n                    TickFont = Font.init(Size=fontSize),\n                    Ticks = StyleParam.TickOptions.Inside,\n                    Mirror = StyleParam.Mirror.AllTicks\n                )\n            )        \n            |\u003E Chart.withYAxis(\n                LinearAxis.init(Visible=false, ShowLine= false, ShowTickLabels = false, ShowGrid = false, ZeroLine=false)\n            )\n            |\u003E Chart.withAnnotations (\n                annotationText\n                |\u003E Seq.mapi (fun x text -\u003E\n                    Annotation.init(\n                        x,1,\n                        Text=(string text),\n                        ShowArrow=false,\n                        Font = Font.init(Size=fontSize)\n                    )\n                )\n            )\n\nlet seqPlot = \n    Chart.SequencePlot(testSeq.Sequence |\u003E Seq.map (BioItem.symbol \u003E\u003E string))\n    |\u003E Chart.withSize(1000)\n\n(**\n\u003Chr\u003E\n*)\n\n(***hide***)\nseqPlot |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n_Fig 3: A better styled version of the Sequence plot._\n\u003Chr\u003E\n\u003Cbr\u003E\n*)\n\n(**\n## A sequence feature view plot for AnnotatedSequence\n\nNow we need to add the feature traces. While Plotly.NET supports shapes to draw on a Plot, these have the disadvantage of not triggering hover events (at least to my knowledge).\n\nSo i decided to render each feature as a horizontal Bar trace, setting its \u0060Base\u0060 property (the Bar start) to the feature start, and the length accordingly.\n\nUsing \u0060Chart.SingleStack\u0060 in shared axis mode together with the previous sequence plot, this has the additional advantage that spikelines of the sequence plot span over the features (try hovering over the sequence below)\n\n*)\n\nlet featureTraceTestPlot = \n    [\n        Chart.SequencePlot(testSeq.Sequence |\u003E Seq.map (BioItem.symbol \u003E\u003E string))\n        [\n            Chart.Bar([\u0022Feature1\u0022, 20], Base=10, ShowLegend = false)\n            Chart.Bar([\u0022Feature1\u0022, 20], Base=41, ShowLegend = false)\n            Chart.Bar([\u0022Feature2\u0022, 50], Base=20, ShowLegend = false)\n        ]\n        |\u003E Chart.combine\n    ]\n    |\u003E Chart.SingleStack(Pattern=StyleParam.LayoutGridPattern.Coupled)\n    |\u003E Chart.withSize(1000)\n\n(**\n\u003Chr\u003E\n*)\n\n(***hide***)\nfeatureTraceTestPlot |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n_Fig 4: Bar traces with different bases can be used in a stacked chart to indicate features mapping to the sequence position of the sequence plot on top._\n\u003Chr\u003E\n\u003Cbr\u003E\n*)\n\n(**\n\nThat looks exactly like i wanted it to turn out!\n\nThe rest is now a matter of styling. here is what i did additionally (in words):\n\n- render all features with the same color, unless indicated otherwise by a color mapping function\n- As seen on the plot above, When there are multiple features in a single lane, they get rendered with a y offset. This can be overcome by setting the barmode of the chart layout to \u0060Overlay\u0060\n- Add a x axis range slider to give more exploratory power\n\nAnd here is the final result (in code):\n\n*)\n\n\ntype Chart with\n    static member SequenceFeatureView\n        (\n            annotatedSequence: AnnotatedSequence\u003C_\u003E,\n            ?FontSize: float,\n            ?ColorMapping: seq\u003C(string*Color)\u003E,\n            ?ShowRangeSlider: bool\n        ) =\n            let showRangeSlider = defaultArg ShowRangeSlider true\n            let sequenceString = annotatedSequence.Sequence |\u003E Seq.map (BioItem.symbol \u003E\u003E string)\n\n            let featureColorMap = \n                ColorMapping\n                |\u003E Option.defaultValue Seq.empty\n                |\u003E Map.ofSeq\n\n            let featurePlots =\n                annotatedSequence.Features\n                |\u003E Map.toSeq\n                |\u003E Seq.map (fun (featureName,features) -\u003E\n                    features\n                    |\u003E List.map (fun f -\u003E\n                        Chart.Bar(\n                            [featureName,f.Length-1], \n                            Width=0.8, \n                            Base=f.Start, \n                            Text = $\u0022({f.Start}-{f.End}):  {f.Abbreviation}\u0022, \n                            TextPosition = StyleParam.TextPosition.Inside,\n                            ShowLegend = false,\n                            Color = (Map.tryFind featureName featureColorMap |\u003E Option.defaultValue (Color.fromKeyword Black))\n                        )\n                    \n                    )\n                )\n                |\u003E Seq.concat\n\n            [\n                Chart.SequencePlot(sequenceString, ?FontSize = FontSize)\n                |\u003E Chart.withYAxis(\n                    LinearAxis.init(Domain = StyleParam.Range.MinMax(0.81,1.))\n                )\n\n                featurePlots\n                |\u003E Chart.combine\n                |\u003E Chart.withYAxis(\n                    LinearAxis.init(ShowGrid=true, FixedRange = false, Domain = StyleParam.Range.MinMax(0.,0.79))\n                )\n            ]\n            |\u003E Chart.SingleStack(Pattern = StyleParam.LayoutGridPattern.Coupled)\n            |\u003E fun c -\u003E \n                if showRangeSlider then\n                    c\n                    |\u003E Chart.withXAxisRangeSlider(\n                        RangeSlider.init(BorderColor=Color.fromKeyword Gray, BorderWidth=1.)\n                    )\n                else\n                    c\n            |\u003E Chart.withConfig(\n                Config.init(ModeBarButtonsToAdd=[\n                    StyleParam.ModeBarButton.ToggleSpikelines\n                ])\n            )\n            |\u003E Chart.withLayout(\n                Layout.init(\n                    BarMode = StyleParam.BarMode.Overlay\n                )\n            )\n            |\u003E Chart.withTitle $\u0022Sequence feature view for {annotatedSequence.Tag}\u0022\n\n(**\nHere is what it looks like with a big test sequence:\n*)\n\nlet bigTestSeq = \n    AnnotatedSequence.create\n        \u0022test sequence\u0022\n        (\u0022ATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGTGTCATGCTAGTGTC\u0022 |\u003E BioArray.ofNucleotideString)\n        (Map.ofList [\n            \u0022Feature 1\u0022, [SequenceFeature.create(\u0022F\u0022,1,33,\u0027X\u0027);  SequenceFeature.create(\u0022F\u0022,50,60,\u0027D\u0027)]\n            \u0022Feature 2\u0022, [SequenceFeature.create(\u0022F\u0022,0,30,\u0027L\u0027);  SequenceFeature.create(\u0022F\u0022,40,50,\u0027E\u0027); SequenceFeature.create(\u0022F\u0022,52,100,\u0027L\u0027)]\n            \u0022Feature 3\u0022, [SequenceFeature.create(\u0022F\u0022,8,83,\u0027X\u0027);  SequenceFeature.create(\u0022F\u0022,84,100,\u0027D\u0027)]\n            \u0022Feature 4\u0022, [SequenceFeature.create(\u0022F\u0022,80,85,\u0027L\u0027); SequenceFeature.create(\u0022F\u0022,40,50,\u0027E\u0027); SequenceFeature.create(\u0022F\u0022,52,79,\u0027L\u0027)]            \n            \u0022Feature 5\u0022, [SequenceFeature.create(\u0022F\u0022,1,33,\u0027X\u0027);  SequenceFeature.create(\u0022F\u0022,50,60,\u0027D\u0027)]\n            \u0022Feature 6\u0022, [SequenceFeature.create(\u0022F\u0022,0,30,\u0027L\u0027);  SequenceFeature.create(\u0022F\u0022,40,50,\u0027E\u0027); SequenceFeature.create(\u0022F\u0022,52,100,\u0027L\u0027)]\n            \u0022Feature 7\u0022, [SequenceFeature.create(\u0022F\u0022,8,83,\u0027X\u0027);  SequenceFeature.create(\u0022F\u0022,84,100,\u0027D\u0027)]\n            \u0022Feature 8\u0022, [SequenceFeature.create(\u0022F\u0022,80,85,\u0027L\u0027); SequenceFeature.create(\u0022F\u0022,40,50,\u0027E\u0027); SequenceFeature.create(\u0022F\u0022,52,79,\u0027L\u0027)]\n            \u0022Feature 9\u0022, [SequenceFeature.create(\u0022F\u0022,1,33,\u0027X\u0027);  SequenceFeature.create(\u0022F\u0022,50,60,\u0027D\u0027)]\n            \u0022Feature 10\u0022,[SequenceFeature.create(\u0022F\u0022,0,30,\u0027L\u0027);  SequenceFeature.create(\u0022F\u0022,40,50,\u0027E\u0027); SequenceFeature.create(\u0022F\u0022,52,100,\u0027L\u0027)]\n            \u0022Feature 11\u0022,[SequenceFeature.create(\u0022F\u0022,8,83,\u0027X\u0027);  SequenceFeature.create(\u0022F\u0022,84,100,\u0027D\u0027)]\n            \u0022Feature 12\u0022,[SequenceFeature.create(\u0022F\u0022,80,85,\u0027L\u0027); SequenceFeature.create(\u0022F\u0022,40,50,\u0027E\u0027); SequenceFeature.create(\u0022F\u0022,52,79,\u0027L\u0027)]            \n            \u0022Feature 13\u0022,[SequenceFeature.create(\u0022F\u0022,1,33,\u0027X\u0027);  SequenceFeature.create(\u0022F\u0022,50,60,\u0027D\u0027)]\n            \u0022Feature 14\u0022,[SequenceFeature.create(\u0022F\u0022,0,30,\u0027L\u0027);  SequenceFeature.create(\u0022F\u0022,40,50,\u0027E\u0027); SequenceFeature.create(\u0022F\u0022,52,100,\u0027L\u0027)]\n            \u0022Feature 15\u0022,[SequenceFeature.create(\u0022F\u0022,8,83,\u0027X\u0027);  SequenceFeature.create(\u0022F\u0022,84,100,\u0027D\u0027)]\n            \u0022Feature 16\u0022,[SequenceFeature.create(\u0022F\u0022,80,85,\u0027L\u0027); SequenceFeature.create(\u0022F\u0022,40,50,\u0027E\u0027); SequenceFeature.create(\u0022F\u0022,52,79,\u0027L\u0027)]\n        ])\n\nlet finalChart =\n    Chart.SequenceFeatureView(\n        bigTestSeq,\n        ColorMapping = [\u0022Feature 10\u0022, Color.fromKeyword DarkSalmon] // show feature 10 in a different color\n    )\n    |\u003E Chart.withSize(1000)\n\n(**\n\u003Chr\u003E\n*)\n\n(***hide***)\nfinalChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n_Fig 5: The final result of my feature view plotting efforts._\n\u003Chr\u003E\n*)"},{"uri":"https://fslab.org/005_testing_t-test.html","title":"Testing with FSharp.Stats I: t-test\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Testing with FSharp.Stats I: t-test\ncategory: datascience\nauthors: Oliver Maus\nindex: 5\n---\n*)\n\n\n(***condition:prepare***)\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON, 13.0.1\u0022\n#r \u0022nuget: DynamicObj, 0.2.0\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON, 13.0.1\u0022\n#r \u0022nuget: DynamicObj, 0.2.0\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n#endif // IPYNB\n\n\n(**\n\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath=content/tutorials/{{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n# Testing with FSharp.Stats I: t-test\n\n## Getting started: The t-test\n\n_I love statistical testing_ - A sentence math teachers don\u0027t hear often during their time at school. In this tutorial we aim to give you a short introduction of the theory and how to \nperform the most used statistical test: the t-test\n\nSuppose you have measured the length of some leaves of two trees and you want to find out if the average length of the leaves is the same or if they differ from each other. \nIf you knew the population distributions of all leaves hanging on both trees the task would be easy, but since we only have samples from both populations, we have to apply a statistical test.\nStudent\u0027s t-test can be applied to test whether two samples have the same mean (H0), or if the means are different (H1). There are two requirements to the samples that have to be fulfilled:\n\n1. The variances of both samples have to be equal.\n\n2. The samples have to follow a normal distribution.\n\n_Note: Slight deviations from these requirements can be accepted but strong violations result in an inflated false positive rate. If the variances are not equal a Welch test can be performed._\n_There are some tests out there to check if the variances are equal or if the sample follows a normal distribution, but their effectiveness is discussed._\n_You always should consider the shape of the theoretical background distribution, instead of relying on preliminary tests rashly._\n\n\nThe t-test is one of the most used statistical tests in datascience. It is used to compare two samples in terms of statistical significance. \nOften a significance threshold (or \u0026alpha; level) of 0.05 is chosen to define if a p value is defined as statistically significant. A p value describes how likely it is to observe an effect\nat least as extreme as you observed (in the comparison) by chance. Low p values indicate a high confidence to state that there is a real difference and the observed difference is not caused by chance.\n\n*)\n\n#r \u0022nuget: FSharp.Data\u0022\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats, 0.4.2\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n\nopen FSharp.Data\nopen Deedle\nopen Plotly.NET\n\n(**\n\nFor our purposes, we will use the housefly wing length dataset (from _Sokal et al., 1955, A morphometric analysis of DDT-resistant and non-resistant housefly strains_).\nHead over to the [Getting started](001_getting-started.html#Data-access) tutorial where it is shown how to import datasets in a simple way.\n\n\n*)\n\n// We retrieve the dataset via FSharp.Data:\nlet rawDataHousefly = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/HouseflyWingLength.txt\u0022\n\nlet dataHousefly : seq\u003Cfloat\u003E = \n    Frame.ReadCsvString(rawDataHousefly, false, schema = \u0022wing length (mm * 10^1)\u0022)\n    |\u003E Frame.getCol \u0022wing length (mm * 10^1)\u0022\n    |\u003E Series.values\n    // We convert the values to mm\n    |\u003E Seq.map (fun x -\u003E x / 10.)\n\n(**\n\nLet us first have a look at the sample data with help of a boxplot. As shown below, the average wingspan is around 4.5 with variability ranges between 3.5 and 5.5.\n\n\n*)\n\nlet boxPlot = \n    Chart.BoxPlot(y = dataHousefly, Name = \u0022housefly\u0022, BoxPoints = StyleParam.BoxPoints.All, Jitter = 0.2)\n    |\u003E Chart.withYAxisStyle \u0022wing length [mm]\u0022\n\n(*** condition: ipynb ***)\n#if IPYNB\nboxPlot\n#endif // IPYNB\n\n(***hide***)\nboxPlot |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n(**\n\n## One-sample t-test\n\nWe want to analyze if an estimated expected value differs from the sample above. Therefore, we perform a one-sample t-test which covers exactly this situation.\n\n\n\n\u003Cimg style=\u0022max-width:75%\u0022 src=\u0022../../images/OneSampleTTest.png\u0022\u003E\u003C/img\u003E\n\nFig. 1: **The one-sample t-test** The dashed orange line depicts the distribution of our sample, the green bar the expected value to test against.\n\n*)\n\nopen FSharp.Stats\nopen FSharp.Stats.Testing\n\n// The testing module in FSharp.Stats require vectors as input types, thus we transform our array into a vector:\nlet vectorDataHousefly = vector dataHousefly\n\n// The expected value of our population.\nlet expectedValue = 4.5\n\n// Perform the one-sample t-test with our vectorized data and our exptected value as parameters.\nlet oneSampleResult = TTest.oneSample vectorDataHousefly expectedValue\n\n(*** hide ***)\n\n(*** include-value:oneSampleResult ***)\n\n(**\n\nThe function returns a \u0060TTestStatistics\u0060 type. If contains the fields \n\n  - \u0060Statistic\u0060: defines the exact teststatistic\n\n  - \u0060DegreesOfFreedom\u0060: defines the degrees of freedom\n\n  - \u0060PValueLeft\u0060: the left-tailed p-value \n\n  - \u0060PValueRight\u0060: the right-tailed p-value\n\n  - \u0060PValue\u0060: the two-tailed p-value\n\nAs we can see, when looking at the two-tailed p-value, our sample does _not_ differ significantly from our expected value. This matches our visual impression of the boxplot, where the sample distribution \nis centered around 4.5.\n\n\n## Two-sample t-test (unpaired data)\n\nThe t-test is most often used in its two-sample variant. Here, two samples, independent from each other, are compared. It is required that both samples are normally distributed.\nIn this next example, we are going to see if the gender of college athletes determines the number of concussions suffered over 3 years (from: _Covassin et al., 2003, Sex Differences and the Incidence of Concussions Among Collegiate Athletes, Journal of Athletic Training_).\n\n\n\u003Cimg style=\u0022max-width:75%\u0022 src=\u0022../../images/TwoSampleTTest.png\u0022\u003E\u003C/img\u003E\n\nFig. 2: **The two-sample t-test** The dashed orange and green lines depict the distribution of both samples that are compared with each other.\n\n*)\n\nopen System.Text\n\nlet rawDataAthletes = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/ConcussionsInMaleAndFemaleCollegeAthletes_adapted.tsv\u0022\n\nlet dataAthletesAsStream = new System.IO.MemoryStream(rawDataAthletes |\u003E Encoding.UTF8.GetBytes)\n\n// The schema helps us setting column keys.\nlet dataAthletesAsFrame = Frame.ReadCsv(dataAthletesAsStream, hasHeaders = false, separators = \u0022\\t\u0022, schema = \u0022Gender, Sports, Year, Concussion, Count\u0022)\n\ndataAthletesAsFrame.Print()\n\n// We need to filter out the columns and rows we don\u0027t need. Thus, we filter out the rows where the athletes suffered no concussions  \n// as well as filter out the columns without the number of concussions.\nlet dataAthletesFemale, dataAthletesMale =\n    let getAthleteGenderData gender =\n        let dataAthletesOnlyConcussion =\n            dataAthletesAsFrame\n            |\u003E Frame.filterRows (fun r objS -\u003E objS.GetAs \u0022Concussion\u0022)\n        let dataAthletesGenderFrame =\n            dataAthletesOnlyConcussion\n            |\u003E Frame.filterRows (fun r objS -\u003E objS.GetAs \u0022Gender\u0022 = gender)\n        dataAthletesGenderFrame\n        |\u003E Frame.getCol \u0022Count\u0022 \n        |\u003E Series.values\n        |\u003E vector\n    getAthleteGenderData \u0022Female\u0022, getAthleteGenderData \u0022Male\u0022\n    \n(**\n\nAgain, let\u0027s check our data via boxplots before we proceed on comparing them.\n\n*)\n\nlet boxPlot2 = \n    [\n        Chart.BoxPlot(y = dataAthletesFemale, Name = \u0022female college athletes\u0022, BoxPoints = StyleParam.BoxPoints.All, Jitter = 0.2)\n        Chart.BoxPlot(y = dataAthletesMale, Name = \u0022male college athletes\u0022, BoxPoints = StyleParam.BoxPoints.All, Jitter = 0.2)\n    ]\n    |\u003E Chart.combine\n    |\u003E Chart.withYAxisStyle \u0022number of concussions over 3 years\u0022\n\n\n(*** condition: ipynb ***)\n#if IPYNB\nboxPlot2\n#endif // IPYNB\n\n(***hide***)\nboxPlot2 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\nBoth samples are tested against using \u0060FSharp.Stats.Testing.TTest.twoSample\u0060 and assuming equal variances.\n\n*)\n\n// We test both samples against each other, assuming equal variances.\nlet twoSampleResult = TTest.twoSample true dataAthletesFemale dataAthletesMale\n\n(*** include-value:twoSampleResult ***)\n\n(**\n\nWith a p value of 0.58 the t-test indicate that there\u0027s no significant difference between the number of concussions over 3 years between male and female college athletes.\n\n\n## Two-sample t-test (paired data)\n\nPaired data describes data where each value from the one sample is connected with its respective value from the other sample.  \nIn the next case, the endurance performance of several persons in a normal situation (control situation) is compared to their performance after ingesting a specific amount of caffeine*. \nIt is the same person that performs the exercise but under different conditions. Thus, the resulting values of the persons under each condition are compared.  \nAnother example are time-dependent experiments: One measures, e.g., the condition of cells stressed with a high surrounding temperature in the beginning and after 30 minutes. \nThe measured cells are always the same, yet their conditions might differ.\nDue to the connectivity of the sample pairs the samples must be of equal length.\n\n*Source: W.J. Pasman, M.A. van Baak, A.E. Jeukendrup, A. de Haan (1995). _The Effect of Different Dosages of Caffeine on Endurance Performance Time_, International Journal of Sports Medicine, Vol. 16, pp225-230.\n\n*)\n\nlet rawDataCaffeine = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/CaffeineAndEndurance(wide)_adapted.tsv\u0022\n\nlet dataCaffeineAsStream = new System.IO.MemoryStream(rawDataCaffeine |\u003E Encoding.UTF8.GetBytes)\nlet dataCaffeineAsFrame = Frame.ReadCsv(dataCaffeineAsStream, hasHeaders = false, separators = \u0022\\t\u0022, schema = \u0022Subject ID, no Dose, 5 mg, 9 mg, 13 mg\u0022)\n\n// We want to compare the subjects\u0027 performances under the influence of 13 mg caffeine and in the control situation.\nlet dataCaffeineNoDose, dataCaffeine13mg =\n    let getVectorFromCol col = \n        dataCaffeineAsFrame\n        |\u003E Frame.getCol col\n        |\u003E Series.values\n        |\u003E vector\n    getVectorFromCol \u0022no Dose\u0022, getVectorFromCol \u002213 mg\u0022\n\n// Transforming our data into a chart.\nlet visualizePairedData = \n    Seq.zip dataCaffeineNoDose dataCaffeine13mg\n    |\u003E Seq.mapi (fun i (control,treatment) -\u003E \n        let participant = \u0022Person \u0022 \u002B string i \n        Chart.Line([\u0022no dose\u0022, control; \u002213 mg\u0022, treatment], Name = participant)\n        )\n    |\u003E Chart.combine\n    |\u003E Chart.withXAxisStyle \u0022\u0022\n    |\u003E Chart.withYAxisStyle(\u0022endurance performance\u0022, MinMax = (0.,100.))\n\n(**\n\n\n*)\n\n(*** condition: ipynb ***)\n#if IPYNB\nvisualizePairedData\n#endif // IPYNB\n\n(***hide***)\nvisualizePairedData |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n\n\nThe function for pairwise t-tests can be found at \u0060FSharp.Stats.Testing.TTest.twoSamplePaired\u0060. Note, that the order of the elements in each vector must be the same, so that a pairwise comparison can be performed.\n\n*)\n\nlet twoSamplePairedResult = TTest.twoSamplePaired dataCaffeineNoDose dataCaffeine13mg\n\n(*** include-value:twoSamplePairedResult ***)\n\n(**\n\nThe two-sample paired t-test suggests a significant difference beween caffeine and non-caffeine treatment groups with a p-value of 0.012. \n\n*)"},{"uri":"https://fslab.org/003_clustering_hierarchical.html","title":"Clustering with FSharp.Stats II: hierarchical clustering\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Clustering with FSharp.Stats II: hierarchical clustering\ncategory: datascience\nauthors: Benedikt Venn\nindex: 2\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n#endif // IPYNB\n\n\n(**\n\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath=content/tutorials/{{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n# Clustering with FSharp.Stats II: hierarchical clustering\n\n_Summary:_ This tutorial demonstrates hierarchical clustering with FSharp.Stats and how to visualize the results with Plotly.NET.\n\nIn the previous article of this series [k-means clustering using FSharp.Stats](002_clustering_kMeans.html) was introduced.\n\n## Introduction\n\nClustering methods can be used to group elements of a huge data set based on their similarity. Elements sharing similar properties cluster together and can be reported as coherent group.\nMany clustering algorithms require a predefined cluster number, that has to be provided by the experimenter.\nHierarchical clustering (hClust) does not require such cluster number definition. Instead, hierarchical clustering results in a tree structure, that has a single cluster (node) on its root and recursively splits up into clusters of \nelements that are more similar to each other than to elements of other clusters. For generating multiple clustering results with different number of clusters, \nthe clustering has to performed only once. Subsequently a cluster number can be defined to split up the clustering tree in the desired number of clusters.\nThe clustering tree is often represented as dendrogram.\n\n### There are two types of hClust:\n\n  - Agglomerative (bottom-up): Each data point is in its own cluster and the nearest ones are merged recursively. It is referred as agglomerative hierarchical clustering.\n\n  - Divisive (top-down): All data points are in the same cluster and you divide the cluster into two that are far away from each other.\n\n  - The presented implementation is an agglomerative type.\n\n### Distance measures\n\nThere are several distance metrics, that can be used as distance function. The commonly used one probably is Euclidean distance.\n\n### Linker\n\nWhen the distance between two clusters is calculated, there are several linkage types to choose from:\n\n  - **complete linkage**: maximal pairwise distance between the clusters (prone to break large clusters)\n\n  - **single linkage**: minimal pairwise distance between the clusters (sensitive to outliers)\n\n  - **centroid linkage**: distance between the two cluster centroids\n\n  - **average linkage**: average pairwise distance between the clusters (sensitive to cluster shape and size)\n\n  - **median linkage**: median pairwise distance between the clusters\n\n\n\u003Cimg style=\u0022max-width:100%\u0022 src=\u0022../../images/hClust.png\u0022\u003E\u003C/img\u003E\n\n\u003Cbr\u003E\n\n\nFor demonstration of hierarchical clustering, the classic iris data set is used, which consists of 150 records, each of which contains four measurements and a species identifier.\n\n## Referencing packages\n\n\u0060\u0060\u0060fsharp\n// Packages hosted by the Fslab community\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n// third party .net packages \n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\u0060\u0060\u0060\n\n*)\n\n(**\n## Loading data\n*)\nopen FSharp.Data\nopen Deedle\n\n// Retrieve data using the FSharp.Data package and read it as dataframe using the Deedle package\nlet rawData = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/iris.csv\u0022\nlet df = Frame.ReadCsvString(rawData)\n\ndf.Print()\n\n\n(*** include-output ***)\n\n(**\n\nLet\u0027s take a first look at the data with heatmaps using Plotly.NET. Each of the 150 records consists of four measurements and a species identifier. \nSince the species identifier occur several times (Iris-virginica, Iris-versicolor, and Iris-setosa), we create unique labels by adding the rows index to the species identifier.\n\n*)\nopen Plotly.NET\n\nlet colNames = [\u0022sepal_length\u0022;\u0022sepal_width\u0022;\u0022petal_length\u0022;\u0022petal_width\u0022]\n\n// isolate data as float [] []\nlet data = \n    Frame.dropCol \u0022species\u0022 df\n    |\u003E Frame.toJaggedArray\n    \n\n// isolate labels as seq\u003Cstring\u003E\nlet labels = \n    Frame.getCol \u0022species\u0022 df\n    |\u003E Series.values\n    |\u003E Seq.mapi (fun i s -\u003E sprintf \u0022%s_%i\u0022 s i)\n    |\u003E Array.ofSeq\n\nlet dataChart = \n    Chart.Heatmap(data,ColNames=colNames,RowNames=labels)\n    // required to fit the species identifier on the left side of the heatmap\n    |\u003E Chart.withMarginSize(Left=100.)\n    |\u003E Chart.withTitle \u0022raw iris data\u0022\n\n\n(*** condition: ipynb ***)\n#if IPYNB\ndataChart\n#endif // IPYNB\n\n(***hide***)\ndataChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n## Clustering\n\nThe function that performs hierarchical clustering can be found at \u0060FSharp.Stats.ML.Unsupervised.HierarchicalClustering.generate\u0060. It requires three input parameters:\n\n  1. Distance measure working on \u0060\u0027T\u0060 (from \u0060FSharp.Stats.ML.DistanceMetrics\u0060)\n  2. Linkage type\n  3. Data to cluster as \u0060\u0027T\u0060\n\n*)\n\nopen FSharp.Stats.ML\nopen FSharp.Stats.ML.Unsupervised\n\nlet distanceMeasure = DistanceMetrics.euclideanNaNSquared\n\nlet linker = HierarchicalClustering.Linker.centroidLwLinker\n\n// calculates the clustering and reports a single root cluster (node), \n// that may recursively contains further nodes\nlet clusterResultH = \n    HierarchicalClustering.generate distanceMeasure linker data\n\n// If a desired cluster number is specified, the following function cuts the cluster according\n// to the depth, that results in the respective number of clusters (here 3). Only leaves are reported.\nlet threeClusters = HierarchicalClustering.cutHClust 3 clusterResultH\n\n(**\n\nEvery cluster leaf contains its raw values and an index that indicates the position of the respective data \npoint in the raw data. The index can be retrieved from leaves using HierarchicalClustering.getClusterId.\n\n*)\n\n// Detailed information for 3 clusters are given\nlet inspectThreeClusters =\n    threeClusters\n    |\u003E List.map (fun cluster -\u003E \n        cluster\n        |\u003E List.map (fun leaf -\u003E \n            labels.[HierarchicalClustering.getClusterId leaf]\n            )\n        )\n\n(*** condition: ipynb ***)\n#if IPYNB\ninspectThreeClusters\n|\u003E List.mapi (fun i x -\u003E \n    let truncCluster = x.[0..4] |\u003E String.concat \u0022; \u0022 \n    sprintf \u0022Cluster%i: [%s ...]\u0022 i truncCluster \n    )\n|\u003E String.concat \u0022\\n\u0022\n#endif // IPYNB\n\n(***hide***)\ninspectThreeClusters\n|\u003E List.mapi (fun i x -\u003E \n    let truncCluster = x.[0..4] |\u003E String.concat \u0022; \u0022 \n    sprintf \u0022Cluster%i: [%s ...]\u0022 i truncCluster \n    )\n|\u003E String.concat \u0022\u003Cbr\u003E\u0022\n(*** include-it-raw ***)\n\n(**\n\nTo break up the tree structure but maintain the clustering order, the cluster tree has to be flattened.\n\n*)\n\n// To recursevely flatten the cluster tree into leaves only, use flattenHClust.\n// A leaf list is reported, that does not contain any cluster membership, \n// but is sorted by the clustering result.\nlet hLeaves = \n    clusterResultH\n    |\u003E HierarchicalClustering.flattenHClust\n    \n// Takes the sorted cluster result and reports a tuple of label and data value.\nlet dataSortedByClustering =    \n    hLeaves\n    |\u003E Seq.choose (fun c -\u003E \n        let label  = labels.[HierarchicalClustering.getClusterId c]\n        let values = HierarchicalClustering.tryGetLeafValue c\n        match values with\n        | None -\u003E None\n        | Some x -\u003E Some (label,x)\n        )\n\n(**\n\nThe visualization again is performed using a Plotly.NET heatmap. \n        \n*)\n\nlet hClusteredDataHeatmap = \n    let (hlable,hdata) =\n        dataSortedByClustering\n        |\u003E Seq.unzip\n    Chart.Heatmap(hdata,ColNames=colNames,RowNames=hlable)\n    // required to fit the species identifier on the left side of the heatmap\n    |\u003E Chart.withMarginSize(Left=100.)\n    |\u003E Chart.withTitle \u0022Clustered iris data (hierarchical clustering)\u0022\n\n(*** condition: ipynb ***)\n#if IPYNB\nhClusteredDataHeatmap\n#endif // IPYNB\n\n(***hide***)\nhClusteredDataHeatmap |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n(**\n\n\n## Limitations\n\n  1. There is no strong guidance on which distance function and linkage type should be used. It often is chosen arbitrarily according to the user\u0027s experience.\n  2. The visual interpretation of the dendrogram is difficult, since swapping the direction of some bifurcations may totally disturbe the visual impression.\n\n## Notes\n\n  - Please note that depending on what data you want to cluster, a column wise z-score normalization may be required. In the presented example differences in sepal width have a reduced influence because\n  the absolute variation is low.\n\n## References\n\n  - Vijaya et al., A Review on Hierarchical Clustering Algorithms, Journal of Engineering and Applied Sciences, 2017\n  - Rani and Rohil, A Study of Hierarchical Clustering Algorithm, International Journal of Information and Computation Technology, 2013\n  - FSharp.Stats documentation, fslaborg, https://fslab.org/FSharp.Stats/Clustering.html\n\n## Further reading\n\nExamples are taken from [FSharp.Stats documentation](https://fslab.org/FSharp.Stats/Clustering.html) that covers various techniques for an optimal cluster number determination.\n\nThe next article in this series covers [DBSCAN using FSharp.Stats](004_clustering_DBSCAN.html).\n\n*)\n\n\n"},{"uri":"https://fslab.org/index.html","title":"This is not the page you are looking for.\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: -\ncategory: hidden\nauthors: -\nindex: 0\n---\n*)\n\n(**\n# This is not the page you are looking for.\n\nWhoops! please tell us how you got here. You are most likely looking for this page: https://fslab.org/tutorials.html\n*)"},{"uri":"https://fslab.org/002_clustering_kMeans.html","title":"Clustering with FSharp.Stats I: k-means\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Clustering with FSharp.Stats I: k-means\ncategory: datascience\nauthors: Benedikt Venn\nindex: 1\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n#endif // IPYNB\n\n(**\n\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath=content/tutorials/{{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n\n# Clustering with FSharp.Stats I: k-means\n\n_Summary:_ This tutorial demonstrates k means clustering with FSharp.Stats and how to visualize the results with Plotly.NET.\n\n## Introduction\n\nClustering methods can be used to group elements of a huge data set based on their similarity. Elements sharing similar properties cluster together and can be reported as coherent group.\nk-means clustering is a frequently used technique, that segregates the given data into k clusters with similar elements grouped in each cluster, but high variation between the clusters.\nThe algorithm to cluster a n-dimensional dataset can be fully described in the following 4 steps:\n\n  1. Initialize k n-dimensional centroids, that are randomly distributed over the data range.\n  2. Calculate the distance of each point to all centroids and assign it to the nearest one.\n  3. Reposition all centroids by calculating the average point of each cluster.\n  4. Repeat step 2-3 until convergence.\n\n### Centroid initiation\n\nSince the random initiation of centroids may influences the result, a second initiation algorithm is proposed (_cvmax_), that extract a set of medians from the dimension with maximum variance to initialize the centroids. \n\n### Distance measure\n\nWhile several distance metrics can be used (e.g. Manhattan distance or correlation measures) it is preferred to use Euclidean distance.\nIt is recommended to use a squared Euclidean distance. To not calculate the square root does not change the result but saves computation time.\n\n\u003Cimg style=\u0022max-width:75%\u0022 src=\u0022../../images/kMeans.png\u0022\u003E\u003C/img\u003E\n\n\u003Cbr\u003E\n\n\nFor demonstration of k-means clustering, the classic iris data set is used, which consists of 150 records, each of which contains four measurements and a species identifier.\n\n## Referencing packages\n\n\u0060\u0060\u0060fsharp\n// Packages hosted by the Fslab community\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n// third party .net packages \n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\u0060\u0060\u0060\n\n*)\n\n(**\n## Loading data\n*)\nopen FSharp.Data\nopen Deedle\n\n// Retrieve data using the FSharp.Data package and read it as dataframe using the Deedle package\nlet rawData = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/iris.csv\u0022\nlet df = Frame.ReadCsvString(rawData)\n\ndf.Print()\n\n(*** include-output ***)\n\n(**\n\nLet\u0027s take a first look at the data with heatmaps using Plotly.NET. Each of the 150 records consists of four measurements and a species identifier. \nSince the species identifier occur several times (_Iris-virginica_, _Iris-versicolor_, and _Iris-setosa_), we create unique labels by adding the rows index to the species identifier.\n\n*)\nopen Plotly.NET\n\nlet colNames = [\u0022sepal_length\u0022;\u0022sepal_width\u0022;\u0022petal_length\u0022;\u0022petal_width\u0022]\n\n// isolate data as float [] []\nlet data = \n    Frame.dropCol \u0022species\u0022 df\n    |\u003E Frame.toJaggedArray\n\n//isolate labels as seq\u003Cstring\u003E\nlet labels = \n    Frame.getCol \u0022species\u0022 df\n    |\u003E Series.values\n    |\u003E Seq.mapi (fun i s -\u003E sprintf \u0022%s_%i\u0022 s i)\n\nlet dataChart = \n    Chart.Heatmap(data,ColNames=colNames,RowNames=labels)\n    // required to fit the species identifier on the left side of the heatmap\n    |\u003E Chart.withMarginSize(Left=100.)\n    |\u003E Chart.withTitle \u0022raw iris data\u0022\n\n// required to fit the species identifier on the left side of the heatmap\n\n(*** condition: ipynb ***)\n#if IPYNB\ndataChart\n#endif // IPYNB\n\n(***hide***)\ndataChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n## Clustering\n\nThe function that performs k-means clustering can be found at \u0060FSharp.Stats.ML.Unsupervised.IterativeClustering.kmeans\u0060. It requires four input parameters:\n\n  1. Centroid initiation method\n  2. Distance measure (from \u0060FSharp.Stats.ML.DistanceMetrics\u0060)\n  3. Data to cluster as \u0060float [] []\u0060, where each entry of the outer array is a sequence of coordinates\n  4. _k_, the number of clusters that are desired\n\n\n*)\n\nopen FSharp.Stats\nopen FSharp.Stats.ML\nopen FSharp.Stats.ML.Unsupervised\n\n// For random cluster initiation use randomInitFactory:\nlet rnd = System.Random()\nlet randomInitFactory : IterativeClustering.CentroidsFactory\u003Cfloat []\u003E = \n    IterativeClustering.randomCentroids\u003Cfloat []\u003E rnd\n\n// For assisted cluster initiation use cvmaxFactory:\n//let cvmaxFactory : IterativeClustering.CentroidsFactory\u003Cfloat []\u003E = \n//    IterativeClustering.intitCVMAX\n\nlet distanceFunction = DistanceMetrics.euclideanNaNSquared\n  \nlet kmeansResult = \n    IterativeClustering.kmeans distanceFunction randomInitFactory data 4\n\n\n(**\nAfter all centroids are set, the affiliation of a datapoint to a cluster can be determined by minimizing the distance of the respective point to each of the centroids.\nA function realizing the mapping is integrated in the \u0060kmeansResult\u0060.\n\n*)\n\nlet clusteredIrisData =\n    Seq.zip labels data\n    |\u003E Seq.map (fun (species,dataPoint) -\u003E \n        let clusterIndex,centroid = kmeansResult.Classifier dataPoint\n        clusterIndex,species,dataPoint)\n\n// Each datapoint is given associated with its cluster index, species identifier, and coordinates.\n\n(*** condition: ipynb ***)\n#if IPYNB\nclusteredIrisData\n|\u003E Seq.take 10\n|\u003E Seq.map (fun (a,b,c) -\u003E sprintf \u0022%i, %A, %A\u0022 a b c)\n|\u003E String.concat \u0022\\n\u0022\n|\u003E fun x -\u003E x \u002B \u0022\\n... \u0022\n#endif // IPYNB\n\n(***hide***)\nlet printClusters=\n    clusteredIrisData\n    |\u003E Seq.take 7\n    |\u003E Seq.map (fun (a,b,c) -\u003E sprintf \u0022%i, %A, %A\u0022 a b c)\n    |\u003E String.concat \u0022\\n\u0022\n    |\u003E fun x -\u003E x \u002B \u0022\\n ... \u0022\n\n(*** include-value:printClusters ***)\n(**\n\n## Visualization of the clustering result as heatmap\n\nThe datapoints are sorted according to their associated cluster index and visualized in a combined heatmap.\n*)\n\nlet clusterChart =\n    clusteredIrisData\n    //sort all data points according to their assigned cluster number\n    |\u003E Seq.sortBy (fun (clusterIndex,label,dataPoint) -\u003E clusterIndex)\n    |\u003E Seq.unzip3\n    |\u003E fun (_,labels,d) -\u003E \n        Chart.Heatmap(d,ColNames=colNames,RowNames=labels)\n        // required to fit the species identifier on the left side of the heatmap\n        |\u003E Chart.withMarginSize(Left=100.)\n        |\u003E Chart.withTitle \u0022clustered iris data (k-means clustering)\u0022\n(**\n\n*)\n(*** condition: ipynb ***)\n#if IPYNB\nclusterChart\n#endif // IPYNB\n\n(***hide***)\nclusterChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n\nTo visualize the result in a three-dimensional chart, three of the four measurements are isolated after clustering and visualized as 3D-scatter plot.\n\n*)\n\nlet clusterChart3D =\n    //group clusters\n    clusteredIrisData\n    |\u003E Seq.groupBy (fun (clusterIndex,label,dataPoint) -\u003E clusterIndex)\n    //for each cluster generate a scatter plot\n    |\u003E Seq.map (fun (clusterIndex,cluster) -\u003E \n        cluster\n        |\u003E Seq.unzip3\n        |\u003E fun (clusterIndex,label,data) -\u003E \n            let clusterName = sprintf \u0022cluster %i\u0022 (Seq.head clusterIndex)\n            //for 3 dimensional representation isolate sepal length, petal length, and petal width\n            let truncData = data |\u003E Seq.map (fun x -\u003E x.[0],x.[2],x.[3]) \n            Chart.Scatter3d(truncData,mode=StyleParam.Mode.Markers,Name = clusterName,Labels=label)\n        )\n    |\u003E Chart.combine\n    |\u003E Chart.withTitle \u0022isolated coordinates of clustered iris data (k-means clustering)\u0022\n    |\u003E Chart.withX_AxisStyle colNames.[0]\n    |\u003E Chart.withY_AxisStyle colNames.[2]\n    |\u003E Chart.withZ_AxisStyle colNames.[3]\n\n(**\n\n*)\n(*** condition: ipynb ***)\n#if IPYNB\nclusterChart3D\n#endif // IPYNB\n\n(***hide***)\nclusterChart3D |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n\n### Optimal cluster number\n\nThe identification of the optimal cluster number _k_ in terms of the average squared distance of each point to its centroid \ncan be realized by performing the clustering over a range of _k_\u0027s multiple times and taking the _k_ according to the elbow criterion.\nFurther more robust and advanced cluster number determination techniques can be found [here](https://fslab.org/FSharp.Stats/Clustering.html#Determining-the-optimal-number-of-clusters).\n\n*)\n\nlet getBestkMeansClustering bootstraps k =\n    let dispersions =\n        Array.init bootstraps (fun _ -\u003E \n            IterativeClustering.kmeans distanceFunction randomInitFactory data k\n            )\n        |\u003E Array.map (fun clusteringResult -\u003E IterativeClustering.DispersionOfClusterResult clusteringResult)\n    Seq.mean dispersions,Seq.stDev dispersions\n\nlet iterations = 10\n\nlet maximalK = 10\n\nlet bestKChart = \n    [2 .. maximalK] \n    |\u003E List.map (fun k -\u003E \n        let mean,stdev = getBestkMeansClustering iterations k\n        k,mean,stdev\n        )\n    |\u003E List.unzip3\n    |\u003E fun (ks,means,stdevs) -\u003E \n        Chart.Line(ks,means)\n        |\u003E Chart.withYErrorStyle(stdevs)\n        |\u003E Chart.withX_AxisStyle \u0022k\u0022\n        |\u003E Chart.withY_AxisStyle \u0022average dispersion\u0022\n        |\u003E Chart.withTitle \u0022iris data set average dispersion per k\u0022\n(**\n\n*)\n(*** condition: ipynb ***)\n#if IPYNB\nbestKChart\n#endif // IPYNB\n\n(***hide***)\nbestKChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n\n\n## Limitations\n\n  1. Outlier have a strong influence on the positioning of the centroids. \n  2. Determining the correct number of clusters in advance is critical. Often it is chosen according to the number of classes present in the dataset which isn\u0027t in the spirit of clustering procedures.\n\n## Notes\n\n  - Please note that depending on what data you want to cluster, a column wise z-score normalization may be required. In the presented example differences in sepal width have a reduced influence because\n  the absolute variation is low.\n\n## References\n\n  - FSharp.Stats documentation, fslaborg, https://fslab.org/FSharp.Stats/Clustering.html\n  - Shraddha and Saganna, A Review On K-means Data Clustering Approach, International Journal of Information \u0026 Computation Technology, Vol:4 No:17, 2014\n  - Moth\u0027d Belal, A New Algorithm for Cluster Initialization, International Journal of Computer and Information Engineering, Vol:1 No:4, 2007\n  - Singh et al., K-means with Three different Distance Metrics, International Journal of Computer Applications, 2013, DOI:10.5120/11430-6785\n  - Kodinariya and Makwana, Review on Determining of Cluster in K-means Clustering, International Journal of Advance Research in Computer Science and Management Studies, 2013\n\n## Further reading\n  \nExamples are taken from [FSharp.Stats documentation](https://fslab.org/FSharp.Stats/Clustering.html) that covers various techniques for an optimal cluster number determination.\n  \nThe next article in this series covers [hierarchical clustering using FSharp.Stats](003_clustering_hierarchical.html).\n\n*)\n\n\n"},{"uri":"https://fslab.org/004_clustering_DBSCAN.html","title":"Clustering with FSharp.Stats III: DBSCAN\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Clustering with FSharp.Stats III: DBSCAN\ncategory: datascience\nauthors: Benedikt Venn\nindex: 2\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n#endif // IPYNB\n\n(**\n\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath=content/tutorials/{{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n\n# Clustering with FSharp.Stats III: DBSCAN\n\n_Summary:_ This tutorial demonstrates DBSCAN with FSharp.Stats and how to visualize the results with Plotly.NET.\n\nIn the previous article of this series [hierarchical clustering using FSharp.Stats](003_clustering_hierarchical.html) was introduced.\n\n## Introduction\n\nClustering methods can be used to group elements of a huge data set based on their similarity. Elements sharing similar properties cluster together and can be reported as coherent group.\nDensity-Based Spatial Clustering of Applications with Noise (DBSCAN) was developed to identify clusters with similar density and allows the exclusion of noise points.\n\n### Two global parameters have to be defined:\n\n  - **\u03B5 (eps)**: radius in which the neighbourhood of each point is checked \n  - **minPts**: minimal number of data points, that must fall into the neighbourhood of a region to be defined as dense\n\n### Data points are classified as:\n\n  - **Core point**: Within a radius of eps there are more (or equal) data points than minPts present.\n  - **Border point**: Within a radius of eps there are less data points than minPts present, but a core point is within the neighbourhood.\n  - **Noise point**: None of the conditions above apply.\n\n\u003Cimg style=\u0022max-width:75%\u0022 src=\u0022../../images/dbscan.png\u0022 class=\u0022center\u0022\u003E\u003C/img\u003E\n\n\u003Cbr\u003E\n\nFor demonstration of DBSCAN, the classic iris data set is used, which consists of 150 records, each of which contains four measurements and a species identifier.\nIn this tutorial we are going to perform DBSCAN on two- and three-dimensional data.\n\n## Referencing packages\n\n\u0060\u0060\u0060fsharp\n// Packages hosted by the Fslab community\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n// third party .net packages \n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\u0060\u0060\u0060\n\n*)\n\n(**\n## Loading data\n*)\nopen FSharp.Data\nopen FSharp.Stats\nopen Deedle\n\n// Retrieve data using the FSharp.Data package and read it as dataframe using the Deedle package\nlet rawData = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/iris.csv\u0022\nlet df = Frame.ReadCsvString(rawData)\n\ndf.Print()\n\n\n(*** include-output ***)\n\n(**\n\nLet\u0027s take a first look at the data with 2D and 3D scatter plots using Plotly.NET. Each of the 150 records consists of four measurements and a species identifier. \nSince the species identifier occur several times (Iris-virginica, Iris-versicolor, and Iris-setosa), we create unique labels by adding the rows index to the species identifier.\n\n*)\nopen Plotly.NET\nopen FSharp.Stats.ML.Unsupervised\n\nlet header2D = [\u0022petal_length\u0022;\u0022petal_width\u0022]\nlet header3D = [\u0022sepal_length\u0022;\u0022petal_length\u0022;\u0022petal_width\u0022]\n\n//extract petal length and petal width\nlet data2D = \n    Frame.sliceCols header2D df\n    |\u003E Frame.toJaggedArray\n\n//extract sepal length, petal length, and petal width\nlet data3D = \n    Frame.sliceCols header3D df\n    |\u003E Frame.toJaggedArray\n\nlet labels = \n    Frame.getCol \u0022species\u0022 df\n    |\u003E Series.values\n    |\u003E Seq.mapi (fun i s -\u003E sprintf \u0022%s_%i\u0022 s i)\n\nlet rawChart2D =\n    let unzippedData =\n        data2D\n        |\u003E Array.map (fun x -\u003E x.[0],x.[1])\n    Chart.Scatter(unzippedData,mode=StyleParam.Mode.Markers,Labels=labels)\n    |\u003E Chart.withXAxisStyle header2D.[0]\n    |\u003E Chart.withYAxisStyle header2D.[1]\n    |\u003E Chart.withTitle \u0022rawChart2D\u0022\n\nlet rawChart3D =\n    let unzippedData =\n        data3D\n        |\u003E Array.map (fun x -\u003E x.[0],x.[1],x.[2])\n    Chart.Scatter3d(unzippedData,mode=StyleParam.Mode.Markers,Labels=labels)\n    |\u003E Chart.withXAxisStyle header3D.[0]\n    |\u003E Chart.withYAxisStyle header3D.[1]\n    |\u003E Chart.withZAxisStyle header3D.[2]\n    |\u003E Chart.withTitle \u0022rawChart3D\u0022\n\n\n(*** condition: ipynb ***)\n#if IPYNB\nrawChart2D\n#endif // IPYNB\n\n(***hide***)\nrawChart2D |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\u003Cbr\u003E\n*)\n\n(*** condition: ipynb ***)\n#if IPYNB\nrawChart3D\n#endif // IPYNB\n\n(***hide***)\nrawChart3D |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n(**\n## Clustering\n\nThe function that performs DBSCAN can be found at \u0060FSharp.Stats.ML.Unsupervised.DbScan.compute\u0060. It requires four input parameters:\n\n  1. Distance measure (\u0060from FSharp.Stats.ML.DistanceMetrics\u0060) (\u0060seq\u003C\u0027T\u003E -\u003E seq\u003C\u0027T\u003E -\u003E float\u0060)\n  1. minPts (\u0060int\u0060)\n  3. eps (\u0060float\u0060)\n  4. data points as sequence of coordinate sequences (\u0060seq\u003C#seq\u003C\u0027T\u003E\u003E\u0060)\n\nThe clustering result consists of a sequence of noise point coordinates and a sequence of clusters containing all related point coordinates.\n\n*)\nopen FSharp.Stats.ML\nopen FSharp.Stats.ML.Unsupervised\n\n\nlet eps2D = 0.5\nlet eps3D = 0.7\n\nlet minPts = 20\n\nlet result2D = DbScan.compute DistanceMetrics.Array.euclidean minPts eps2D data2D\n\n(***hide***)\nlet printClusters2D = result2D.ToString()\n(*** include-value:printClusters2D ***)\n\nlet result3D = DbScan.compute DistanceMetrics.Array.euclidean minPts eps3D data3D\n\n(***hide***)\nlet printClusters3D = result3D.ToString()\n\n(*** include-value:printClusters3D ***)\n\n(**\n## Visualization of clustering result\n\nTo visualize the clustering result coordinates of each cluster and noise points are visualized separately and combined in a single scatter plot.\n\n### 2D clustering result visualization\n\n*)\n\n\n//to create a chart with two dimensional data use the following function\n    \nlet chartCluster2D = \n    result2D.Clusterlist\n    |\u003E Seq.mapi (fun i l -\u003E\n        l\n        |\u003E Seq.map (fun x -\u003E x.[0],x.[1])\n        |\u003E Seq.distinct //more efficient visualization; no difference in plot but in point numbers\n        |\u003E Chart.Point\n        |\u003E Chart.withTraceName (sprintf \u0022Cluster %i\u0022 i))\n    |\u003E Chart.combine\n\nlet chartNoise2D = \n    result2D.Noisepoints\n    |\u003E Seq.map (fun x -\u003E x.[0],x.[1])  \n    |\u003E Seq.distinct //more efficient visualization; no difference in plot but in point numbers\n    |\u003E Chart.Point\n    |\u003E Chart.withTraceName \u0022Noise\u0022\n\nlet chartTitle2D = \n    let noiseCount   = result2D.Noisepoints |\u003E Seq.length\n    let clusterCount = result2D.Clusterlist |\u003E Seq.length\n    let clPtsCount   = result2D.Clusterlist |\u003E Seq.sumBy Seq.length\n    $\u0022eps: %.1f{eps2D} minPts: %i{minPts} pts: %i{noiseCount \u002B clPtsCount} cluster: %i{clusterCount} noisePts: %i{noiseCount}\u0022 \n\nlet chart2D =\n    [chartNoise2D;chartCluster2D]\n    |\u003E Chart.combine\n    |\u003E Chart.withTitle chartTitle2D\n    |\u003E Chart.withXAxisStyle header2D.[0]\n    |\u003E Chart.withYAxisStyle header2D.[1]\n\n(*** condition: ipynb ***)\n#if IPYNB\nchart2D\n#endif // IPYNB\n\n(***hide***)\nchart2D |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n### 3D clustering result visualization\n\n\n\n*)\n\n\nlet chartCluster3D = \n    result3D.Clusterlist\n    |\u003E Seq.mapi (fun i l -\u003E\n        l\n        |\u003E Seq.map (fun x -\u003E x.[0],x.[1],x.[2])\n        |\u003E Seq.distinct //faster visualization; no difference in plot but in point number\n        |\u003E fun x -\u003E Chart.Scatter3d (x,StyleParam.Mode.Markers)\n        |\u003E Chart.withTraceName (sprintf \u0022Cluster_%i\u0022 i))\n    |\u003E Chart.combine\n\nlet chartNoise3D =\n    result3D.Noisepoints\n    |\u003E Seq.map (fun x -\u003E x.[0],x.[1],x.[2])  \n    |\u003E Seq.distinct //faster visualization; no difference in plot but in point number\n    |\u003E fun x -\u003E Chart.Scatter3d (x,StyleParam.Mode.Markers)\n    |\u003E Chart.withTraceName \u0022Noise\u0022\n\nlet chartname3D = \n    let noiseCount   = result3D.Noisepoints |\u003E Seq.length\n    let clusterCount = result3D.Clusterlist |\u003E Seq.length\n    let clPtsCount   = result3D.Clusterlist |\u003E Seq.sumBy Seq.length\n    $\u0022eps: %.1f{eps3D} minPts: %i{minPts} pts: %i{noiseCount \u002B clPtsCount} cluster: %i{clusterCount} noisePts: %i{noiseCount}\u0022 \n   \nlet chart3D = \n    [chartNoise3D;chartCluster3D]\n    |\u003E Chart.combine\n    |\u003E Chart.withTitle chartname3D\n    |\u003E Chart.withXAxisStyle header3D.[0]\n    |\u003E Chart.withYAxisStyle header3D.[1]\n    |\u003E Chart.withZAxisStyle header3D.[2]\n    \n//for faster computation you can use the squaredEuclidean distance and set your eps to its square\nlet clusteredChart3D() = DbScan.compute DistanceMetrics.Array.euclideanNaNSquared 20 (0.7**2.) data3D \n\n\n(*** condition: ipynb ***)\n#if IPYNB\nchart3D\n#endif // IPYNB\n\n(***hide***)\nchart3D |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n\n## Limitations\n\n  1. The selection of minPts and eps is critical and even small deviations can severely influence the final results\n  2. When data points are of varying density, DBSCAN is not appropriate\n\n## Notes\n\n  - Please note that depending on what data you want to cluster, a column wise z-score normalization may be required. In the presented example differences in sepal width have a reduced influence because\n  the absolute variation is low.\n\n## References\n\n  - [FSharp.Stats documentation](https://fslab.org/FSharp.Stats/Clustering.html), fslaborg, \n  - Shinde and Sankhe, Comparison of Enhanced DBSCAN Algorithms: A Review, International Journal of Engeneering Research \u0026 Technology, 2017\n  - Nagaraju et al., An effective density based approach to detect complex data clusters using notion of neighborhood difference, Int. J. Autom. Comput., 2017, https://doi.org/10.1007/s11633-016-1038-7 \n\n*)\n\n"},{"uri":"https://fslab.org/introductionII.html","title":"F# Introduction II: Scripting in F#\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: F# Introduction II: Scripting in F#\ncategory: fsharp\nauthors: Jonathan Ott\nindex: 2\n---\n*)\n(**\n# F# Introduction II: Scripting in F#\n\n## Creating a .fsx file\n\n### Visual Studio\n\n* Open Visual Studio and navigate to the \u0022File\u0022 tab, where you select to create a new file.\n* Select the \u0022F# Script File\u0022 option.  \n    \n    ![]({{root}}images/FsxVS.png)\n\n* You now have a working script file. You can write code and execute it by selecting it and pressing \u0060Alt \u002B Enter\u0060.\n\n### Visual Studio Code\n\n* Open Visual Studio Code and navigate to the \u0022File\u0022 tab, where you select to create a new file.\n* You will then be prompted to select a language. Choose F# there.  \n\n    ![]({{root}}images/FsxVSCode.png)\n\n* You now have a working script file. You can write code and execute it by selecting it and pressing \u0060Alt \u002B Enter\u0060.\n* When you are done with your file save it as .fsx.\n\n## Referencing packages\n\n* Packages on nuget can be referenced using \u0027#r \u0022nuget: PackageName\u0022\u0027:\n*)\n// References the latest stable package\n#r \u0022nuget: FSharp.Stats\u0022\n// References a sepcific package version\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.6\u0022\n(**\n* Alternatively, .dll files can be referenced directly with the following syntax:\n*)\n(***do-not-eval***)\n#r @\u0022Your\\Path\\To\\Package\\PackageName.dll\u0022\n\n(**\n## Working with notebooks\n\n* Visual Studio Code supports working with notebooks\n* To work with notebooks, you need to install the [.NET Interactive Notebooks](https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.dotnet-interactive-vscode) extension.  \n\n    ![]({{root}}images/NotebooksExt.png)\n\n* A new Notebook can be opened by pressing \u0060Ctrl \u002B Shift \u002B P\u0060 and selecting \u0022.NET Interactive: Create new blank notebook\u0022.\n* You will then be prompted to create it either as .dib or .ipynb.\n* When asked for the language, choose F#\n* Notebooks contain Text- and Codeblocks:\n* Adding a new Text- or Codeblock can be done by hovering at the upper or lower border of an existing block or upper part of the notebook and pressing \u0060\u002BCode\u0060 or \u0060\u002BMarkdown\u0060  \n\n    ![]({{root}}images/NBBlock.png)\n\n* Working with Textblocks:\n    You can edit a Textblock by doubleklicking on it. Inside a Textblock you can write plain text or style it with [Markdown](https://en.wikipedia.org/wiki/Markdown).\n    Once you are finished you can press the \u0060Esc\u0060 button.\n* Working with Codeblocks:\n    You can start editing any Codeblock by clicking in it. In there you can start writing your own code or edit existing code. Once you are done you can execute the Codeblock by pressing \u0060Ctrl \u002B Alt \u002B Enter\u0060.\n    If you want to execute all codeblocks at once, you can press on the two arrows in the upper left corner of the notebook.\n*)\n"},{"uri":"https://fslab.org/001_getting-started.html","title":"Getting started\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Getting started\ncategory: datascience\nauthors: David Zimmer\nindex: 0\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n#endif // IPYNB\n\n(**\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath=content/tutorials/{{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n# Getting started\n\nGlad to see you here! Now that you found out and learned about FsLab, this section aims to illustrate how FsLab packages synergize and can be used to tackle\npractical data science challenges. Note that every package used througout the tutorial has its own documentation so if you are interested in Deedle (link), FSharp.Stats or Plotly.Net feel free to take a deeper dive.\n\n## Referencing packages\n\nFsLab is a meant to be a project incubation space and can be thought of as a safe heaven for both, package developers and package users by providing guidelines and tutorials. Packages provided by the community can be used on their own, in combination with other FsLab packages but also in combination with any other .netstandard 2.0 compatible package. From F# 5.0 on packages can be referenced using the following notation:\n\n\u0060\u0060\u0060fsharp\n// Packages hosted by the Fslab community\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n// third party .net packages \n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#r \u0022nuget: FSharp.Data\u0022\n\u0060\u0060\u0060\n\nafter referencing the packages one can access their namespaces and use provided functions. In the following example we will reference the\ntop level namespaces and then use a function provided by the FSharp.Stats package to calculate a factorial:\n*)\nopen FSharp.Stats\n\nlet factorialOf3 = SpecialFunctions.Factorial.factorial 3\n\n(*** condition: ipynb ***)\n#if IPYNB\nfactorialOf3\n#endif // IPYNB\n\n(***include-value:factorialOf3***)\n\n(**\n## Data access\nEquipped with these packages we are now ready to tackle promises made in the first paragraph: solving a practical data science problem. We will start by retrieving the data using the FSharp.Data package, subsequently we will use Deedle (link), a powerful data frame library that makes tabular data accessible by data frame programming. (Note that the chosen names give insight on their type, however thanks to FSharp being a strongly typed language and the we can at any time hower over single values to see the assigned type.)\n*)\nopen FSharp.Data\nopen Deedle\n\n// Retrieve data using the FSharp.Data package\nlet rawData = Http.RequestString @\u0022https://raw.githubusercontent.com/dotnet/machinelearning/master/test/data/housing.txt\u0022\n\n// And create a data frame object using the ReadCsvString method provided by Deedle.\n// Note: Of course you can directly provide the path to a local source.\nlet df = Frame.ReadCsvString(rawData,hasHeaders=true,separators=\u0022\\t\u0022)\n\n// Using the Print() method, we can use the Deedle pretty printer to have a look at the data set.\ndf.Print()\n\n(*** include-output ***)\n\n(**\n## Data crunching\nThe data set of choice is the boston housing data set. As you can see from analyzing the printed output, it consists of 506 rows. Each row represents a house in the boston city area and each column encodes a feature/variable, such as the number of rooms per dwelling (RoomsPerDwelling), Median value of owner-occupied homes in $1000\u0027s (MedianHomeValue) and even variables indicating if the house is bordering river charles (CharlesRiver, value = 1) or not (CharlesRiver, value = 0). \n\nLets say in our analysis we are only interested in the variables just described, furthermore we only want to keep rows where the value of the indicator variable is 0. We can use Deedle to easily create a new frame that fullfills our criteria. In this example we also cast the value of the column \u0022CharlesRiver\u0022 to be of type bool, this illustrates how data frame programming can become typesafe using deedle.\n*)\n\nlet housesNotAtRiver = \n    df\n    |\u003E Frame.sliceCols [\u0022RoomsPerDwelling\u0022;\u0022MedianHomeValue\u0022;\u0022CharlesRiver\u0022]\n    |\u003E Frame.filterRowValues (fun s -\u003E s.GetAs\u003Cbool\u003E(\u0022CharlesRiver\u0022) |\u003E not ) \n\n//sprintf \u0022The new frame does now contain: %i rows and %i columns\u0022 housesNotAtRiver.RowCount housesNotAtRiver.ColumnCount\n\nhousesNotAtRiver.Print()\n\n(*** include-output ***)\n\n(**\n## Data exploration\n\nExploratory data analysis is an approach favored by many - to meet this demand we strongly advertise the use of Plotly.Net. The following snippet illustrates how we can access a column of a data frame and create an interactive chart in no time. Since we might want an idea of the distribution of the house prices a histogram can come in handy: \n*)\nopen Plotly.NET\n\n// Note that we explicitly specify that we want to work with the values as floats. \n// Since the row identity is not needed anymore when plotting the distribution we can\n// directly convert the collection to a FSharp Sequence. \nlet pricesNotAtRiver : seq\u003Cfloat\u003E = \n    housesNotAtRiver\n    |\u003E Frame.getCol \u0022MedianHomeValue\u0022\n    |\u003E Series.values\n    \nlet h1 = \n    Chart.Histogram(pricesNotAtRiver)\n    |\u003E Chart.withXAxisStyle(\u0022median value of owner occupied homes in 1000s\u0022)\n    |\u003E Chart.withXAxisStyle(\u0022price distribution\u0022)\n\n(*** condition: ipynb ***)\n#if IPYNB\nh1\n#endif // IPYNB\n\n(***hide***)\nh1 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\nSince plotly charts are interactive they invite us to combine mutliple charts. Let repeat the filter step and see if houses that are located at the river show a similar distribution:\n*)\n\nlet housesAtRiver = \n    df\n    |\u003E Frame.sliceCols [\u0022RoomsPerDwelling\u0022;\u0022MedianHomeValue\u0022;\u0022CharlesRiver\u0022]\n    |\u003E Frame.filterRowValues (fun s -\u003E s.GetAs\u003Cbool\u003E(\u0022CharlesRiver\u0022))\n\nlet pricesAtRiver : seq\u003Cfloat\u003E = \n    housesAtRiver\n    |\u003E Frame.getCol \u0022MedianHomeValue\u0022\n    |\u003E Series.values\n\nlet h2 =     \n    [\n    Chart.Histogram(pricesNotAtRiver)\n    |\u003E Chart.withTraceName \u0022not at river\u0022\n    Chart.Histogram(pricesAtRiver)\n    |\u003E Chart.withTraceName \u0022at river\u0022\n    ]\n    |\u003E Chart.combine\n    |\u003E Chart.withXAxisStyle(\u0022median value of owner occupied homes in 1000s\u0022)\n    |\u003E Chart.withXAxisStyle(\u0022Comparison of price distributions\u0022)\n\n(***hide***)\nh2 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\nThe interactive chart allows us to compare the distributions directly. We can now reconstruct our own idea of the city of boston, the sampled area, just by looking at the data e.g.:\n\nAssuming that the sampling process was homogenous while observing that there are much more houses sampled that are not located on the riverside could indicate that a spot on the river is a scarce commodity.\nThis could also be backed by analyzing the tails of the distribution: it seems that houses located at the river are given a head-start in their assigned value - the distribution of the riverside houses is truncated on the left. \n\nSuppose we would have a customer that wants two models, one to predict the prices of a house at the riverside and one that predicts the prices if this is not the case, then we can meet this demand by using FSharp.Stats in combination with Deedle. Of course we need a variable that is indicative of the house price, in this we will check if the number of rooms per dwelling correlates with the house value:\n*)\n\nlet pricesAll :Series\u003Cint,float\u003E = \n    df\n    |\u003E Frame.getCol \u0022MedianHomeValue\u0022\n\nlet roomsPerDwellingAll :Series\u003Cint,float\u003E = \n    df\n    |\u003E Frame.getCol \u0022RoomsPerDwelling\u0022   \n\nlet correlation = \n    let tmpPrices,tmpRooms = \n        Series.zipInner pricesAll roomsPerDwellingAll    \n        |\u003E Series.values \n        |\u003E Seq.unzip\n    Correlation.Seq.pearson tmpPrices tmpRooms\n                                              \n(***include-value:correlation***)\n\n(**\nSo indeed, the number of rooms per dwelling shows a positiv correlation with the house prices. With a pearson correlation of ~0.7 it does not explain the house prices completely - but this is nothing that really surprises us, as one of our hypothesis is that the location (e.g. riverside) does also have influence on the price -  however, it should be sufficient to create a linear model. \n\nSo now we will use FSharp.Stats to build the two linear models ordered by the hypothetical customer. We start by defining a function that performs the fitting and plots the result:\n*)\n\nopen Fitting.LinearRegression.OrdinaryLeastSquares\n\nlet predictPricesByRooms description data = \n    let pricesAll :Series\u003C_,float\u003E = \n        data\n        |\u003E Frame.getCol \u0022MedianHomeValue\u0022\n\n    let roomsPerDwellingAll :Series\u003C_,float\u003E = \n        data\n        |\u003E Frame.getCol \u0022RoomsPerDwelling\u0022   \n\n    let fit = \n        let tmpRooms, tmpPrices = \n            Series.zipInner roomsPerDwellingAll pricesAll    \n            |\u003E Series.sortBy fst\n            |\u003E Series.values \n            |\u003E Seq.unzip\n        let coeffs = Linear.Univariable.coefficient (vector tmpRooms) (vector tmpPrices)\n        let model  = Linear.Univariable.fit coeffs \n        let predictedPrices = tmpRooms |\u003E Seq.map model\n        [\n        Chart.Point(tmpRooms,tmpPrices)\n        |\u003E Chart.withTraceName (sprintf \u0022%s: data\u0022 description )\n        Chart.Line(tmpRooms,predictedPrices)\n        |\u003E Chart.withTraceName (sprintf \u0022%s: coefficients: intercept:%f, slope:%f\u0022 description coeffs.[0] coeffs.[1])\n        ]                                  \n        |\u003E Chart.combine\n        |\u003E Chart.withXAxisStyle(\u0022rooms per dwelling\u0022)\n        |\u003E Chart.withYAxisStyle(\u0022median value\u0022)\n    fit   \n\n(**\nAfterwards, we can apply the function on our prepared datasets and have a look at the model and especially the model coefficients. \n*)\nlet modelVis = \n    [\n    predictPricesByRooms \u0022not at river\u0022 housesNotAtRiver\n    predictPricesByRooms \u0022at river\u0022 housesAtRiver\n    ]\n    |\u003E Chart.combine\n    |\u003E Chart.withSize(1200.,700.)\n\n(***hide***)\nmodelVis |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n(**\nBoth models approximate the data in a reasonable way. When we inspect the coefficients, we see that the models only differ slightly in slope, but have an absolute offset of ~7.5. This observation complements the insights gained by the explorative data analysis approach using the histogram! \n*)"},{"uri":"https://fslab.org/007_replicate-quality-control.html","title":"Replicate quality control\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Replicate quality control\ncategory: advanced\nauthors: Heinrich Lukas Weil    \nindex: 0\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: FSharp.Data\u0022\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Cyjs.NET\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: FSharp.Data\u0022\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Cyjs.NET\u0022\n#endif // IPYNB\n\n\n(**\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath=content/tutorials/{{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n# Replicate quality control\n\n\n_Summary:_ This tutorial demonstrates an example workflow using different FsLab libraries. The aim is to check the quality of replicate measurements by clustering the samples.\n\n\n## Introduction\n\nIn biology and other sciences, experimental procedures are often repeated several times in the same conditions. These resulting samples are called replicates. \nReplicates are especially useful to check for the reproducibility of the results and to boost their trustability.\n\nOne metric for the quality of the measurements is rather easy in principle. Samples received from a similar procedure should also result in similar measurements. \nTherefore just checking if replicates are more similar than other samples can already hand to the experimenter some implications about the quality of his samples.\nThis is especially useful when considering that usually - as the ground truth is unknown - this trustability is difficult to measure. \n\nIn this tutorial, a simple workflow will be presented for how to visualize the clustering of replicates in an experiment. For this, 3 FsLab libraries will be used:\n\n0. [FSharp.Data](https://fsprojects.github.io/FSharp.Data/) for retreiving the data file\n1. [Deedle](https://github.com/fslaborg/Deedle) for reading a frame containing the data\n2. \u0026 3. [FSharp.Stats](https://fslab.org/FSharp.Stats/) to impute missing values and cluster the samples\n4. [CyJS.NET](https://fslab.org/Cyjs.NET/) to visualize the results\n\n\n## Referencing packages\n\n\u0060\u0060\u0060fsharp\n#r \u0022nuget: FSharp.Data\u0022\n#r \u0022nuget: Deedle\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Cyjs.NET\u0022\n\ndo fsi.AddPrinter(fun (printer:Deedle.Internal.IFsiFormattable) -\u003E \u0022\\n\u0022 \u002B (printer.Format()))\n\u0060\u0060\u0060\n\n## Loading Data \n\nIn this tutorial, an in silico generated dataset is used.  \n\n\u0060FSharp.Data\u0060 and \u0060Deedle\u0060 are used to load the data into the fsi.\n\n*)\n\nopen FSharp.Data\nopen Deedle\n\n// Load the data \nlet rawData = Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/InSilicoGeneExpression.csv\u0022\n\n// Create a deedle frame and index the rows with the values of the \u0022Key\u0022 column.\nlet rawFrame : Frame\u003Cstring,string\u003E = \n    Frame.ReadCsvString(rawData)\n    |\u003E Frame.indexRows \u0022Key\u0022\n\n(***hide***)\nrawFrame.Print()\n\n\n(*** include-output ***)\n\n(** \n\n## Data imputation\n\nMissing data is a constant companion of many data scientists. And it\u0027s not the best company, as missing values [can introduce a substantial amount of bias, make the handling and analysis of the data more arduous, and create reductions in efficiency](https://en.wikipedia.org/wiki/Imputation_(statistics)).\n\nTo tackle this, missing values can be substituted in a step called \u0060imputation\u0060. Different approaches for this exist. Here a k-nearest neighbour imputation is shown, which works as follows: \nFor each observation with missing values, the k most similar other observations are chosen. Then the missing value of this observation is substituted by the mean of these values in the neighbouring observations.\n\n*)\n\nopen FSharp.Stats\nopen FSharp.Stats.ML\n\n// Select the imputation method: kNearestImpute where the 2 nearest observations are considered\nlet kn : Impute.MatrixBaseImputation\u003Cfloat[],float\u003E = Impute.kNearestImpute 2\n\n// Impute the missing values using the \u0022imputeBy\u0022 function. The values of the deedle frame are first transformed into the input type of this function.\nlet imputedData = \n    rawFrame \n    |\u003E Frame.toJaggedArray \n    |\u003E Impute.imputeBy kn Ops.isNan\n\n// Creating a new frame from the old keys and the new imputed data\nlet imputedFrame = \n    Frame.ofJaggedArray imputedData\n    |\u003E Frame.indexRowsWith rawFrame.RowKeys\n    |\u003E Frame.indexColsWith rawFrame.ColumnKeys\n\n(***hide***)\nimputedFrame.Print()\n\n(*** include-output ***)\n(** \n\n## Hierarchical clustering\n\nTo sort the level of closeness between samples, we perform a hierarchical clustering. Details about this can be found [here](003_clustering_hierarchical.html) and [here](https://fslab.org/FSharp.Stats/Clustering.html#Hierarchical-clustering).\n\n*)\n\nopen FSharp.Stats.ML.Unsupervised\n\n// Retreive the sample columns from the frame\nlet samples = \n    imputedFrame\n    |\u003E Frame.getNumericCols\n    |\u003E Series.observations\n    |\u003E Seq.map (fun (k,vs) -\u003E \n        k,\n        vs\n        |\u003E Series.values\n    )\n\n// Run the hierarchical clustering on the samples\n// The clustering is performed on labeled samples (name,values) so that these labels later appear in the cluster tree\nlet clustering = \n    HierarchicalClustering.generate \n        (fun (name1,values1) (name2,values2) -\u003E DistanceMetrics.euclidean values1 values2) // perform the distance calculation only on the values, not the labels\n        HierarchicalClustering.Linker.wardLwLinker\n        samples\n    |\u003E HierarchicalClustering.mapClusterLeaftags fst // only keep the labels in the cluster tree\n\n(*** include-value:clustering ***)\n\n(** \n\n## Data visualization\n\nFinally, the clustering results can be visualized to check for replicate clustering. For this we use \u0060Cyjs.NET\u0060, an FsLab library which makes use of the \u0060Cytoscape.js\u0060 network visualization tool.\n\nFurther information about styling the graphs can be found [here](https://fslab.org/Cyjs.NET/).\n*)\n\n\nopen Cyjs.NET\n\n// Function for flattening the cluster tree to an edgelist\nlet hClustToEdgeList (f : int -\u003E \u0027T) (hClust : HierarchicalClustering.Cluster\u003C\u0027T\u003E) =\n    let rec loop (d,nodeLabel) cluster=\n        match cluster with\n        | HierarchicalClustering.Node (id,dist,_,c1,c2) -\u003E\n            let t = f id\n            loop (dist,t) c1\n            |\u003E List.append (loop (dist,t) c2)\n            |\u003E List.append [nodeLabel,t,d] \n        | HierarchicalClustering.Leaf (_,_,label)-\u003E [(nodeLabel,label,d)]\n    loop (0., f 0) hClust\n\nlet rawEdgeList = hClustToEdgeList (string) clustering\n\n// The styled vertices, samnples are coloured based on the condition they belong to. So replicates of one condition have the same colour\nlet cytoVertices = \n    rawEdgeList\n    |\u003E List.collect (fun (v1,v2,w) -\u003E\n        [v1;v2]\n    )\n    |\u003E List.distinct\n    |\u003E List.map (fun v -\u003E \n        let label,color,size = \n            match v.Split \u0027_\u0027 with\n            | [|\u0022Condition0\u0022;_|] -\u003E \u0022Condition0\u0022, \u0022#6FB1FC\u0022,\u002240\u0022\n            | [|\u0022Condition1\u0022;_|] -\u003E \u0022Condition1\u0022, \u0022#EDA1ED\u0022,\u002240\u0022\n            | [|\u0022Condition2\u0022;_|] -\u003E \u0022Condition2\u0022, \u0022#F5A45D\u0022,\u002240\u0022\n            | _ -\u003E \u0022\u0022,\u0022#DDDDDD\u0022,\u002210\u0022\n\n        let styling = [CyParam.label label; CyParam.color color; CyParam.width size]\n        Elements.node (v) styling\n    )\n\n// Helper function to transform the distances between samples to weights\nlet distanceToWeight = \n    let max = rawEdgeList |\u003E List.map (fun (a,b,c) -\u003E c) |\u003E List.max\n    fun distance -\u003E 1. - (distance / max)   \n\n\n// Styled edges\nlet cytoEdges = \n    rawEdgeList\n    |\u003E List.mapi (fun i (v1,v2,weight) -\u003E \n        let styling = [CyParam.weight (distanceToWeight weight)]\n        Elements.edge (\u0022e\u0022 \u002B string i) v1 v2 styling\n    )\n\n// Resulting cytograph\nlet cytoGraph = \n\n    CyGraph.initEmpty ()\n    |\u003E CyGraph.withElements cytoVertices\n    |\u003E CyGraph.withElements cytoEdges\n    |\u003E CyGraph.withStyle \u0022node\u0022 \n        [\n            CyParam.content =. CyParam.label\n            CyParam.shape =. CyParam.shape\n            CyParam.color =. CyParam.color\n            CyParam.width =. CyParam.width\n        ]\n    |\u003E CyGraph.withLayout (Layout.initCose (id))  \n\n(** \n\n\u0060\u0060\u0060fsharp\n// Send the cytograph to the browser\ncytoGraph\n|\u003E CyGraph.show\n\u0060\u0060\u0060\n\n*)\n\n(***hide***)\ncytoGraph\n|\u003E CyGraph.withSize(600, 400) \n|\u003E HTML.toEmbeddedHTML\n\n(*** include-it-raw ***)\n\n\n(** \n\n## Interpretation\n\nAs can be seen in the graph, replicates of one condition cluster together. This is a good sign for the quality of the experiment. \nIf one replicate of a condition does not behave this way, it can be considered an outlier.\nIf the replicates don\u0027t cluster together at all, there might be some problems with the experiment.\n\n*)"},{"uri":"https://fslab.org/introductionIII.html","title":"F# Introduction III: Library Setup\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: F# Introduction III: Library Setup\ncategory: fsharp\nauthors: Kevin Schneider, Jonathan Ott\nindex: 3\n---\n*)\n\n(***hide***)\n#r \u0022nuget: BlackFox.Fake.BuildTask\u0022\n#r \u0022nuget: Fake.Core.Target\u0022\n#r \u0022nuget: Fake.Core.Process\u0022\n#r \u0022nuget: Fake.Core.ReleaseNotes\u0022\n#r \u0022nuget: Fake.IO.FileSystem\u0022\n#r \u0022nuget: Fake.DotNet.Cli\u0022\n#r \u0022nuget: Fake.DotNet.MSBuild\u0022\n#r \u0022nuget: Fake.DotNet.AssemblyInfoFile\u0022\n#r \u0022nuget: Fake.DotNet.Paket\u0022\n#r \u0022nuget: Fake.DotNet.FSFormatting\u0022\n#r \u0022nuget: Fake.DotNet.Fsi\u0022\n#r \u0022nuget: Fake.DotNet.NuGet\u0022\n#r \u0022nuget: Fake.Api.Github\u0022\n#r \u0022nuget: Fake.DotNet.Testing.Expecto \u0022\n#r \u0022nuget: Fake.Tools.Git\u0022\n\n(**\n# F# Introduction III: Library Setup\n\nThis guide shows an example setup for a library. This is not the only way on how to do this, but merely a possibility. As always, this guide is meant as a starting point to be expanded upon. \nFor example, unit tests and full buildchains with automatic releases can be added to this template. \nThe installation of .NET 5.0 or dotnet SDK 3.1 LTS is required. It is also recommended to use [GitHub](https://github.com/) when following this example.\n\n## Initializing the repository\n\n* An easy way to initialize a repository is by creating a new one using GitHub and cloning it.\n    * You can automatically add a readme, a .gitignore with many entries for Visual Studio already added and a license of choice.\n\n    ![]({{root}}images/InitRepo.png)\n\n* After you cloned the initialized repository, it should look like this:  \n\n    ![]({{root}}images/Lib1.png)\n\n## Initializing the library\n\n* The stock library template is just fine (change framework if you know what you are doing):\n    \u0060dotnet new classlib -lang F# -n \u0022YourNameHere\u0022 --framework net5.0 -o src/YourNameHere\u0060\n* Add an entry for the \u0027pkg\u0027 folder to your \u0060.gitignore\u0060\n* Create a \u0060RELEASE_NOTES.md\u0060 file in the project root, make sure to add at least one version header like this:\n\n\u0060\u0060\u0060\n### 0.0.1 - 28/7/2021\n\u0060\u0060\u0060\n* Add a solution to your projekt with \u0060dotnet new sln --name YourNameHere\u0060\n* After you completed the previous steps your folder should look like this:  \n\n    ![]({{root}}images/Lib2.png)\n\n## Initializing the buildchain with FAKE\n\n* Initialize a local tool manifest that will keep track of the usable local dotnet tools in this project.\n    * In the project root: \u0060dotnet new tool-manifest\u0060\n* In the project root: Install the fake cli as local tool: \u0060dotnet tool install fake-cli\u0060\n* In the project root: Install paket as local tool: \u0060dotnet tool install paket\u0060\n* In the project root: Create a new empty \u0060build.fsx\u0060 file\n* Your folder should now look like this:  \n\n    ![]({{root}}images/Lib3.png)\n\n* Open the \u0060build.fsx\u0060 file (intellisense will not work right after creating it) and add the following content.\n\nFirst, lets reference the dependencies of the build script. In fake they are loaded via the \u0060paket\u0060 manager:\n\n\u0060\u0060\u0060fsharp\n#r \u0022paket:\nnuget BlackFox.Fake.BuildTask\nnuget Fake.Core.Target\nnuget Fake.Core.Process\nnuget Fake.Core.ReleaseNotes\nnuget Fake.IO.FileSystem\nnuget Fake.DotNet.Cli\nnuget Fake.DotNet.MSBuild\nnuget Fake.DotNet.AssemblyInfoFile\nnuget Fake.DotNet.Paket\nnuget Fake.DotNet.FSFormatting\nnuget Fake.DotNet.Fsi\nnuget Fake.DotNet.NuGet\nnuget Fake.Api.Github\nnuget Fake.DotNet.Testing.Expecto \nnuget Fake.Tools.Git //\u0022\n\u0060\u0060\u0060\n\nThen, we open the dependencies. Note that for getting intellisense, you will have to run the script once with the fake runner (see [here](#Running-the-build-script)).\n*)\n\n#if !FAKE\n#load \u0022./.fake/build.fsx/intellisense.fsx\u0022\n#r \u0022netstandard\u0022 // Temp fix for https://github.com/dotnet/fsharp/issues/5216\n#endif\n\nopen BlackFox.Fake\nopen System.IO\nopen Fake.Core\nopen Fake.DotNet\nopen Fake.IO\nopen Fake.IO.FileSystemOperators\nopen Fake.IO.Globbing.Operators\nopen Fake.Tools\n\n[\u003CAutoOpen\u003E]\n/// user interaction prompts for critical build tasks where you may want to interrupt when you see wrong inputs.\nmodule MessagePrompts =\n\n    let prompt (msg:string) =\n        System.Console.Write(msg)\n        System.Console.ReadLine().Trim()\n        |\u003E function | \u0022\u0022 -\u003E None | s -\u003E Some s\n        |\u003E Option.map (fun s -\u003E s.Replace (\u0022\\\u0022\u0022,\u0022\\\\\\\u0022\u0022))\n\n    let rec promptYesNo msg =\n        match prompt (sprintf \u0022%s [Yn]: \u0022 msg) with\n        | Some \u0022Y\u0022 | Some \u0022y\u0022 -\u003E true\n        | Some \u0022N\u0022 | Some \u0022n\u0022 -\u003E false\n        | _ -\u003E System.Console.WriteLine(\u0022Sorry, invalid answer\u0022); promptYesNo msg\n\n    let releaseMsg = \u0022\u0022\u0022This will stage all uncommitted changes, push them to the origin and bump the release version to the latest number in the RELEASE_NOTES.md file. \n        Do you want to continue?\u0022\u0022\u0022\n\n    let releaseDocsMsg = \u0022\u0022\u0022This will push the docs to gh-pages. Remember building the docs prior to this. Do you want to continue?\u0022\u0022\u0022\n\n/// Executes a dotnet command in the given working directory\nlet runDotNet cmd workingDir =\n    let result =\n        DotNet.exec (DotNet.Options.withWorkingDirectory workingDir) cmd \u0022\u0022\n    if result.ExitCode \u003C\u003E 0 then failwithf \u0022\u0027dotnet %s\u0027 failed in %s\u0022 cmd workingDir\n(**\nNote: This \u0060build.fsx\u0060 will be gradually epxanded\n\n* Add the \u0060ProjectInfo\u0060 module to the \u0060build.fsx\u0060 file, which will contain all relevant metadata for the buildchain except nuget package metadata (more on that later).\n* Replace all strings with the correct ones for your project.\n*)\n/// Metadata about the project\nmodule ProjectInfo = \n\n    let project = \u0022LibraryExample\u0022\n\n    let summary = \u0022An example Library\u0022\n\n    let configuration = \u0022Release\u0022\n\n    // Git configuration (used for publishing documentation in gh-pages branch)\n    // The profile where the project is posted\n    let gitOwner = \u0022YourGitProfile\u0022\n    let gitName = \u0022YourNameHere\u0022\n\n    let gitHome = sprintf \u0022%s/%s\u0022 \u0022https://github.com\u0022 gitOwner\n\n    let projectRepo = sprintf \u0022%s/%s/%s\u0022 \u0022https://github.com\u0022 gitOwner gitName\n\n    let website = \u0022/YourNameHere\u0022\n\n    let pkgDir = \u0022pkg\u0022\n\n    let release = ReleaseNotes.load \u0022RELEASE_NOTES.md\u0022\n\n    let stableVersion = SemVer.parse release.NugetVersion\n\n    let stableVersionTag = (sprintf \u0022%i.%i.%i\u0022 stableVersion.Major stableVersion.Minor stableVersion.Patch )\n\n    let mutable prereleaseSuffix = \u0022\u0022\n\n    let mutable prereleaseTag = \u0022\u0022\n\n    let mutable isPrerelease = false\n(**\n* Add the \u0060BasicTasks\u0060 module to the \u0060build.fsx\u0060 file, which will contain the minimal build chain.\n*)\n/// Barebones, minimal build tasks\nmodule BasicTasks = \n\n    open ProjectInfo\n\n    let setPrereleaseTag = BuildTask.create \u0022SetPrereleaseTag\u0022 [] {\n        printfn \u0022Please enter pre-release package suffix\u0022\n        let suffix = System.Console.ReadLine()\n        prereleaseSuffix \u003C- suffix\n        prereleaseTag \u003C- (sprintf \u0022%s-%s\u0022 release.NugetVersion suffix)\n        isPrerelease \u003C- true\n    }\n\n    let clean = BuildTask.create \u0022Clean\u0022 [] {\n        !! \u0022src/**/bin\u0022\n        \u002B\u002B \u0022src/**/obj\u0022\n        \u002B\u002B \u0022pkg\u0022\n        \u002B\u002B \u0022bin\u0022\n        |\u003E Shell.cleanDirs \n    }\n\n    let build = BuildTask.create \u0022Build\u0022 [clean] {\n        !! \u0022src/**/*.*proj\u0022\n        |\u003E Seq.iter (DotNet.build id)\n    }\n\n    let copyBinaries = BuildTask.create \u0022CopyBinaries\u0022 [clean; build] {\n        let targets = \n            !! \u0022src/**/*.??proj\u0022\n            -- \u0022src/**/*.shproj\u0022\n            |\u003E  Seq.map (fun f -\u003E ((Path.getDirectory f) \u003C/\u003E \u0022bin\u0022 \u003C/\u003E configuration, \u0022bin\u0022 \u003C/\u003E (Path.GetFileNameWithoutExtension f)))\n        for i in targets do printfn \u0022%A\u0022 i\n        targets\n        |\u003E  Seq.iter (fun (fromDir, toDir) -\u003E Shell.copyDir toDir fromDir (fun _ -\u003E true))\n    }\n(**\n* At the bottom of the \u0060build.fsx\u0060 file, add the following lines:\n*)\nopen BasicTasks\nBuildTask.runOrDefault copyBinaries\n(**\n* Create a \u0060build.cmd\u0060 or \u0060build.sh\u0060 file (or both) with the following lines:\n\n### build.cmd\n\n\u0060\u0060\u0060shell\ndotnet tool restore\ndotnet fake build %*\n\u0060\u0060\u0060\n\n### build.sh\n\n\u0060\u0060\u0060shell\n#!/usr/bin/env bash\n\nset -eu\nset -o pipefail\n\ndotnet tool restore\ndotnet fake build \u0022$@\u0022\n\u0060\u0060\u0060\n\n## Running the build script\n\n* You can now run your build via calling either \u0060build.cmd\u0060 or \u0060build.sh\u0060.\n    * Optionally, you can pass the \u0060-t\u0060 argument with it to execute a specific build task, e.g \u0060./build.cmd -t clean\u0060 to execute the clean target.\n    * The first time you run the build.cmd will also enable intellisense for the fake build script\n* After building for the first time your folder will look like this:  \n\n    ![]({{root}}images/Lib4.png)\n\n## Packing a nuget package\n\n* Add nuget package metadata to the project file (src/LibraryExample/LibraryExample.fsproj) and adapt accordingly:\n\n\u0060\u0060\u0060\n\u003CPropertyGroup\u003E\n    \u003CAuthors\u003EYourName\u003C/Authors\u003E\n    \u003CDescription\u003EYour description here\u003C/Description\u003E\n    \u003CSummary\u003EYour summary here\u003C/Summary\u003E\n    \u003CPackageLicenseExpression\u003EMIT\u003C/PackageLicenseExpression\u003E\n    \u003CPackageProjectUrl\u003Ehttps://fslab.org/projectName/\u003C/PackageProjectUrl\u003E\n    \u003CPackageIconUrl\u003Ehttps://fslab.org/projectName/img/logo.png\u003C/PackageIconUrl\u003E\n    \u003CPackageTags\u003Edocumentation fsharp csharp dotnet\u003C/PackageTags\u003E\n    \u003CRepositoryUrl\u003Ehttps://github.com/fslaborg/projectName\u003C/RepositoryUrl\u003E\n    \u003CRepositoryType\u003Egit\u003C/RepositoryType\u003E\n    \u003CFsDocsLicenseLink\u003Ehttps://github.com/fslaborg/projectName/blob/master/LICENSE\u003C/FsDocsLicenseLink\u003E\n    \u003CFsDocsReleaseNotesLink\u003Ehttps://github.com/fslaborg/projectName/blob/master/RELEASE_NOTES.md\u003C/FsDocsReleaseNotesLink\u003E\n\u003C/PropertyGroup\u003E\n\u0060\u0060\u0060\n\n* Add the \u0060PackageTasks\u0060 module to the \u0060build.fsx\u0060 file, which will take care of building nuget packages for both stable and prerelease packages:\n*)\n\n/// Package creation\nmodule PackageTasks = \n\n    open ProjectInfo\n\n    open BasicTasks\n\n    let pack = BuildTask.create \u0022Pack\u0022 [clean; build; copyBinaries] {\n        if promptYesNo (sprintf \u0022creating stable package with version %s OK?\u0022 stableVersionTag ) \n            then\n                !! \u0022src/**/*.*proj\u0022\n                |\u003E Seq.iter (Fake.DotNet.DotNet.pack (fun p -\u003E\n                    let msBuildParams =\n                        {p.MSBuildParams with \n                            Properties = ([\n                                \u0022Version\u0022,stableVersionTag\n                                \u0022PackageReleaseNotes\u0022,  (release.Notes |\u003E String.concat \u0022\\r\\n\u0022)\n                            ] @ p.MSBuildParams.Properties)\n                        }\n                    {\n                        p with \n                            MSBuildParams = msBuildParams\n                            OutputPath = Some pkgDir\n                    }\n                ))\n        else failwith \u0022aborted\u0022\n    }\n\n    let packPrerelease = BuildTask.create \u0022PackPrerelease\u0022 [setPrereleaseTag; clean; build; copyBinaries] {\n        if promptYesNo (sprintf \u0022package tag will be %s OK?\u0022 prereleaseTag )\n            then \n                !! \u0022src/**/*.*proj\u0022\n                //-- \u0022src/**/Plotly.NET.Interactive.fsproj\u0022\n                |\u003E Seq.iter (Fake.DotNet.DotNet.pack (fun p -\u003E\n                            let msBuildParams =\n                                {p.MSBuildParams with \n                                    Properties = ([\n                                        \u0022Version\u0022, prereleaseTag\n                                        \u0022PackageReleaseNotes\u0022,  (release.Notes |\u003E String.toLines )\n                                    ] @ p.MSBuildParams.Properties)\n                                }\n                            {\n                                p with \n                                    VersionSuffix = Some prereleaseSuffix\n                                    OutputPath = Some pkgDir\n                                    MSBuildParams = msBuildParams\n                            }\n                ))\n        else\n            failwith \u0022aborted\u0022\n    }\n(**\n* You can test both targets with \u0060./build.cmd -t Pack\u0060 or \u0060./build.cmd -t PackPrerelease\u0060 respectively.\n* The packages can be found in the \u0060pkg\u0060 folder in the project root. Since you do not want to host your nuget packages on github, do also remove this folder from source control by adding /pkg to your .gitignore file.\n* If you want users of your nuget package to have a pleasant debugging experience you can make use of [sourcelink](https://github.com/dotnet/sourcelink).\n    * To install this package, navigate to the folder of your project, e.g. src/LibraryExample and call: \u0060dotnet add package Microsoft.SourceLink.GitHub --version 1.0.0\u0060\n\n## Documentation\n\n* In the project root: Install fsdocs as local tool: \u0060dotnet tool install FSharp.Formatting.CommandTool\u0060\n* In the project root: Install the fslab documentation template: \u0060dotnet new -i FsLab.DocumentationTemplate::*\u0060\n* Initialize the fslab documentation template: \u0060dotnet new fslab-docs\u0060\n* Add the \u0060DocumentationTasks\u0060 module to the \u0060build.fsx\u0060 file, which will take care initializing documentation files and developing them:\n*)\n/// Build tasks for documentation setup and development\nmodule DocumentationTasks =\n\n    open ProjectInfo\n\n    open BasicTasks\n\n    let buildDocs = BuildTask.create \u0022BuildDocs\u0022 [build; copyBinaries] {\n        printfn \u0022building docs with stable version %s\u0022 stableVersionTag\n        runDotNet \n            (sprintf \u0022fsdocs build --eval --clean --property Configuration=Release --parameters fsdocs-package-version %s\u0022 stableVersionTag)\n            \u0022./\u0022\n    }\n\n    let buildDocsPrerelease = BuildTask.create \u0022BuildDocsPrerelease\u0022 [setPrereleaseTag; build; copyBinaries] {\n        printfn \u0022building docs with prerelease version %s\u0022 prereleaseTag\n        runDotNet \n            (sprintf \u0022fsdocs build --eval --clean --property Configuration=Release --parameters fsdocs-package-version %s\u0022 prereleaseTag)\n            \u0022./\u0022\n    }\n\n    let watchDocs = BuildTask.create \u0022WatchDocs\u0022 [build; copyBinaries] {\n        printfn \u0022watching docs with stable version %s\u0022 stableVersionTag\n        runDotNet \n            (sprintf \u0022fsdocs watch --eval --clean --property Configuration=Release --parameters fsdocs-package-version %s\u0022 stableVersionTag)\n            \u0022./\u0022\n    }\n\n    let watchDocsPrerelease = BuildTask.create \u0022WatchDocsPrerelease\u0022 [setPrereleaseTag; build; copyBinaries] {\n        printfn \u0022watching docs with prerelease version %s\u0022 prereleaseTag\n        runDotNet \n            (sprintf \u0022fsdocs watch --eval --clean --property Configuration=Release --parameters fsdocs-package-version %s\u0022 prereleaseTag)\n            \u0022./\u0022\n    }\n(**\n* To create a new documentation file, run \u0060./build.cmd -t InitDocsPage\u0060\n* Add \u0060tmp/\u0060 to \u0060.gitignore\u0060\n* To run fsdocs in watchmode (hot reaload local hosting of your docs for live development), run \u0060dotnet fsdocs watch\u0060\n* Your repository should now look like this:  \n\n    ![]({{root}}images/Lib5.png)\n\n## Adding nuget packages\n\n* Navigate to your project folder (i. e. \u0060src/LibraryExample\u0060)\n* If you want to specify a package source other than nuget.com (e.g. a local package) you can specify other sources after adding a nuget.config file to your project root:\n\n\u0060\u0060\u0060\n\u003C?xml version=\u00221.0\u0022 encoding=\u0022utf-8\u0022?\u003E\n\u003Cconfiguration\u003E\n\u003C/configuration\u003E\n\u0060\u0060\u0060\n\n* The following example would add the local lib folder as a new nuget source to your local nuget.config file: \u0060dotnet nuget add source ./lib --configfile nuget.config\u0060\n\n\u0060\u0060\u0060\n\u003C?xml version=\u00221.0\u0022 encoding=\u0022utf-8\u0022?\u003E\n\u003Cconfiguration\u003E\n  \u003CpackageSources\u003E\n    \u003Cadd key=\u0022Package source 1\u0022 value=\u0022./lib\u0022 /\u003E\n  \u003C/packageSources\u003E\n\u003C/configuration\u003E\n\u0060\u0060\u0060\n\n* Calling \u0060dotnet add package PackageName --version PackageVersion\u0060 will still start to search for the package on nuget.com, but if this call is unsuccesful, Package source 1 will be used as a fallback. For a more complete view on how to use nuget.config files please visit the [offical documentation](https://docs.microsoft.com/en-us/nuget/consume-packages/configuring-nuget-behavior) or have a look at [this](https://blogs.naxam.net/configure-nuget-package-sources-for-your-project-cd8b96397360) blog post.\n*)"},{"uri":"https://fslab.org/introductionI.html","title":"F# Introduction I: Setting up an environment\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: F# Introduction I: Setting up an environment\ncategory: fsharp\nauthors: Jonathan Ott\nindex: 1\n---\n*)\n(**\n# F# Introduction I: Setting up an environment\n\n## Installing Visual Studio Code\n\n* Download the recommended [.NET SDK](https://dotnet.microsoft.com/download) for your operating system and install it.\n    * By Selecting [All .NET downloads](https://dotnet.microsoft.com/download/dotnet) you can between installers for different operating systems.  \n\n    ![]({{root}}images/DotnetSDK.png)\n\n* Download the latest stable build of [Visual Studio Code](https://code.visualstudio.com/) for your operating system and install it.  \n\n    ![]({{root}}images/VSCode.png)\n\n* Open Visual Studio Code, navigate to the \u0022Extensions\u0022 tab and install \u0022Ionide-fsharp\u0022  \n\n    ![]({{root}}images/IonideVSCode.png)\n\n## Installing Visual Studio\n\n### Windows\n\n* Download the desired version of [Visual Studio](https://visualstudio.microsoft.com/downloads/?utm_medium=microsoft\u0026utm_source=docs.microsoft.com\u0026utm_campaign=inline\u002Blink\u0026utm_content=download\u002Bvs2019)  \n\n    ![]({{root}}images/VSWindows.png)\n\n* When executing the installer select \u0022.NET desktop development\u0022 under workloads and make sure \u0022F# desktop language support\u0022 is ticked as well on the right side.  \n\n    ![]({{root}}images/VSInstaller.png)\n\n* Select any other workloads or individual components you are interested in and start the installation.\n\n### macOS\n\n* Download Visual Studio for Mac [Visual Studio](https://visualstudio.microsoft.com/downloads/?utm_medium=microsoft\u0026utm_source=docs.microsoft.com\u0026utm_campaign=inline\u002Blink\u0026utm_content=download\u002Bvs2019)  \n\n    ![]({{root}}images/VSMac.png)\n\n* Run the Installer. F# is installed by default.\n*)"},{"uri":"https://fslab.org/external.html","title":"Here is a list of usefull external (non-fslab) F# resources:\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: External F# resources\ncategory: fsharp\nauthors: Various\nindex: 0\n---\n*)\n\n(**\n# Here is a list of usefull external (non-fslab) F# resources:\n\n## Learning and documentation\n- Official F# documentation: https://docs.microsoft.com/en-us/dotnet/fsharp/\n- F# module on Microsoft LEARN: https://docs.microsoft.com/en-us/learn/modules/fsharp-first-steps/\n- Website of the F# Software Foundation: https://fsharp.org/\n\n## Blogs \u0026 other content\n- fsharp for fun and profit: https://fsharpforfunandprofit.com/\n- fsharp weekly: https://sergeytihon.com/category/f-weekly/\n\n*)"},{"uri":"https://fslab.org/006_savitzky_golay_temperature.html","title":"Smoothing data with the Savitzky-Golay filter\n","content":"(***hide***)\n\n(*\n#frontmatter\n---\ntitle: Smoothing data with the Savitzky-Golay filter\ncategory: datascience\nauthors: Kevin Frey\nindex: 4\n---\n*)\n\n(***condition:prepare***)\n#r \u0022nuget: Fsharp.Data\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n\n(***condition:ipynb***)\n#if IPYNB\n#r \u0022nuget: FSharp.Data\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n#r \u0022nuget: Newtonsoft.JSON\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n#endif // IPYNB\n\n(**\n[![Binder]({{root}}images/badge-binder.svg)](https://mybinder.org/v2/gh/fslaborg/fslaborg.github.io/gh-pages?filepath=content/tutorials/{{fsdocs-source-basename}}.ipynb)\u0026emsp;\n[![Script]({{root}}images/badge-script.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.fsx)\u0026emsp;\n[![Notebook]({{root}}images/badge-notebook.svg)]({{root}}content/tutorials/{{fsdocs-source-basename}}.ipynb)\n\n\n# Smoothing data with the Savitzky-Golay filter\n\n_Summary:_ This tutorial demonstrates how to access a public dataset for temperature data with [FSharp.Data](https://fsprojects.github.io/FSharp.Data/), how to smooth the data points with \nthe Savitzky-Golay filter from [FSharp.Stats](https://fslab.org/FSharp.Stats/) and finally how to visualize the results with [Plotly.NET](https://plotly.net).\n\n## Introduction: \n\nThe Savitzky-Golay is a type of low-pass filter, particularly suited for smoothing noisy data. The main idea behind this approach is to make for each point a \nleast-square fit with a polynomial of high order over a odd-sized window centered at the point. One advantage of the Savitzky-Golay filter is that portions \nof high frequencies are not simply cut off, but are preserved due to the polynomial regression. This allows the filter to preserve properties of the distribution \nsuch as relative maxima, minima, and dispersion, which are usually distorted by flattening or shifting by conventional methods such as moving average.\n\nThis is useful when trying to identify general trends in highly fluctuating data sets, or to smooth out noise to improve the ability to find minima and maxima of the data trend.\nTo showcase this we will plot a temperature dataset from the \u0022[Deutscher Wetterdienst](https://www.dwd.de/DE/leistungen/klimadatendeutschland/klimadatendeutschland.html)\u0022, \na german organization for climate data. We will do this for both the original data points and a smoothed version.\n\n![windowed polynomial regression](https://upload.wikimedia.org/wikipedia/commons/8/89/Lissage_sg3_anim.gif)\n\nThe image shows the moving window for polynomial regression used in the Savitzky-Golay filter [@wikipedia](https://upload.wikimedia.org/wikipedia/commons/8/89/Lissage_sg3_anim.gif)\n\n\n## Referencing packages\n\n\u0060\u0060\u0060fsharp\n// Packages hosted by the Fslab community\n#r \u0022nuget: FSharp.Stats\u0022\n// third party .net packages \n#r \u0022nuget: FSharp.Data\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-preview.12\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-preview.12\u0022\n\u0060\u0060\u0060\n\n*)\n\n\n(**\n## Loading data\n\nWe will start by retrieving the data. This is done with the [FSharp.Data](https://fsprojects.github.io/FSharp.Data/) package \nand will return a single string in the original format.\n*)\n\n// Get data from Deutscher Wetterdienst\n// Explanation for Abbreviations: https://www.dwd.de/DE/leistungen/klimadatendeutschland/beschreibung_tagesmonatswerte.html\nlet rawData = FSharp.Data.Http.RequestString @\u0022https://raw.githubusercontent.com/fslaborg/datasets/main/data/WeatherDataAachen-Orsbach_daily_1year.txt\u0022\n\n// print first 1000 characters to console.\nrawData.[..1000] |\u003E printfn \u0022%s\u0022\n\n(*** include-output ***)\n\n(**\n\nCurrently the data set is not in a format, that is easily parsable. Normally you would try to use \nthe Deedle package to read in the data into a [Deedle](https://fslab.org/Deedle/) data frame. As this is not possible here, we will do some ugly formatting.\n\n## Data Formatting/Parsing\n*)\n\nopen System\nopen System.Text.RegularExpressions\n\n/// Tuple of 4 data arrays representing the measured temperature for over a year.\nlet processedData = \n    // First separate the huge string in lines\n    rawData.Split([|\u0027\\n\u0027|], StringSplitOptions.RemoveEmptyEntries)\n    // Skip the first 5 rows until the real data starts, also skip the last row (length-2) to remove a \u0022\u003C/pre\u003E\u0022 at the end\n    |\u003E fun arr -\u003E arr.[5..arr.Length-2]\n    |\u003E Array.map (fun data -\u003E \n        // Regex pattern that will match groups of whitespace\n        let whitespacePattern = @\u0022\\s\u002B\u0022\n        // This is needed to tell regex to replace hits with a tabulator\n        let matchEval = MatchEvaluator(fun _ -\u003E @\u0022\\t\u0022 )\n        // The original data columns are separated by different amounts of whitespace.\n        // Therefore, we need a flexible string parsing option to replace any amount of whitespace with a single tabulator.\n        // This is done with the regex pattern above and the fsharp core library \u0022System.Text.RegularExpressions\u0022 \n        let tabSeparated = Regex.Replace(data, whitespacePattern, matchEval)\n        tabSeparated\n        // Split each row by tabulator will return rows with an equal amount of values, which we can access.\n        |\u003E fun dataStr -\u003E dataStr.Split([|@\u0022\\t\u0022|], StringSplitOptions.RemoveEmptyEntries)\n        |\u003E fun dataArr -\u003E \n            // Second value is the date of measurement, which we will parse to the DateTime type\n            DateTime.ParseExact(dataArr.[1], \u0022yyyyMMdd\u0022, Globalization.CultureInfo.InvariantCulture),\n            // 5th value is minimal temperature at that date.\n            float dataArr.[4],\n            // 6th value is average temperature over 24 timepoints at that date.\n            float dataArr.[5],\n            // 7th value is maximal temperature at that date.\n            float dataArr.[6]\n    )\n    // Sort by date\n    |\u003E Array.sortBy (fun (day,tn,tm,tx) -\u003E day)\n    // Unzip the array of value tuples, to make the different values easier accessible\n    |\u003E fun arr -\u003E \n        arr |\u003E Array.map (fun (day,tn,tm,tx) -\u003E day.ToShortDateString()),\n        arr |\u003E Array.map (fun (day,tn,tm,tx) -\u003E tm),\n        arr |\u003E Array.map (fun (day,tn,tm,tx) -\u003E tx),\n        arr |\u003E Array.map (fun (day,tn,tm,tx) -\u003E tn)\n\n(*** include-value:processedData ***)\n\n(**\n## Exploring the data set with Plotly.NET\n\nNext we create a create chart function with [Plotly.NET](https://plotly.net) to produce a visual representation of our data set.\n*)\n\nopen Plotly.NET\nopen Plotly.NET.LayoutObjects\n\n// Because our data set is already rather wide we want to move the legend from the right side of the plot\n// to the right center. As this function is not defined for fsharp we will use the underlying js bindings (https://plotly.com/javascript/legend/#positioning-the-legend-inside-the-plot).\n// Declarative style in F# using underlying DynamicObj\n// https://plotly.net/#Declarative-style-in-F-using-the-underlying\nlet legend = \n    let tmp = Legend()\n    tmp?yanchor \u003C- \u0022top\u0022\n    tmp?y \u003C- 0.99\n    tmp?xanchor \u003C- \u0022left\u0022\n    tmp?x \u003C- 0.5\n    tmp\n\n/// This function will take \u0027processedData\u0027 as input and return a range chart with a line for the average temperature\n/// and a different colored area for the range between minimal and maximal temperature at that date.\nlet createTempChart (days,tm,tmUpper,tmLower) =\n    Chart.Range(\n        // data arrays\n        days, tm, tmUpper, tmLower,\n        StyleParam.Mode.Lines_Markers,\n        Color= Color.fromString \u0022#3D1244\u0022,\n        RangeColor= Color.fromString \u0022#F99BDE\u0022,\n        // Name for line in legend\n        Name=\u0022Average temperature over 24 timepoints each day\u0022,\n        // Name for lower point when hovering over chart\n        LowerName=\u0022Min temp\u0022,\n        // Name for upper point when hovering over chart\n        UpperName=\u0022Max temp\u0022\n    )\n    // Configure the chart with the legend from above\n    |\u003E Chart.withLegend legend\n    // Add name to y axis\n    |\u003E Chart.withYAxisStyle(\u0022daily temperature [\u00B0C]\u0022)\n    |\u003E Chart.withSize (1000.,600.)\n\n/// Chart for original data set \nlet rawChart =\n    processedData \n    |\u003E createTempChart\n\n\n(***hide***)\nrawChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n(**\n\nAs you can see the data looks chaotic and is difficult to analyze. Trends are hidden in daily \ntemperature fluctuations and correlating events with temperature can get difficult. So next we want to\nsmooth the data to clearly see temperature trends.\n\n## Savitzky-Golay filter\n\nWe will use the \u0060Signal.Filtering.savitzkyGolay\u0060 function from [FSharp.Stats](https://fslab.org/FSharp.Stats/).\n\nParameters:\n\n- windowSize (\u0060int\u0060) the length of the window. Must be an odd integer number.\n- order (\u0060int\u0060) the order of the polynomial used in the filtering. Must be less then \u0060windowSize\u0060 - 1.\n- deriv (\u0060int\u0060) the order of the derivative to compute (default = 0 means only smoothing)\n- rate (\u0060int\u0060) this factor will influence amplitude when using Savitzky-Golay for derivation\n- data (\u0060float array\u0060) the values of the time history of the signal.\n\n*)\n\nopen FSharp.Stats\n\nlet smootheTemp ws order (days,tm,tmUpper,tmLower) =\n    let tm\u0027 = Signal.Filtering.savitzkyGolay ws order 0 1 tm\n    let tmUpper\u0027 = Signal.Filtering.savitzkyGolay ws order 0 1 tmUpper\n    let tmLower\u0027 = Signal.Filtering.savitzkyGolay ws order 0 1 tmLower\n    days,tm\u0027,tmUpper\u0027,tmLower\u0027\n\nlet smoothedChart =\n    processedData\n    |\u003E smootheTemp 31 4\n    |\u003E createTempChart \n\n\n(***hide***)\nsmoothedChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)"}]